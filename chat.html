<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>THIMBLE Chat</title>
    <style>
        body {
    font-family: Arial, sans-serif;
    margin: 0;
    padding: 0;
    background-color: #f0f0f0;
}

.chat-container {
    max-width: 800px;
    margin: 0 auto;
    padding: 20px;
    background-color: white;
    box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
}

h1 {
    text-align: center;
    color: #333;
}

.chat-messages {
    margin-bottom: 20px;
}

.message {
    background-color: #e6e6e6;
    border-radius: 5px;
    padding: 10px;
    margin-bottom: 10px;
}

.message-header {
    display: flex;
    justify-content: space-between;
    margin-bottom: 5px;
}

.author {
    font-weight: bold;
    color: #333;
}

.timestamp {
    color: #777;
    font-size: 0.8em;
}

.message-content {
    margin-bottom: 5px;
}

.message-hashtags {
    color: #0066cc;
    font-size: 0.9em;
}

.message-form {
    margin-top: 20px;
}

.message-form form {
    display: flex;
    flex-direction: column;
}

.message-form input,
.message-form textarea {
    margin-bottom: 10px;
    padding: 5px;
}

.message-form button {
    background-color: #4CAF50;
    color: white;
    border: none;
    padding: 10px;
    cursor: pointer;
}

.message-form button:hover {
    background-color: #45a049;
}

.chat-info {
    margin-top: 20px;
    text-align: center;
    color: #777;
    font-size: 0.9em;
}
.chat-messages {
    height: 400px; /* Adjust this value as needed */
    overflow-y: auto;
    display: flex;
    flex-direction: column-reverse;
}
.messages-wrapper {
    display: flex;
    flex-direction: column;
}

    </style>
</head>
<body>
    <div class="chat-container">
        <h1>THIMBLE Chat</h1>
        <div class="chat-messages">    
            <div class="chat-messages">
                <div class="message">
    <div class="message-header">
        <span class="author">ilyag</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">thank you for this day.

today i woke up just in time for standup.

barton is back!

i reported on working on this project.

i did the dishes in c-house and e-house.

and now i'm co-working at mit.

author: ilyag

</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">-----BEGIN PGP PUBLIC KEY BLOCK-----
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=/Ajc
-----END PGP PUBLIC KEY BLOCK-----
</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">test</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">this is not in the repo yet?

ok

author: test
</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

How to clean the compost bin

After it is picked up from the loading dock area, the compost bin may be dirty inside.

Here is an example of what it may look like: 42b7876f818b10241fa13b48d4dac68c50b4f27c

Cleaning the compost bin is an easy and straightforward process, but must be performed carefully, so as to not get the operator's clothes dirty.

Here is how it can be done:

Step 1: Transport the compost bin to the janitor closet.

Step 2: Open the compost bin's lid all the way (flip it)

Step 3: Lift and tip the compost bin into/over the sink, so that any excess liquid pours out into the sink.

Step 4: Place the compost bin upright again.

Step 5: Test the faucet flow rate over the sink. Open the knob slowly, so that you do not get unexpected extra water pressure. Tune to a slow flow rate, which will not splash you when hitting random surfaces inside the bin.

Step 6: Close the faucet, and put the hose over the compost bin.

Step 7: Let the water flow slowly, and run it over the compost bin sides. Do this until about a gallon of water is at the bottom of the compost bin. Do not overfill the compost bin! Otherwise, you will not be able to lift it!

Step 8: Lift and tip, just like in step 3.

Repeat steps 4-8 until the compost bin looks/smells reasonably clean.

Step 9: Profit of one clean compost bin! Take it back into the lounge.
-----BEGIN PGP SIGNATURE-----

wlwEAQEIABAFAmZDY4sJEED2yaahtwq8AAAHRQH+M2hakmijR7FTHbeMyuEP
QSHmaDeFDxVAwEmctYtx49hMKh6spaPkIKXXVb6VHg8BfGz5B104TxuCyNwq
Ro/0Bg==
=nYIL
-----END PGP SIGNATURE-----

-- 
Cookie: 40F6C9A6A1B70ABC
Received: 1715692427
Client: BE370DB5B3ED1ABC

</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">-----BEGIN PGP PUBLIC KEY BLOCK-----

xk0EZplypwECAMClH2cvUsxNXSbezCSzjl893wSq62/j0+8GbynCAwVSjEUL
kcwvIR2T9FUzmx73yYdRtf4mhIYo28oeosd1l9cAEQEAAc0FR3Vlc3TCdQQQ
AQgAKQUCZplypwYLCQcIAwIJEN1kS26iRLO1BBUICgIDFgIBAhkBAhsDAh4B
AAB2GgIAuIVEG6GdYU6ZahbimnZHy1w8Bb4TMWxe3PfzZWtq2IaOUV1vcj6x
O+FRk+xbILMhpwZ8oIV8uH6+USQQN10c/c5NBGaZcqcBAgCzx97Yws7IsbG3
qMYZ8LjkY2HrxrmP+000xrDScWAP7XmeubvQz8zIWupqwWRu7S0v7EK2lQIT
Y5xaqIwv1zp/ABEBAAHCXwQYAQgAEwUCZplypwkQ3WRLbqJEs7UCGwwAAPst
AgCLLrAnAjWoGzvppcKG4XE9DW+tvTc0E1OkmipauvFvLN8PJuPhMvPNLWRT
M64xhWpLtvQR/Y0XaB/zvNc2BZyt
=vJlw
-----END PGP PUBLIC KEY BLOCK-----

</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Fennelly, Lawrence J.                     </span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">
             BIBLIOGRAPHY OF COMPUTER SECURITY BOOKS
                       (1973 through 1988)

Note:  A bibliography is now being developed to encompass 1989. 
     

                       ABUSE/MISUSE/CRIME

                                                            
          AUTHOR:  Fennelly, Lawrence J.                     
                                                            
          TITLE:  Handbook of Loss Prevention and Crime      
                 Prevention                                 
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  Second                                
          NAME OF PUBLISHER:  Butterworth Publishers         
          LOCATION OF PUBLISHER:  Stoneham, MA               
          PUBLICATION DATE:  October 1988                    
          CATEGORY:  Abuse/Misuse/Crime                      
         COST:  $69.95                                      
         DESCRIPTION:  This book brings together the        
         expertise of over 40 security and crime prevention 
         professionals with information on the latest       
         technology, trends, and references.                

                                                            
          AUTHOR:  Lobel, Jerome                             
                                                            
          TITLE:  Foiling The Systems Breakers               
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  McGraw-Hill Book Company       
          LOCATION OF PUBLISHER:  New York                   
          PUBLICATION DATE:  1986                            
          CATEGORY:  Abuse/Misuse/Crime                      
         COST:  $34.95                                      
         DESCRIPTION:  This book is designed to help system 
         designers and data processing staff find ways to   
         protect computer systems from unauthorized access. 
                

                                                           
          AUTHOR:  U.S. Department of Justice                
                                                            
          TITLE:   Computer Crime:  Computer Security        
                  Techniques                                
          ORGANIZATION:  U.S. Department of Justice          
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER: U.S. Department of Justice      
          LOCATION OF PUBLISHER:  Washington, D.C.           
          PUBLICATION DATE:  Not Given TBD                   
          CATEGORY:  Abuse/Misuse/Crime                      
         COST:  Free                                        
         DESCRIPTION:  Presents the results of a major      
         review of the computer security procedures         
         currently employed in the public and private       
         sectors.                                           


          AUTHOR:  U.S. Department of Justice                
                                                            
          TITLE:  Computer Crime:  Electronic Fund Transfer  
                 Systems and Crime                          
          ORGANIZATION: U.S. Department of Justice           
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  U.S. Department of Justice     
          LOCATION OF PUBLISHER:  Washington, D.C.           
          PUBLICATION DATE:  1982                            
          CATEGORY:  Abuse/Misuse/Crime                      
         COST:  Free                                        
         DESCRIPTION:  Reviews the crime-related            
         implications of the growth of computer usage in    
         EFT, and the nature and magnitude of EFT crimes.   



          AUTHOR:   Van Duyn, Julia                          
                                                            
          TITLE:  The Human Factor in Computer Crime         
                                                            
          ORGANIZATION:  Institute of Internal Auditors      
          VOLUME NO:                                         
          EDITION NO:                                        
          NAME OF PUBLISHER:  Petrocelli Books, Inc.         
          LOCATION OF PUBLISHER:  New York, Princeton        
          PUBLICATION DATE:  1984                            
          CATEGORY:  Abuse/Misuse/Crime                      
         COST:  $24.95                                      
         DESCRIPTION:  States that insiders in a company    
         are the ones most likely to commit computer abuse. 
         A list of procedures that management can follow to 
         make their installation secure is included.        
                  

                         ACCESS CONTROL

          AUTHOR:  Abrams, M.D. and Podell, H.J.             
                                                            
          TITLE:  Computer and Network Security              
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO: First                                  
          NAME OF PUBLISHER:  Computer Society               
          LOCATION OF PUBLISHER:  Los Alamitos, CA           
          PUBLICATION DATE:   1987                           
          CATEGORY:  Access Control                          
         COST:  $50.00                                      
         DESCRIPTION: Examines information system security  
         with regard to computer, data, and network         
         security.                                          
                    
                                                          
          AUTHOR:  Bowers, Dan M.                            
                                                            
          TITLE:   Access Control and Personal Identification
                  Systems                                   
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Butterworth Publishers         
          LOCATION OF PUBLISHER:  Stoneham, MA               
          PUBLICATION DATE:  1988                            
          CATEGORY:  Access Control                          
         COST:  $24.95                                      
         DESCRIPTION:  Presents a thorough examination of   
         access control systems and devices for security    
         managers and practitioners in the field.           

              

                                                        
          AUTHOR:  Davies, D.W. and Price, W.L.              
                                                            
          TITLE:  Security for Computer Networks: An         
         Introduction to Data Security in Teleprocessing    
          ORGANIZATION:  National Physical Laboratory        
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER: John Wiley & Sons, Inc.         
          LOCATION OF PUBLISHER:  New York                   
          PUBLICATION DATE:  1984                            
          CATEGORY: Access Control                           
         COST:  $34.95                                      
         DESCRIPTION: Covers all aspects of network security
         from information protection and data integrity to  
         user identification and authentication. It         
         emphasizes cryptography exclusively as the means   
         of protecting data in networks.                    
                      
                                                            
          AUTHOR:   Foster, Caxton C.                        
                                                            
          TITLE:  Cryptoanalysis for Microcomputers          
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Hayden Book Company. Inc.      
          LOCATION OF PUBLISHER:   Rochelle Park, NJ         
          PUBLICATION DATE:  1982                            
          CATEGORY:  Access Control                          
         COST:                                              
         DESCRIPTION:  This books discusses cryptoanalyst   
         programs for microcomputers and provides programs  
         written in basic.                                  


                                                            
          AUTHOR: Katzan, Harry Jr.                          
                                                            
          TITLE:  The Standard Data Encryption Algorithm     
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Petrocelli Books, Inc.         
          LOCATION OF PUBLISHER:  Princeton, NJ              
          PUBLICATION DATE:  1977                            
          CATEGORY:  Access Control                          
         COST: $14.00                                       
         DESCRIPTION: This book provides a thorough         
         understanding of data encryption algorithm         
         techniques and their implementation.               



                      AUDIT AND EVALUATION

                                                            
          AUTHOR:  Kvong, Javier F.                          
                                                            
          TITLE:  Computer Auditing, Security, and Internal  
                 Control Manual                             
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO: First                                  
          NAME OF PUBLISHER:  Prentice Hall, Inc.            
          LOCATION OF PUBLISHER:  Englewood Cliffs, NJ       
          PUBLICATION DATE:  1987                            
          CATEGORY:  Audit and Evaluation                    
         COST:  $59.95                                      
         DESCRIPTION: This book shows how to test internal  
         controls and the integrity of a computer system.   
         It also gives a checklist and guidelines for       
         evaluating the controls and security of computer    
         installations.                                     
                  
                                                           
          AUTHOR:  Plagman, Bernard K. and Ross, Steven J.   
                                                            
          TITLE:   Audit and Control Systems Programming     
                  Activities                                
          ORGANIZATION:  Institute of Internal Auditors      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Institute of Internal Auditors 
          LOCATION OF PUBLISHER:  Altamonte Springs, FL      
          PUBLICATION DATE:  1985                            
          CATEGORY:  Audit and Evaluation                    
         COST:  $33.00                                      
         DESCRIPTION:  This books describes techniques that 
         can be used to audit the activities of systems     
         programmers. A composite profile is included of    
         what constitutes good systems programming activity.
                      
                                                         
          AUTHOR:  Rothberg, Gabriel B.                      
                                                            
          TITLE:  Structured EDP Auditing                    
                                                            
          ORGANIZATION:  Institute of Internal Auditors      
          VOLUME NO:                                         
          EDITION NO: First                                  
          NAME OF PUBLISHER:  Lifetime Learning Publications 
          LOCATION OF PUBLISHER:  Altamonte Springs, FL      
          PUBLICATION DATE:  1983                            
          CATEGORY:  Audit and Evaluation                    
         COST:  $33.95                                      
         DESCRIPTION:  This book shows how to go about      
         reviewing and establishing an EDP audit function.  
         Also included is how to define a DP environment    
         and identify its problems.                         


                                                            
          AUTHOR: Wood, Charles, Banks, William, Garcia, Abel
         Guarro, Sergio, Hampel, Viktor, Sartorio, Henry    
          TITLE: Computer Security:  A Comprehensive         
                Controls Checklist                          
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO: First                                  
          NAME OF PUBLISHER:  John Wiley & Sons              
          LOCATION OF PUBLISHER:  Somerset, NJ               
          PUBLICATION DATE:  1987                            
          CATEGORY:  Audit and Evaluation                    
         COST: 56.95                                        
         DESCRIPTION:  This books provides computer security
         procedures and related checklists. It is designed  
         to assist in determining the integrity of security 
         controls.                                          
                  

                      CONTINGENCY PLANNING
                                                            
          AUTHOR:  The Chantico Series                       
                                                            
          TITLE:  Disaster Recovery:  Contingency Planning   
                 and Program Evaluation                     
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Q.E.D. Information Sciences    
          LOCATION OF PUBLISHER:  Wellesley, MA              
          PUBLICATION DATE:  1985                            
          CATEGORY:  Contingency Planning                    
         COST:  $24.95                                      
         DESCRIPTION: This book discusses the phases of a   
         disaster recovery program including establishing   
         requirements, conducting the review program, and   
         evaluating the disaster recovery program.          


                      DATA BASE MANAGEMENT
                                                            
          AUTHOR:  Fernandex, E.B., Summers, R.C., and       
                  Wood, C.                                  
          TITLE:  The Systems Programming Series Database    
                 Security and Integrity                     
          ORGANIZATION:                                      
          VOLUME NO:  14467                                  
          EDITION NO:  First                                 
          NAME OF PUBLISHER:   Addison-Wesley Publishers     
          LOCATION OF PUBLISHER:  Reading, MA                
          PUBLICATION DATE:  1981                            
          CATEGORY:  Data Base Security                      
         COST:  $20.95                                      
         DESCRIPTION:  This book is concerned with the      
         security and integrity of information that is      
         maintained in data bases.                          


                        GENERAL SECURITY
                                                            
          AUTHOR:  Bosworth, Bruce                           
                                                            
          TITLE:  Codes, Ciphers, And Computers              
                 An Introduction to Information Security    
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Hayden Book Company, Inc.      
          LOCATION OF PUBLISHER: New York                    
          PUBLICATION DATE: 1983                             
          CATEGORY:  General Security                        
         COST: $14.95                                       
         DESCRIPTION: This book presents the fundamentals   
         of traditional and modern cryptographic techniques.
         It also provides modern techniques for the highest 
         levels of security for data and information.       

                                                      
          AUTHOR:  Buck, Edward                              
                                                            
          TITLE:  Introduction to Data Security & Controls   
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Q.E.D. Information Sciences    
          LOCATION OF PUBLISHER:  Wellesley, MA              
          PUBLICATION DATE:  1982                            
          CATEGORY: General Security                         
         COST: $24.95                                       
         DESCRIPTION: This book presents the general context
         of data security, including the need for security  
         and the reasons earlier approaches are no          
         longer sufficient. It also gives new methods for   
         dealing with data security.                        

                                                            
          AUTHOR:  Carroll, John M.                          
                                                            
          TITLE:   Computer Security                         
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  Second                                
          NAME OF PUBLISHER: Butterworth Publishers          
          LOCATION OF PUBLISHER:  Stoneham, MA               
          PUBLICATION DATE:  1987                            
          CATEGORY:  General Security                        
         COST:  $32.95                                      
         DESCRIPTION: This book is divided into six sections
         covering threats, security management              
         considerations, physical security, communications  
         security, system security, and threat evaluation.  
      

                                                            
          AUTHOR:  Chantico Technical Management Series      
                                                            
          TITLE:  Security Evaluation For Small Computer     
                 Centers                                    
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Q.E.D. Information Sciences    
          LOCATION OF PUBLISHER:  Wellesley, MA              
          PUBLICATION DATE:  1985                            
          CATEGORY:  General Security                        
         COST:  $24.95                                      
         DESCRIPTION:  This book is concerned with the      
         activities required to review and evaluate the     
         security of small computer centers. It presents all
         the major elements to be considered in a review.   
         
                                                   
          AUTHOR:   Cooper, James Arlin                      
                                                            
          TITLE:   Computer Security Technology              
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO: First                                  
          NAME OF PUBLISHER: Lexington Books                 
          LOCATION OF PUBLISHER: Lexington, MA               
          PUBLICATION DATE:  1984                            
          CATEGORY:  General Security                        
         COST:   $35.00                                     
         DESCRIPTION:                                       

                                                          
          AUTHOR:  Gallery, Shari Mendelson, ed.             
                                                            
          TITLE:   Computer Security:  Readings from         
         "Security Management" Magazine                     
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO: First                                  
          NAME OF PUBLISHER:  Butterworth Publishers         
          LOCATION OF PUBLISHER:  Stoneham, MA               
          PUBLICATION DATE:  1987                            
          CATEGORY:  General Security                        
         COST:  $24.95                                      
         DESCRIPTION:  An assortment of readings concerning 
         a wide variety of computer security areas from     
         "Security Management" magazine.                    
          
                                                            
          AUTHOR:  Fisher, Royal P.                          
                                                            
          TITLE:  Information Systems Security               
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
         NAME OF PUBLISHER:   Prentice-Hall, Inc.           
          LOCATION OF PUBLISHER: Englewood Cliffs, NJ        
          PUBLICATION DATE: 1984                             
          CATEGORY:  General Security                        
         COST: $24.95                                       
         DESCRIPTION: This book not only focuses on the role
         of management in computer security, but it also    
         looks at practical ways of strengthening security  
         in information systems.                            
                 

                                                            
          AUTHOR:  Landreth, Bill                            
                                                            
          TITLE:  Out of The Inner Circle                    
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Microsoft Press                
          LOCATION OF PUBLISHER:  Bellevue, Washington       
          PUBLICATION DATE:  1985                            
          CATEGORY:  General Security                        
         COST: $9.95                                        
         DESCRIPTION:  This book examines a wide variety of 
         computer hackers' approaches and techniques.       
         Provides a security checklist identifying the      
         security loopholes exploited by hackers today.     

                                                       
          AUTHOR:  Leiss, Ernst L.                           
                                                            
          TITLE:  Principles of Data Security                
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Plenum Press                   
          LOCATION OF PUBLISHER:  New York, NY               
          PUBLICATION DATE:  1982                            
          CATEGORY:  General Security                        
         COST:  $32.50  plus $1.50 for shipping.            
         DESCRIPTION: This book presents a comprehensive    
         study of security for computers and their data     
         bases. Authorization mechanisms and cryptography   
         systems are explained in detail.                   
                      
                                                            
          AUTHOR:  Martin, James                             
                                                            
          TITLE:  Security, Accuracy, And Privacy In         
                 Computer Systems                           
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Prentice-Hall, Inc.            
          LOCATION OF PUBLISHER:  Englewood Cliffs, NJ       
          PUBLICATION DATE:  1973                            
          CATEGORY:  General Security                        
         COST:   $65.00                                     
         DESCRIPTION: This book provides a codification of  
         information on computer accuracy, security, and    
         privacy.                                           

                                                  
          AUTHOR:  Norman, Adrien                            
                                                            
          TITLE:  Computer Insecurity                        
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO: First                                  
          NAME OF PUBLISHER:  Methuen, Inc.                  
          LOCATION OF PUBLISHER:  New York, NY               
          PUBLICATION DATE:  1985                            
          CATEGORY:  General Security                        
         COST:  $16.95                                      
         DESCRIPTION: This book presents actual cases of     
         computer security breaches.                        
                      
                                                          
          AUTHOR:  Schweitzer, James A.                      
                                                            
          TITLE:   Computers, Business, and Security:  The   
                  New Role for Security                     
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Butterworth Publishers         
          LOCATION OF PUBLISHER:  Stoneham, MA               
          PUBLICATION DATE:  1987                            
          CATEGORY:  General Security                        
         COST:  $24.95                                      
         DESCRIPTION:  This book covers the essentials of   
         establishing a secure work environment including   
         implementing a security program.                   
                     
                                                       
          AUTHOR: Turn, Rein, ed.                            
                                                            
          TITLE:  Advances in Computer Systems Security      
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER: Artech House, Inc.              
          LOCATION OF PUBLISHER:  Dedham, MA                 
          PUBLICATION DATE:  1984                            
          CATEGORY:  General Security                        
         COST: $44.00                                       
         DESCRIPTION:  This book contains a variety of      
         articles and technical papers that discuss         
         some aspect of computer security.                  
                   
                                                          
          AUTHOR:  Wood, Michael B.                          
                                                            
          TITLE:  Introducing Computer Security              
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  John Wiley and Sons, Inc.      
          LOCATION OF PUBLISHER:  Somerset, NJ               
          PUBLICATION DATE: 1982                             
          CATEGORY:  General Security                        
         COST:  $18.60                                      
         DESCRIPTION: This book stresses that an effective   
         security program needs to be incorporated into an  
         organization. Written with the non-specialist in   
         mind, it covers both intentional and accidental    
         threats, which can affect computer systems.        
           

                     MICROCOMPUTER SECURITY

                                                            
          AUTHOR:  Carroll, John M.                          
                                                            
          TITLE:  Managing Risk: A Computer-Aided Strategy   
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Butterworth Publishers         
          LOCATION OF PUBLISHER:  Stoneham, MA               
          PUBLICATION DATE:  1984                            
          CATEGORY:  Risk Management                         
         COST: $24.95                                       
         DESCRIPTION:  This book is a "how to" manual on    
         quantifing risk management using your  computer    
         as an active tool in accessing and reducing loss.  
   
                                                            
          AUTHOR:  Cronin, Daniel J.                         
                                                            
          TITLE:  Microcomputer Data Security:  Issues and   
                 Strategies                                 
          ORGANIZATION:                                      
          ORDER  NO:  ISBN 0-89303-672-2                     
          EDITION NO: First                                  
          NAME OF PUBLISHER:  Prentice Hall, Inc.            
          LOCATION OF PUBLISHER:  Englewood Cliffs, NJ       
          PUBLICATION DATE: 1986                             
          CATEGORY:  Microcomputer Security                  
         COST:  $18.95 plus $1.50 shipping & handling       
         DESCRIPTION:  This book examines the microcomputer 
         and offers a variety of practical solutions to     
         both hardware and software integrity problems.     
         Deals mainly with IBM and IBM-compatible systems.  
               
                                                            
          AUTHOR:  Hansen, James V. and Romney, Marshell B.  
                                                            
          TITLE:  An Introduction to Microcomputers and      
                 Their Controls                             
          ORGANIZATION:  Institute of Internal Auditors      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Institute of Internal Auditors 
          LOCATION OF PUBLISHER:  Altamonte Springs, FL      
          PUBLICATION DATE:  1985                            
          CATEGORY:  Microcomputer Security                  
         COST:  $33.00                                      
         DESCRIPTION:  This book covers the unique problems 
         that will be found on individual systems and the   
         control strategies to correct these problems. The  
         subjects include principles of control and         
         security, risks and potential losses, and implemen-
         tation of actions.                                 
                     
                                                        
          AUTHOR:  Highland, Harold Joseph                   
                                                            
          TITLE:  Protecting Your Microcomputer System       
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO: First                                  
          NAME OF PUBLISHER:   John Wiley & Sons, Inc.       
          LOCATION OF PUBLISHER:   Somerset, NJ              
          PUBLICATION DATE:  1984                            
          CATEGORY:  Microcomputer Security                  
         COST: $14.95 plus local sales tax.                 
         DESCRIPTION: This book identifies the risks that   
         can destroy a microcomputer system and shows how   
         to safeguard the computer from a variety of hazards
         that threaten the system.                          
                 

                       RISK MANAGEMENT

                                                          
          AUTHOR:  Broder, James F.                          
                                                            
          TITLE:  Risk Analysis And The Security Survey      
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Butterworth Publishers         
          LOCATION OF PUBLISHER:  Stoneham, MA               
          PUBLICATION DATE:  1984                            
          CATEGORY:   Risk Management                        
         COST: $26.95                                       
         DESCRIPTION: This book shows where security        
         allocations may be inadequate, or where resources  
         may be wasted, and how to apply the practical      
         concepts of risk analysis.                         

                       SECURITY MANAGEMENT

                                                           
          AUTHOR:  Parker, Donn B.                           
                                                            
          TITLE:  Computer Security Management               
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO: First                                  
          NAME OF PUBLISHER:  Prentice Hall Publisher        
          LOCATION OF PUBLISHER:  Englewood Cliffs, NJ       
          PUBLICATION DATE:  1981                            
          CATEGORY:  Security Management                     
         COST: $40.00                                       
         DESCRIPTION: A basic text on problems, concepts,   
         theories, and practices in the management of       
         computer security.                                 
       
                                                            
          AUTHOR:  Schweitzer, James A.                      
                                                            
          TITLE:  Managing Information Security:  A Program  
                 for the Electronic Information Age         
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Butterworth Publishers         
          LOCATION OF PUBLISHER:  Stoneham, MA               
          PUBLICATION DATE:  1982                            
          CATEGORY:  Security Management                     
         COST:  $26.95                                      
         DESCRIPTION:  This book surveys the information    
         processing environment and offers proven, tested   
         approaches to effectively safeguard vital          
         electronic information.                            
                  
                                                            
          AUTHOR:  Schweitzer, James A.                      
                                                            
          TITLE:  Protecting Information in the Electronic   
                 Workplace:  A Guide for Managers           
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Reston Publishers              
          LOCATION OF PUBLISHER:  Reston, VA                 
          PUBLICATION DATE:  1983                            
          CATEGORY:  Security Management                     
         COST: $36.00                                       
         DESCRIPTION:  This book gives a structure for      
         information security. It discusses the protection  
         of personal workstations, cases of fraud, and      
         examples of applying security in the computer      
         environment.                                       
                    
                                                            
          AUTHOR:  Talbot, J.R.                              
                                                            
          TITLE:   Management Guide to Computer Security     
                                                            
          ORGANIZATION:                                      
          VOLUME NO:                                         
          EDITION NO:  First                                 
          NAME OF PUBLISHER:  Gower Publishing Co., LTD.     
          LOCATION OF PUBLISHER:  Brookfield, VT             
          PUBLICATION DATE:  1981                            
          CATEGORY:  Security Management                     
         COST: $36.95                                       
         DESCRIPTION:  This book describes a wide range of  
         computer security considerations a manager might   
         want to keep in mind. Risks to installations and   
         steps to prevent damage to computers are covered.  
                                                                                                                         </div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">NCSC-TG-11 
Library No. 5-235,465 
Version 1 
TRUSTED NETWORK INTERPRETATION ENVIRONMENTS GUIDELINE
FOREWORD
The National Computer Security Center is issuing the Trusted Network Interpretation Environments Guideline as part of our Technical Guidelines Program, through which the "Rainbow Series" is produced. The Technical Guidelines Program ensures that the features of the Trusted Computer Systems Evaluation Criteria (DOD 5200.28-STD) are discussed in detail and that guidance is provided for meeting each requirement. The National Computer Security Center, through its Trusted Product Evaluation Program, analyses the security features of commercially produced and supported computer systems. Together, these programs ensure that organisations are capable of protecting their important data with trusted computer systems. 
The Trusted Network Interpretation Environments Guideline is a companion to the Trusted Network Interpretation of the. Trusted Computer System Evaluation Criteria (NCSC-TG-O5), published 31 July 1987. The Trusted Network Interpretation Environments Guideline provides insight into the issues relevant when integrating, operating, and maintaining trusted computer networks. This document identifies the minimum security protection required in different network environments such that network certifiers, integrators, and accreditors can determine what protection mechanisms and assurances are mmimally required in specific network environments. 
This document parallels Computer Security Requirements - Guidance for Applying the Department of Defense Trusted Computer System Evaluation Criteria in Specific Environments (CDC-STD-O3-85) and its technical rationale (CSC-STD-04-85). It also provides a descriptive presentation of the security issues that exist in networked computer systems as the networked computer system environment is inherently more complex and requires additional protection considerations over stand-alone computer systems. 
As the Director, National Computer Security Center, I invite your suggestions for revising this document. We plan to review this document as the need arises. 
PATRICK R. GALLAGHER JR. 1 August 1990 
Director 
National Computer Security Center 
ACKNOWLEDGMENTS
The National Computer Security Center extends special recognition and acknowledgment for their contributions to this document to Dr. Marshall D. Abrams, Renee Child, Annabelle Lee, Dr. Jonathan K. Millen, Samuel I. Schaen, and Dr. Martin W. Schwartz, of The MITRE Corporation, as authors; Richard Wilmer, also of The MITRE Corporation, as technical editor; and to Alfred Arsenault, David Chizmadia, id Rick Siebenaler of the National Computer Security Center, who managed the effort ad participated in the development. 
Special thanks are extended to the many members of the computer security community who enthusiastically gave their time and expertise in reviewing the material and providing valuable comments and suggested changes. Special thanks are extended to James P. Anderson of James P. Anderson Co., Donald L. Brinkley of Gemini Computers, Inc., Dr. Eric Roskos of The Institute for Defense Analysis, Dr. Tien Tao of Gemini Computers, Inc., and Dr. John M. Vasak of The MITRE Corporation for their extensive suggestions and recommendations. 
1 Introduction
This Trusted Network Interpretation (TNI) Environments Guideline (TNIEG) addresses many issues in determining the security protection required in different network environments. It complements the TNI, just as the Trusted Computer System Evaluation Criteria (TCSEC) Environments Guideline [1] complements the TCSEC. The TNI interprets the TCSEC for networks; it contains all of the criteria in the TCSEC, adding interpretation and rationale to applying trust technology to network systems. In the same way that the TCSEC Environments Guideline provides gnidance on applying the TCSEC, this TNIEG provides gnidance on the use of the TNI. The TCSEC and its Environments Guideline constitute the foundation on which the TNI and TNIEG add network applicability. 
1.1 Background
The National Computer Security Center (NCSC) is responsible for establishing and maintaining technical standards and criteria for the evaluation of trusted computer systems. As part of this responsibility, the NCSC is developing guidance on how new security technology should be used. Two objectives of this guidance are: 
 Establishing a metric for categorizing systems according to the security protection they provide, and 
 Identifying the minimum security protection required in different environments. 
The TCSEC [2] helps to satisfy the first objective by categorizing computer systems into hierarchical classes based on evaluation of their security features and assurances. The TCSEC Environments Guideline [1] helps to satisfy the second objective by identifying the minimum classes appropriate for systems in different risk environments. These two documents, however, apply to stand-alone corn puter systems. 
The TNI [3] satisfies the first objective by interpreting the TCSEC for networks. 
The TNI also provides guidance for selecting and specifying other security services (e.g., communications integrity, denial of service, transmission security). The TNIEG is the first step toward addressing the second objective. 
TNI Environments Guideline Introduction 
1.2 Trusted Network Technology Publications
The NCSC has decided to provide guidance concerning security in networks and distributed Automated Information Systems (AISs)1 in a series of publications. The subject area is collectively identified as Trusted Network Technology (TNT). The TNI is the first TNT publication. This TNIEG is the second TNT publication. It contains the best guidance that is available at this time; as technology advances and more experience is gained in implementing trusted networks, more specific guidance will be provided. This TNIEG provides elaboration and clarification on the TNI. Guidance concerning Interconnected AIS which initially appeared in the TNI, Appendix C, has been revised and incorporated into this document (see Section 6 and Appendix A). This document does not address all of the security issues that are excluded from the TNI. Other topics, such as composing a trusted system from evaluated components, will be discussed in future TNT publications. 
1.3 Purpose
The overall purpose of this TNIEG is to assist program managers, integrators, certifiers, and Accreditors with identifying the minimum security protection needed for different trusted computer network environments. For brevity, this audience is referred to as security managers. Not all questions can be answered at this time. The NCSC invites suggestions for topics to be addressed in future TNT publications. 
This guideline is not a tutorial on security and networking; it is assumed that the reader will have some background in both areas. Suggested background references are identified in Appendix B. This guideline is designed to be self contained; a fair amount of background information that can be found in the TNI is also included here. The interested reader may consult the TNI and other documents referenced in this guideline for further detail. 
1.4 Scope
This document describes an environmental assessment process that helps determine the minimum level of trust recommended for a specific network operational environment. The primary focus of this document (and also of the TNI) is on the AIS 1Definitions of terms particularly important to this document are given in Section 2. 
TNI Environments Guideline Introduction 
hardware, firmware, and software aspects of security; therefore, neither this guideline nor the TNI address all the security requirements that may be imposed on a network. Depending on the particular environment, communications security (COMSEC), emanations security (TEMPEST), physical security, personnel security, administrative security, and other information security (INFOSEC) measures or safeguards are also required. This document applies to networks that are entrusted with the processing of information, regardless of whether that information is classified, sensitive, or otherwise relevant to national security. 
1.5 Structure of the Document
Section 2 of this document defines terms and Section 3 discusses Network Security Architecture and Design. Section 4 guides security managers in applying Part I of the TNI; Section 5 does the same for Part II. Section 6 addresses security issues that arise when AIS are interconnected. Appendix A discusses the Cascade Condition in greater detail; Appendix B provides tutorial and background references on network security; and Appendix C discusses encryption and encryption mechanisms. 
2 Terminology
Many of the terms used in the TNI are drawn from diverse specialization areas. 
Their special meaning in context may differ from common English usage. In this section we explain how such terms are used in the TNI and how these definitions have been refined in this document. Terms are printed in boldface when they are defined. 
2.1 Automated Information System
An AIS is defined in DODD 5200.28 as "an assembly of computer hardware, software, and/or firmware configured to collect, create, communicate, compute, disseminate, process, store, and/or control data or information" [4]. This is both a broad definition and a new one, since DODD 5200.28 was published after the TNI. The TNI states that "automatic data processing (ADP) systems, referred to in this [TNI] document as Automated Information System (AIS)...", and equates AIS and ADP. We will use the DODD 5200.28 definition since it is broader and more authoritative. We also note that DODD 5200.28 tends to pluralize AIS as AISs while the TNI considers AIS to be a collective noun. We have followed the latter convention. 
2.2 Network Trusted Computing Base
The Network Trusted Computing Base (NTCB) is the totality of protection mechanisms within a network system2-including hardware, firmware, and software-the combination of which is responsible for enforcing a security policy. The NTCB is the network generalization of the trusted computing base (TCB). An NTCB Partition is the totality of mechanisms within a single network subsystem3 for enforcing the network policy, as allocated to that subsystem; it is the part of the NTCB within a single network subsystem. 
The distinction between a system and a subsystem is a matter of the viewpoint of the ob-server. One observer's system may be another observer's subsystem. For example, the ven-dor of a local area network may regard his product as a system, while the customer's network architect may consider it to be a subsystem along with hosts, workstations, etc. ~e THI uses component in the definition of NTCB Partition. We use subsystem to be con-sistent in this document. 
TNI Environments Guideline Terminology 
2.3 System and Component
The terms system ad component need to be related to each other. 
Unfortunately, the TNI is not completely consistent in its use of these terms. We will first cite the relevant sections from the TNI; then we will reconcile them as used in this guideline. As discussed below, we define the relationship as follows: A component is a physical unit contained within a system. 
2.3.1 TNI Introduction (definition not used in TNIEG)
The TNI Introduction states (emphasis added): 
A network system is the entire collection of hardware, firmware, and software necessary to provide a desired functionality. A component is any part of a system that, taken by itself, provides all or a portion of the total functionality required of a system. A component is recursively defined to be an individual unit, not useful to further subdivide, or a collection of components up to and including the entire system. 
2.3.2 TNI - Appendix A (definition not used in TNIEG)
Appendix A of the TNI presents the view: 
a trusted network represents a composition of trusted components.... The approach to evaluation of a network suggested by this view is to partition the system into components, rate each component to determine its security-relevant characteristics, and then evaluate the composition of the components to arrive at an overall rating class for the network. This approach ... allows for the evaluation of components which in and of themselves do not support all the policies required by the TCSEC, ... contribute[s] to the overall evaluation of any network which uses them and allows for the reuse of the evaluated component in different networks without the need for a re-evaluation of the component. 
Appendix A goes on to state that: 
The set of policy-related features to be supported by the c'omponent need not be the complete set required for a stand-alone system: features not supplied by one component for the system are supplied by another. 
2.3.3 Discussion
We see a difference between the Introduction and Appendix A of the TNI. We 
will use the definition of component as an individual unit that does not provide acomplete set of end-user services. As a consequence, a subsystem can operate on its own and a component will require an external connection to perform a useful function. 
TNI Environments Guideline Terminology 
Appendix C of the TNI uses component, as follows, where we would use subsystem: 
Any AIS that is connected to other AIS must enforce an "Interconnection Rule" that limits the sensitivity levels of information that it may send or receive. Using the component connection view, each component responsible for maintaining the separation of multiple levels of information must decide locally whether or not information ca be sent or received. 
A component may support all the policy and accountability requirements: M, D, I, ad A4; however, as defined above, this is not applicable to determining whether an individual unit is a component. A component which supports some part of the security policy contains an NTCB partition. In the extreme, a component may not have any security-relevant function; in this case it doesn't support any TCSEC policy and doesn't contain an NTCB partition. 
2.3.4 Definitions
To summarize the previous discussions, following are definitions for component ad system/subsystem. 
 Component: An individual physical unit that does not provide a complete set of end-user services. 
 System/suhsystem: A collection of hardware, firmware, and software necessary configured to collect, create, communicate, compute, disseminate, process, store, and/or control data ad information [4]. 
2.4 Evaluation
NCSC-evaluation refers specifically to the process in which the NCSC determines whether a commercial-off-the-shelf (COTS) product satisfies the TCSE~C. Application of the TCSEC to a particular product may be assisted by an interpretation guideline such as the TNI [5]. In such a case, the guideline clarifies the meaing of the TCSEC's language with regard to a particular type of product, but in no case circumvents or grants exception to the requirements of the TCSEC. The purpose of an NCSC-evaluation is as follows: 
4M:datory access control, discretionary access control, identification and authentication, and audit, respectively. 
TNI Environments Guideline Terminology 
The primary goal of the NCSC is to encourage the widespread availability of trusted computer systems. This goal is realized, in large measure, through the NCSC's Commercial Product Evaluation Program. This program is focused on the technical evaluation of the protection capabilities of off-the-shelf, commercially produced and supported systems that meet the computer security needs of government departments and agencies. This product evaluation culminates in the publication of an Evaluated Products List (EPL) report... [6]. 
An NCSC~valuation places a product in one of four divisions: D, C, B, or A. 
Division D is for systems that have been evaluated but fail to meet the requirements for a higher NCSC~valuation rating. Division C has two classes: C1 and C2, which require discretionary (need-to-know) protection. Division B has three classes: B1, B2, and B3, which require support for sensitivity labels and increasing robustness of system architecture. Division A has only class Al, which requires additional assurance through formal verification methods. 
2.5 Certification
Certification is defined as "the technical evaluation of a system's security features, made as part of and in support of the approval/accreditation process, that establishes the extent to which a particular system's design and implementation meet a set of specified security requirements" [7]. In this definition, the word evaluation is used in the generic sense and should not be confused with NCSC valuation. The primary distinction is that certification is an evaluation with respect to specified requirements, ad NCSC~valuation is an evaluation against the TCSEC (and the TNI). 
Certification is conducted in support of the accreditation decision. For most systems, the hardware, system software, applications software, communications equipment, and the operational facility must be configured and tested during certification. Certification should be performed by technical personnel independent of the development organization, according to an acceptable methodology. Certification should identify the level of security protection with regard to a procedure, program, or system. Certification results in the issuance of the Certification Statement, which states whether system security requirements are met, describes all known remaining vulnerabilities, and advises the Accreditor relative to the accreditation decision. If requirements are not met, the Certification Statement lists problem areas and identifies suggested solutions (if known). A certification documentation package, called the Certification Report of Findings, submitted to the Accreditor includes the Certification Statement, certification analysis, resuils of Security Test and Evaluation, id results of Operational Test and Evaluation. 
2.6 Accreditation
Accreditation is "the managerial authorization and approval granted to an ADP system or network to process sensitive data in an operational environment, made on the basis of a certification by designated technical personnel..." [3]. Accreditation is a management decision to operate a system or network employing specific safeguards, against a defined threat, at an acceptable level of risk, under a stated operational concept, with stated interconnections, in a specific operational environment, with a specific security mode of operation. Other terms have been used to identify the formal managerial approval for operation; in this document we use the term Accreditation. FIPS PUB 102 defines Accrediting Officials as "the agency officials who have authority to accept an application's security safeguards and issue an accreditation statement that records that decision. The Accrediting Officials must also possess authority to allocate resources to achieve acceptable security and to remedy security deficiencies" [7]. The ultimate responsibility for system security rests with the Accreditor. DODD 5200.28 employs the term Designated Approving Authority (DAA) to refer to the same officials or officers [4]. 
All AIS must be accredited before they may process or use sensitive or classified information, unless a written waiver is granted by the Accreditor. Accreditation is based on a technical investigation and a formal review of the certification Report of Findings. Before authorizing an AIS to operate, the Accreditor must ensure that satisfactory security measures have been installed and that any residual risk is within acceptable limits. Often, the Accreditor must weigh the technical shortcomings of an AIS against operational necessity. Lacking other ways to accomplish an operational mission, the Accreditor may determine that it is preferable to accept a residual security risk than to preclude the mission. To ensure that the accreditation goals and objectives are adequately met, the Accreditor must be involved throughout the system life cycle. 
2.7 Two Types of Networks
A network may be defined as either an interconnection of accredited AIS or as a Unified Network. When it is not necessary to differentiate in this guideline, the term network is used. 
2.7.1 Unified Networks
The TNI defines a Network Single Trusted System while DODD 5200.28 Enclosure (5) defines a Unified Network; this TNIEG conforms to the latter usage. 
The section of Enclosure (5) that addresses Unified Networks is brief and instructive5: 
Some networks may be accredited as a whole without prior accreditation of their component AIS. It is necessary to treat a network as unified when some of its AIS subsystems are so specialized or dependent on other subsystems of the network for security support that individual accreditation of such subsystems is not possible or meaningful with respect to secure network operation. In order to be accredited, a Unified Network shall possess a coherent network architecture and design, and it should be developed with an attention to security requirements, mechanisms, and assurances commensurate with the range of sensitivity of information for which it is to be accredited. 
The recommended approach for accrediting a Unified Network is to apply Enclosure 4 to the entire network to derive an evaluation class. Requirements to meet that evaluation class then are obtained from an applicable interpretation of DoD 5200.28-STD [the TCSEC], such as NCSC-TG~05 [the TNI]. 
2.7.2 Interconnected Accredited AIS
Enclosure (5) of DODD 5200.28 also discusses Interconnected Accredited AIS: 
If a network consists of previously accredited AIS, a Memorandum of Agreement6 [MOA] is required between the DAA of each DOD Component AIS and the DAA responsible for the network ... The network DAA must ensure that interface restrictions and limitations are observed for connections between DOD Component AIS. ... In particular, connections between accredited AIS must be consistent with the mode of operation of each AIS, the specific sensitivity level or range of sensitivity levels for which each AIS own and a component will require an external connection to perform a useful function is accredited, any additional interface constraints associated with the particular interface device used for the connection, and any other restrictions required by the MOA 
--------------------------- 
5 As mentioned in the introduction and the definitions, this TNIEG differs from DODD 5200.28 and the TNI in the usage of AIS and the definition of component. This quotation has been slightly edited to conform to the usage in this guideline. she content of a Memorandum of Agreement is discussed in Section 3.2 
2.8 Network Security Architecture and Design
Network Security Architecture and Design (NSAD) applies to all networks. The NSAD identifies how the NTCB is partitioned and how the trusted system requirements are met. Security engineering, including the development of the NSAD, is a specialty area within systems engineering. The security engineer is responsible for ensuring that the system being built meets the security requirements of the organization. The security engineer ensures that the AIS security conforms to applicable regulations and policy, and implements the system security requirements [8]. 
The security policy includes the set of laws, rules, and practices that govern how an organization manages, protects, and distributes sensitive information (including classified information). The overall security policy is addressed in a family of related documents consisting of a system security policy, a security policy model, and security requirements. The system security policy is developed first, followed by the other two. A system security policy interprets and applies regulations to systems. The security policy model defines subjects and objects and the accesses between the two. The security requirements document identifies evaluatable user requirements for a secure system. 
The security architecture is that part of the system architecture that describes the required security services and features. The security architecture shows how the required level of assurance for the system is to be met. A mapping of security requirements to functional elements is documented in the security architecture; therefore, the securily architecture is used to document security design decisions. 
2.9 Protocol Layer Approach
This guideline discusses networks in terms of the Open System Interconnection (0SI) reference model [9] because that model provides a well-understood terminology and is used in the TNI. This guideline, however, is independent of the actual protocol reference model used. 
274-353 0 - 90 - 2 : QL 3 
TNI Environments Guideline Terminology 
An NTCB implementation need not include all protocol layers. The precise security services and their granularity will depend on the highest protocol layer at which an NTCB partition is implemented.7 For example, in a Unified Network where layer 3 (the network layer) is the highest layer that implements the NTCB, the network will be able to enforce mandatory access control (MAC) and discretionary access control (DAC) decisions on the granularity of network addresses8. The network system being evaluated knows only about the range of classifications that the host (or other network) is permitted to handle and the hosts (or other networks) that are permitted to communicate with each other. Finer distinctions must be made by the hosts (or other networks) involved. When a trusted network provides all seven layers, the network is aware of and enforces MAC and DAC at the granularity of individual users. 
A network device might not provide a complete set of end-user services through layer 7. Products that do not provide all system services through layer 7 may be NCSC-evaluated as components and subsequently used with other components to compose a network. 
2.10 Part II Security Services
The terms functionality, strength of mechanism, and assurance are used to rate TNI Part II services. Their meanings in that context are described below. 
Functionality refers to the objective and approach of a security service; it includes features, mechanism, and performance. Alternative approaches to achieving the desired functionality may be more suitable in different applications environments. 
Strength of'mechanism refers to how well a specific approach may be expected to achieve its objectives. In some cases the selection of parameters, such as number of bits used in a checksum or the number of permutations used in an encryption algorithm, can significantly affect strength of mechanism. Wiih regard to inadvertent threats, strength refers to the ability to operate correctly during natural disasters, emergencies, operator errors, and accidents. Inadvertent threats are particularly 
7 Since the publication of the TNI, the policy environment has changed. "User", as defined in DODD 5200.28, ad peer.entity, as defined in the 051 reference model, are comparable. Therefore, the TNIEG applies to all layers of the 051 architecture. 
8 A network address refers to either a host or another network. 
TNI Environments Guideline Terminology 
critical to prevention of denial of service. As an example, for communications line outages, strength of mechanism may refer to the number of alternate routes that may be used to bypass the outage. The misdelivery of messages is an example of an inadvertent threat that may disclose information to unauthorized individuals. Encryption can be used to prevent the unintended recipient from seeing the information. 
Assurance refers to a basis for believing that the functionality will be achieved; it includes tamper resistance, verifiability, and resistance against circumvention or bypass. Assurance is generally based on analysis involving theory, testing, software engineering, validation and verification, and related approaches. The analysis may be formal or informal. 
3 Network Security Architecture and Design (NSAD)
Every network should have a Network Security Architecture and Design (NSAD). This section helps the security manager in establishing the NSAD for the network. 
The NSAD, produced as part of the risk management process, documents the security services. As mentioned in Section 1, the primary focus of this TNIEG is on the AIS aspects of security. Depending on the particular environment, communications security (COMSEC), emanations security (TEMPEST), physical security, personnel security, administrative security, and other information security (INFOSEC) measures or safeguards are also incorporated in the NSAD. An NSAD results from a series of tradeoffs among cost, effectiveness, technical risk, mission requirements, and risk management. 
While the architecture part of the NSAD may be somewhat abstract, the design part should be quite concrete. The design maps the selected security services to system functional elements9. Next, these functional elements are assigned to components and subsystems. 
3.1 Composing an NSAD
The security manager is responsible for ensuring that an NSAD is defined that applies to all the components or subsystems that constitute the network. The NSAD for a network must address the applicable security-relevant policies and may incorporate the NSADs of its constituent components or subsystems. In some cases, such as when a component provides part of the functionality of the network (e.g., a local area network (LAN) providing 051 layer three communication services), the NSAD of the component may be incorporated with little or no change into the NSAD for the network. The component NSAD will probably require some modification to address the applicable policy and environment constraints. 
A typical network configuration will include multiple vendor's products. When the network is created, the security manager must reconcile the diverse NSADs of the constituents into a coherent NSAD for the configured network and identify any 
9 Sections 4 and 5 of this document should guide the security manager in selecting those securi-ty services and safeguards that are appropriate for the given operational environment. 
TNI Environments Guideline Network Security Architecture and Design 
restrictions or new security services and assurance that must be added. The NSAD must implement national, service, and command policies for the environment in which the network will operate. The same process applies when previously accredited AIS are to be interconnected to support the exchange of information. 
In contrast to the networks described above, when a network is created from scratch, the NSAD may be established before any devices are selected and may be included as part of the criteria for selecting the network devices. 
Note that the network may include components that are not security-relevant and, therefore, do not have a component NSAD. The design decisions that result in the inclusion of non-security-relevant components are documented in the NSAD. 
AIS may be combined into a network under conditions of a hierarchical relationship of their security managers. In this case the NSAD of the subordinate system must conform to the governing NSAD. For example, when a host computer connects to a common user network, the host computer must conform to the NSAD established by the security manager of the common user network, who has a responsibility to the security managers of all other connected AIS to maintain the network's trustworthiness. As discussed below, this conformance is recorded in a Memorandum of Agreement (MOA). 
AIS whose security managers are not hierarchically related may also be combined to form a network. In this case, the security managers come to agreement on the NSAD for the network; this agreement is also recorded in an MOA. 
3.2 Memorandum of Agreement
If a network consists of previously accredited AIS, a MOA is required between the Accreditors for each subsystem. This MOA is part of the documentation of the NSAD. The MOA discusses the accreditation requirements for each subsystem that is to be interconnected to form the network [4], i.e., defines all the terms and conditions of the security arrangements that will govern the operation of the network [10]. The objective of the MOA is to document the interconnection requirements and identify any requirements that may be necessary to provide overall security safeguards for the entire network. This network includes all the interconnected subsystems, the communications devices, the usei-s, and the data stored in the subsystem 
[10]. A Memorandum of Record (MOR) is used when the subsystems have the same Accreditor. A comprehensive M0A10 could constitute the entire NSAD for a network; alternatively, the MOA could contain high level agreements, with the details spelled out in supporting documents. Following is a list of suggestions for the contents of the MOA and supporting documents. The items towards the top of the list are more likely to occur in the MOA; those towards the end of the list are more likely to occur in supporting documents. 
 A general description of the information that will be transmitted to the network by each subsystem 
 A summary discussion of the trusted behavior that is expected from each subsystem 
 The details of the overall security plan for the network and the assignment of responsibility for producing and accepting the plan 
 A description of the overall network security policy 
 A description of additional security training and assignment of training responsibility 
 Specification of the security parameters that are to be transmitted between communicating subsystems 
 A discussion of security details that are relevant to the exchange of information among the subsystems. 
 A description of the user community, including the lowest clearance of any user who will have access to the network 
 Any special considerations for dial-up connections to any subsystem in the network, including potential security threats and the safeguards that will be used. 
 A description of the security protections provided by the data communications, both local to a subsystem and between communicating subsystem 
________________ 
10 In this guideline, NOA is used to identify the agreement between Accreditors and includes the NOR. 
TNI Environments Guideline Network Security Architecture and Design 
 A description of the information that each subsystem will log in the audit trail, and how the audit trail tasks will be divided among the subsystems 
 A description of the information security services to be offered to the network by each subsystem, including: 
 The types of processing provided by each subsystem, e.g., file query, individual user, general processing 
 The modes of operation of all the subsystems, e.g., dedicated, system high, multilevel 
 The sensitivity levels processed on all subsystems 
4 TNI Part I Security Requirements
This section assists the security manager in determining the recommended minimum security requirements based on TNI Part I and Appendix A, which interprets the TCSEC for networks. 
The procedure for determining the minimum security requirements for a network parallels the procedure for a stand-alone system, whereby the highest classification of data and the lowest clearance among system users are used in computing a risk index. The risk index is used to determine which NCSC~vaIuation rating is required of the system to provide adequate security. To emphasize, these are the minimum requirements. The TCSEC Environments Guideline does not address environmental factors such as the number of users and the percentage of users at different classification levels. These factors may become more significant in a network environment. Communications security risk in a network is addressed by the National Security Agency (NSA) and other cognizant organizations and results in a set of recommendations for the appropriate equipment or security procedures. Other factors, such as the number of connections, the physical distance between devices, the number of subsystems, the presence of encryption, and the possible presence of intervening systems between the resources being used and the ultimate user may result in more or less stringent requirements. 
4.1 Risk Management
Risk management is a methodology used to identify, measure, and control events which adversely affect security; it involves cost-benefit analyses to ensure appropriate cost~ffectiveness of security safeguards. A risk management program is mandated by Enclosure (3) of DODD 5200.28. 
The literature on risk management is quite extensive. It is not the ;Purpose of this document to survey the field. The interested reader is referred to FIPS PUB 65 [11]. The literature is constantly growing; a recent high-level introduction to general concepts and terminology can be found in Bell [12] and in the Proceedings of the First Invitational Workshop on Computer Security Risk Management [13]. 
DODD 5200.28 Enclosure (4) mandates the use of a methodology, extracted from 
the TCSEC Environments Guideline, to determine the recommended evaluation class 
TNI Environments Guideline TNI Part I Security Requirements 
(or requirements of an evaluation class) based on a specific environment. Enclosure (5) of the Directive also recommends this method to determine minimum computer-based requirements in a network. This guideline also uses that method. Use of a different method requires prior approval of the Assistant Secretary of Defense (ASD) Command, Control, Communications, and Intelligence (C31). 
DODD 5200.28 Enclosure (4) contains six major steps in the risk assessment procedure. These steps are listed below. DODD 5200.28 Enclosure (4) applies in all steps. 
Step 1. Determine system security mode of operation. 
Step 2. Determine minimum user clearance or authorization rating. 
Step 3. Determine maximum data sensitivity rating. 
Step 4. Determine risk index. 
Step 5. Determine minimum security evaluation class for computer-based controls. 
Step 6. Determine adjustments to computer security evaluation class required. 
An elaboration of step six given in Migues [14], involving a detailed analysis of both environmental and architectural risk factors, is based on Landwehr and Lubbes [15]. It presents a method which incorporates analysis of the applications environment. This analysis includes such factors as whether the system allows programming, or whether it is restricted to a limited set of applications. This more detailed information supports a finer determination of the level of trust required. 
4.2 Determination of Network Risk
To apply the TCSEC Environments Guideline guidance, the security manager must determine the following: 
 minimum clearance or authorization of the network usefs (see Table 1 11), 
TNI Environments Guideline TNI Part I Security Requirements 
Table 1 
Rating Scale for Minimum User Clearance ~m1n) 
Minimum User Clearance               Rmin                                  

Uncleared OR Not Authorized (U)      0                                     

Not Cleared but Authorized Access    1                                     
to Sensitive                                                               

Confidential                                                              

Secret(S)                            3                                     

Top Secret (TS) and/or current       4                                     
Background Investigation (BI)                                              

TS and/or current Special            5                                     
Background Investigation (SBI)                                             

One Category (IC)                    6                                     

Multiple Categories (MC)              7                                    


 maximum sensitivity of data processed by the network (see Table 2) (the TCSEC Environments Guideline distinguishes between an open system and a closed system based on whether application development was done by cleared or uncleared users; the distinction was dropped in DODD 5200.28 and is not used here either). 
The number derived from Table 1 is used for Rmin; the one derived from Table 2 
is used for Rmax. A risk index for the network is calculated using the following formula: 
Risk Index = Rmax - Rmin 
TNI Environments Guideline TNI Part I Security Requirements 
Table 2 
Rating Scale for Maximum Data Sensitivity ffm:) 
Maximum                                                                      
Sensitivity                                                                  
Rating                                                                       
 Maximum Data                                                                
           Rating                                                            

Ratings without     (Rmax)             Sensitivity         (Rmax)            

categories          with categories                                          
                   1,2                                                       

Unclassified U     0                  N/A 3                                  

Not Classified     2                                                         
but    1       N                                                             
with one or more                                                             
Categories                                                                   

Sensitive N                                                                  

Confidential C     3                                                         
    2         C                                                              
with one or more                                                             
Cate ories                                                                   

Secret (S)          4                                                        
 3         S with                                                            
one or more                                                                  
Categones                                                                    

only one Category                                                            
containing S                                                                 

S with two or      5                                                         
more Categories                                                              

containin S                                                                  

Top Secret (TS)     6                                                        
    5 5       TS                                                             
with one or more                                                             
Categories                                                                   

only one Category                                                            
containing S or                                                              
TS                                                                           

TS with two or     7                                                         
more Categories                                                              

containin S or TS                                                            


1 Where the number of categories is large or where a highly sensitive category is involved, a higher rat-ing might be warranted. 
2 The only categories of concern are those for which some users are not authorized access. When counting the number of categories, count all categories regardless of the sensitivity level associated with the data. If a category is associated with more than one sensitivity level, it is only counted at the highest level. Systems in which all data are in the same category are treated as without categories. 
3 Unclassified data by definition may not contain categories. 
4 Examples of N data include financial, proprietary, privacy, and mission-sensitive data. In some situa-tions (e.g., those involving extremely large financial sums or critical mission-sensitive data), a higher rat-ing may be warranted. This table prescribes minimum ratings. 
5 The rating increment between the Secret and Top Secret data sensitivity levels is greater than the in-crement between other adjacent levels. This difference derives from the fact that the loss of Top Secret data causes EXCEPTIONALLY GRAVE damage to U.S. national security, whereas the loss of Secret data causes SERIOUS damage. 
THI Environments Guideline TNI Part I Security Requirements 
Table 3 
Security Risk Index 
Risk Index               Security Mode             Minimum Security Class   
                                                   4                        

0                        Dedicated                 No Minimum Class 1 2     

0                        System High               C2  2                    

1                        Multilevel Partitioned    B1  3                    

2                        Multilevel Partitioned    B2                       

3                        Multilevel                B3                       

4                        Multilevel                A1                       

5                        Multilevel                *                        

6                        Multilevel                *                        

7                        Multilevel                *                        


1 Although there is no prescribed minimum class, the integrity and denial of service requirements of many systems warrant at least class C2 protection. 
2 Automated markings on output must not be relied on to be accurate unless at least class B1 is used. 
3 Where an AI$ handles classified or compartmented data and some users do not have at least a Confi-dential clearance, or when there are more than two types of compartmented information being handled, at least a class B2 is required. 
4 The asterisk (*) indicates that computer protection for environments with that risk index is considered to be beyond the state of current computer security technology. 
5 Most embedded systems and desk top computers operate in the dedicated mode. 
Table 3 12 is used, along with the Risk Index calculated above, to determine a minimum NCSC-evaluation rating for the system. Note that some terms that appear m the TCSEC Environments Guideline are no longer defined in DODD 5200.28. (Limited Access Mode, and Compartmented Mode fall under the heading of Partitioned Mode. Controlled Mode comes under the heading Multilevel. The prevt.ou:ly used terms referred to the equivalent of the BI and B2 evaluation classes. In DODD 5200.28, Partitioned Mode is used in place of Compartmented Mode.) 
____________________ 
12 Table 3 is adapted from the TCSEC Environments Guideline 
5 TNI Part II Security Requirements
This section contains a discussion of TNI Part II which describes qualitative evaluations of security services in terms of functionality, strength of mechanism, and assurance. Part II of the TNI describes additional security concerns and services that arise in conjunction with networks, but that do not normally arise in stand-alone computers. 
Part II of the TNI focuses on those threats that occur between end systems (hosts) on the network. These security services include protection against compromise, denial of service, and unauthorized modification. In discussing these services, the TNI borrows heavily from the International Standards Organization (150) 051 Basic Reference Model [9] and Security Architecture [16]. The services discussed are closely related to those found in the latter reference. The TNI goes beyond the 051 Security Architecture in several respects. First, the 051 document does not address the relative strengths of different mechanisms nor the assurances that they operate as intended. Second, the protection against denial of service threats is not specifically addressed by 051 but is an important consideration in the TNI. 
5.1 Relationship of TNI Part II Services to Part I and Appendix A 
The Part II services are not as well understood as the features in TN1 Part I. The fact that Part 11 services have not been supported by equally well developed theories and detailed evaluation criteria should not be interpreted to imply that their security problems do not have to be evaluated as rigorously as TNI Part I and Appendix A services. Some Part II services may not be part of the NTCB. For example, to make the NTCB as small as possible, some of the protocol software may be outside the NTCB. Therefore, the protocol-based protection against denial of service is likely to be outside the NTCB. Nonetheless, it must rely on some of the fundamental NTCB assurances since the protocols invoke portions of the subsystem's operating system. 
It is important to recognize that many Part II security services depend on (embedded) AIS. These AIS should be evaluated using Part I and Appendix A of the TNI. Encryption systems, for example, are highly dependent upon AIS; they are addressed in Appendix B of the TNI and Appendix C of this guideline. Appendix C presents some considerations concerned with applying Tables 1, 2, and 3 to encryption systems. 
25 
TNI Environments Guideline TNI PartII Security Requirements 
For security services that do not depend strongly on AIS, a qualitative evaluation approach is used. For functionality, a question and answer format is presented in Section 5.4.3. For strength of mechanism and assurance, the concept of a risk index is used in Sections 5.4.1 and 5.4.2. 
5.2 Specification and Evaluation of Security Services
Specifying and evaluating Part II security services is quite different from a TNI Part I evaluation even though both parts are concerned with the same three aspects of security services or capabilities: functionality, strength of mechanism, and assurance. For clarity these terms are defined as follows: Functionality refers to the objective and approach of a security service. Sirength of mechanism refers to how well a specific approach may be expected to achieve its objectives. Assurance refers to a basis for believing that the functionality will be achieved. 
5.3 Evaluation Ratings
Part II evaluations are qualitative, as compared with the hierarchically~rdered ratings (e.g., C1, C2, ...) from the TCSEC. The results of a Part II evaluation for offered services are generally summarized using the terms none, minimum, fair, and good. For some services, functionality is summarized using none or present because gradations are not meaningful. Theterm none is used to mean the security service fails to distinguish the strength of mechanism. The term not offered is used when a security service is not offered. For example, if a certain network did not include non-repudiation as one of its security services, that network would be rated not offered with respect to non-repudiation. Table 4 represents the evaluation structure of PartII as a matrix. It identifies a set of security services. It also shows the possible evaluation ranges for each service in terms of its functionality, strength of mechanism, and assurance. 
5.4 Selecting Security Services
Part II enumerates representative security services that an organization may choose to employ in a specific situation. Not all security services will be equally important for a specific environment, nor will their relative importance be the same 
TNI Environments Guideline TNI Part II Security Requirements 
Table 4 
Evaluation Structure for Network Security Services 
Network Security   Criterion          Evaluation                             
Service                                                                      

Communications     None present                                              
Integrity                                                                    
Functionality                                                                

Authentication     None               good                                   
Strength                                                                     

Assurance          None               good                                   

Communications     None               good                                   
Field Integrity                                                              
Functionality                                                                

Strength                              None                good               

Assurance          None               good                                   

Non-repudiation    None               present                                
Functionality                                                                

Strength            Denial of         None                good               
                   Service                                                   

Continuity of      None               good                                   
Operations                                                                   
Functionality                                                                

Strength                              None                good               

Assurance          None               good                                   

Protocol Based     None               good                                   
Protection                                                                   
Functionality                                                                

Strength           None               good                                   

Assurance          None               good                                   

Network            None               present                                
Management                                                                   
"Functionality                                                               

Strength           None               good                                   

Compromise         None               present                                
Protection Data                                                              
Confidentiality                                                              
Functionality                                                                

Strength                                                                     
Sensitivity level                                                            

Assurance          None               good                                   

Traffic Flow       None               present                                
Confidentiality                                                              
Functionality                                                                

Strength           Sensitivity        level                                  

Assurance          None               good                                   

Selective Routing  None               present                                
Functionality                                                                

Strength           None               good                                   

Assurance          None               good                                   


among different environments. Selecting security services is a management decision, with assistance provided by this guideline. 
Ordinarily, the security manager would first determine whether a particular service is required and what functionality is needed (if there are distinctions) through a series of questions provided in Section 5.4.3. A separate set of questions is provided for each service shown in Table 4. 
Once the functionality has been determined, the strength of mechanism and appropriate level of assurance must be determined. The process is similar to the determination of Part I risk in Section 4 of this guideline. Since the strength of mechanism and assurance determination do not differ for the various services, these topics are addressed first. 
5.4.1 Strength of Mechanism
Determination of strength of mechanism for each service has two components. The inadvertent threat and the malicious threat should be analyzed separately. In many cases, the malicious threat will dominate the inadvertent threat; malicious users can often duplicate the circumstances of an inadvertent threat. The required strength of mechanism is determined using a risk index similar to that used in PartI. 
For inadvertent threats, traditional risk management techniques are used. While some countermeasures may be the same for inadvertent and malicious threats, others may be effective only against the former. The security manager must determine the likelihood of a particular threat, the dollar cost of a countermeasure, and the residual risk if the countermeasure is put into effect. The manager concerned with these inadvertent threats is referred to the references on risk assessment previously cited. 
For malicious threats, we consider the most sensitive information contained on the system and the lowest clearance of user who can gain physical access to some device in the system, including access to wireless transmissions. Some devices in the system may be physically protected in buildings that require a clearance for admittance. Other devices in the system, such as long-haul transmission lines, may have no physical protection. 
Protection of the information in the network system is a combination of physical, administrative, procedural, and technical protections. The TNIlis concerned only with the AIS hardware, firmware, software, and configuration management protections. Various service or agency regulations describe methods for implementing the other protections. 
The various devices in the system must be considered separately; for each device, 
the risk index will be based on the most sensitive information on the network system and the minimum clearance to gain physical access to the device. Note that this is 
different from the Part I risk index calculation (where the lowest cleared user is of concern). For some devices in the system (e.g., the communications media), the clearance of individuals with physical access may be lower than that for authorized users. For convenience, all the necessary tables are included here. Table 5, Minimum Clearance for Physical Access, is identical to Table 1. For each device in the system, the lowest clearance of individuals with physical access to that device is used. Table 6 for Maximum Data Sensitivity is identical to Table 2. 
Table 5 
Minimum Clearance for Physical Access 
Minimum User Clearance               Rmin                                  

                                                                           

Uncleared OR Not Authorized (U)       0                                    

Not Cleared but Authorized Access     1                                    
to Sensitive                                                               

Unclassified Information (N)                                               

Confidential                        2                                     

Secret (S)                            3                                    

Top Secret (TS) and/or current       4                                     
Background                                                                 

Investigation (BI)                                                         

TS and/or current Special            5                                     
Background                                                                 

Investigation (SBI)                                                        

One Category (IC)                     6                                    

Multiple `Categories (MC)             7                                    

                                                                           


Table 6 
Maximum Data Sensitivity 
Maximum Sensitivity Rating Maximum Data Rating 
Ratings without (Rmax) Sensitivity (Rmax) 
Categories with Categoriesi,1 2 
Unclassified U 0 N/A 3 
Not Classified but 1 N with one or more Categories 2 
Sensitive N 4 
Confidential C 2 C with one or more Cate ories 3 
Secret (S) 3 5 with one or more Categories 4 
only one Category containing 5 
S with two or more Categories 5 
containin S 
Top Secret (TS) 5 5 TS with one or more Categories 6 
only one Category containing 5 or TS 
T5 with two or more Categories 7 
containin S or TS 
1 Where the number of categories is large or where a highly sensitive category is involved, a higher rat-ing might be warranted. 
2 The only categories of concern are those for which some users are not authorized access. When counting the number of categories, count all categories regardless of the sensitivity level associated with the data. If a category is associated with more than one sensitivity level, it is only counted at the highest level. Systems in which all data are in the same category are treated as without categories. 
3 Unclassified data by definition may not contam categories. 
4 Examples of N data include financial, proprietary, privacy, and mission-sensitive data. In some situa-tions (e.g., those involving extremely large financial sums or critical mission-sensitive data), a higher rat-ing may be warranted. This table prescribes minimum ratings. 
5 The rating increment between the Secret and Top Secret data sensitivity l~els is greater than the in-crement between other adjacent levels. This difference derives from the fact that the loss of Top Secret data causes EXCEPTIONALLY GRAVE damage to U.S. national security, whereas the loss of Secret data causes SERIOUS damage. 
Table 7 now gives the strength of mechanism requirement based on the risk index 
calculated as 
Risk Index = Rmax - Rmin 
Table 7 
Minimum Strength of Mechanism Requirement 
Risk Strength of 
 None 
1 Minimum 
2 Fair 
>2 Good 
5.4.2 Assurance
Assurance is a very important concept in the TCSEC and TNI. This section discusses the need for assurance and the ways in which it may be achieved. 
One salient property of trusted systems is the reliance on a TCB. Similarly, trusted network systems rely on an NTCB. In addition to its other responsibilities, the NTCB prevents unauthorized modification to objects within the network system. In particular, the NTCB maintains the integrity of the programs which provide security services, thus ensuring that their assurance is continued. The NTCB provides an execution environment that is extremely valuable in enhancing the assurance of security services. Discretionary and mandatory access controls can be employed to segregate unrelated services. Thus, service implementation that is complex and error-prone or obtained from an unevaluated supplier can be prevented from degrading the assurance of other services implemented in the same device. Furthermore, an NTcB ensures that the basic protection of the security and integrity information entrusted to the network is not diluted by various supporting security services. 
The relationship of the risk index to the required assurance is expressed in Table 8. 
TNI Environments Guideline TNI PartII Security Requirements 
Table 8 
Minimum Assurance Requirements 
Risk Part II 
Index Assurance Rating 
 None 
1 Minimum 
2 Fair 
>2 Good 
Assurance of the design and implementation of PartII mechanisms is also related to the assurance requirements in Part I because service integrity depends on protection by the NTCB or TCBs. Table 9 expresses this dependency. The second column identifies the minimum Part I evaluation which supports the Part II assurance requirement. Note that Table 9 is applicable only to those PartII services not strongly dependent on AIS; the AIS implementing those services can be directly evaluated under PartI and Appendix A of the TNI. 
Note that the Evaluation Class calculation in Part I will not necessarily be the same as the Minimum Part I Evaluation in Table 9. This is because the Rmin for Part II may be different from that of Part I since the Part II protections are oriented towards outsiders (those with physical access) rather than towards users. Depending on the particular environment, either the Part I requirement or the Part II requirement may dominate. The latter would be the case if a system were operated in the system high mode-where all users were cleared to see the most sensitive information-but the network was exposed to lower clearance individuals. 
5.4.3 Functionality
This section asks questions about each of the security servi'ces contained in PartII of the TNI. These questions are designed to help the security manager identify the functionality required for each security service. The questions should be answered in sequence, unless the answer to one question contains an instruction to skip ahead. 
Authentication 
1. Is there a requirement to determine what individual, process or device is at the other end of a network communication? If yes, document this requirement. 
Table 9 
Part II Assurance Rating 
PartII                                Minimum PartI                        

Assurance Rating                     Evaluation                            

Minimum                              CI                                    

Fair                                 C2                                    

Good                                 B2                                    


If no, skip to Communications Field Integrity. 
2. Do you have a requirement to identify and authenticate the specific hardware device at the distant end-point involved in the network communication? If yes, then you have a functionality requirement for authentication. This functionality may be implemented at one or more protocol layer. For example, a specific control character, ENQ (enquiry or who-are-you) may be used to return immediately a stored terminal identifier. 
3. Do you have a requirement to identify and authenticate the location of the hardware at the distant end-point or in any intermediate system involved in the network communication? 
If yes, then you have a functionality requirement for authentication at protocol layer 2, the Link Layer or layer 3, the Network Layer. 
4. Do you have a requirement to identify and authenticate the specific operating system or control program at the distant end-point or in any intermediate system involved in the network communication? 
If yes, then you have a functionality requirement for authentication at protocol layer 4, the Transport Layer. 
5. Do you have a requirement to identify and authenticate the subject (process/domain pair) at the distant end-point involved in the network communication? 
If yes, then you have a functionality requirement for authentication at protocol layer 4 or above. 
6. Do you have a requirement to identify ad authenticate the application or user at the distant end-point involved in the network communication? If yes, then you have a functionality requirement for authentication above protocol layer 7, the Applications Layer. The Applications Layer provides an interface to the application. Authentication information may pass over this interface. Authentication of a user is addressed in Part I of the TNI. Application process authentication is outside the scope of the 05I Security Architecture, but does fall within the scope of TNI PartII Security Services. Have you chosen to use some mechanism other than encryption to provide authentication? If so, your strength of mechanism is shown in Table 7. If your authentication mechanism is encryption based, see the appropriate encryption authority (e.g., NSA). Even if encryption is used, some supporting processes may need to satisfy the strength of mechanism shown in Table 7 (depending on the architecture). For example, a database that relates encryption keys to specific users may need to be trusted. 
Communications Field Integrity 
1. Do you have a requirement to protect communication against unauthorized modification? If no, skip to Non-Repudiation. 
2. Are your protection requirements the same for all parts of the information communicated? 
If no, then you should identify the separate parts and answer the rest of the questions in this section separately for each part. Each part is known as a field. 
There are two major fields: protocol-information, whherein the network is informed of the destination of the information and any special services required; and user-rlata. Not every protocol data unit (PDU) contains user-data, but protocol-information is necessary. Each of these fields may be divided into additional fields; depending on your application, protection requirements for fields may differ. 
3. Do you have a requirement for detecting unauthorized modification to part or allofaPDU? 
If yes, you have a requirement for at least minimum functionality. 
4. Do you have a requirement for detecting any of the following forms of message stream modification: insertion, deletion, or replay? 
If yes, you have a requirement for at least fair functionality. In addition, your functionality must be incorporated in a connection oriented protocol. 
5. Do you require that, if message stream modification is detected, recovery (correction) should be attempted? 
If yes, you have a requirement for good functionality. In addition, you must implement integrity in a reliable transport (layer 4) mechanism. 
Non-repudiation 
1. Do you have a requirement to be able to prove (to a third party) that a specific message transfer actually occurred? If no, skip to Denial of Service. 
2. Do you have a requirement for proving that a specific message was sent? 
Specific message means that the identity of the subject sending the message, the host computer and/or mail agent/server, time and date, and contents are all uniquely and unalterably identified. 
If yes, then you have a functionality requirement for non-repudiation with proof of origin. 
3. Do you have a requirement for proving that a specific message was received? 
Specific message means that the identity of the subject to which the message was delivered, the host computer and/or mail agent/server, time and date, and contents are all uniquely and unalterably identified. 
If yes, then you have a functionality requirement for non-repudiation with proof of delivery. 
Denial of Service 
1. Do you have a requirement to assure the availability of communications service or to determine when a Denial of Service (DOS) condition exists? A DOS condition is defined to exist whenever throughput falls below a pre~stablished threshold, or when access to a remote entity is unavailable, or when resources are not available to users on an equitable basis. For a DOS condition to occur, the user must have priority to access the system or resources. If no, skip to Data Confidentiality. 
2. Do you have a requirement to detect conditions that would degrade service below a pre-selected minimum and to report such degradation to the network operators? 
If yes, you have a requirement for at least minimum denial of service functionality. 
3. Could failure of the system to operate for several minutes lead to personal injury or large financial loss? 
If yes, you have a requirement for at least fair denial of service functionality. 
4. Do you have a requirement for service resiliency that would continue-perhaps in a degraded or prioritized mode-in the event of equipment failure and/or unauthorized actions? 
If yes, you have a requirement for at least fair denial of service functionality. 
5. Could failure of your system to operate for several minutes lead to loss of life? 
If yes, you have a requirement for good denial of service functionality. 
6. Do you have a requirement for automatic adaptation upon detection of a denial~fservice condition? 
If yes, you have a requirement for good denial of service functionality. 
Protocol Based DOS Protection 
1. Do you want advanced knowledge of unavailability of service? 
If no, skip to Network Management. 
If yes, do you want to implement alternatives? 
If yes, you should employ this alternative basis and skip to Network Management. 
2. In general, ordinary protocol mechanisms don't provide protection against malicious attacks or bizarre errors. Do you have a requirement to detect a DOS condition which cannot be met by the protocols used as part of normal communications? 
If no, you do not have a functional requirement for protocol-based DOS protection and should skip to Network Management. 
3. The TNI suggests the following protocol-based mechanisms: 
a. Measure the transmission rate between peer entities under conditions of input queuing, and compare the measured transmission rate with a rate previously identified as the minimum acceptable; 
b. Employ a request-response polling mechanism, such as "are-you-there" and "here-I-am" messages, to verify that an open path exists between peer entities. 
If you have identified any additional mechanisms, include them in your list of required mechanisms. 
Network Management 
1. Do you have a requirement for (at least) detecting a denial of service condition that affects more than a single instance of communication or attempted communication? 
If no, skip to Data Confidentiality. 
If yes, you have a functional requirement for network management denial of service protection. 
Data Confidentiality 
1. Do you have a requirement to protect any part of transmitted data from disclosure to unauthorized persons? If no, skip to Traffic Flow Confidentiality. 
2. Is your requirement for confidentiality limited to selected field of user~ata within a PDU? 
If no, then you require confidentiality for the entire data portion of each PDU. 
Continue with Traffic Flow Confidentiality. 
3. Is there a reason to encrypt only selected fields (e.g., cost savings, legal requirements)? 
If yes, you require selected field confidentiality. If no, you require full confidentiality on the data portion of each PDU. 
Traffic Flow Confidentiality 
1. Do you have a requirement to prevent analysis of message length, frequency, ad protocol components (such as addresses) to prevent information disclosure through inference (traffic analysis)? 
If no, skip to Selective Routing. 
If yes, you have a functional requirement for traffic flow confidentiality. 
Selective Routing 
1. Do you have a requirement to choose or avoid specific networks, links, relays, or other devices for any reason at any time? 
If yes, you have a functional requirement for selective routing. 
6 Interconnecting AIS
The definition of Interconnected Accredited AIS recognizes that parts of a network may be independently created, managed, and accredited. AIS in different security domains 13 generally operate under different security policies, consequently, it is difficult to combine them into a Unified Network. For example, AIS operated by the U.S. DOD and NATO cannot be combined into a Unified Network, since they enforce different policies and do not have a common authority. 
Interconnecting systems that support different security domains (e.g., classified, sensitive unclassified) adds additional complexity. Exchange of information among these different security domains requires identification of the markings and protection given to information when transmitted to another domain. For example, several evolving approaches to the protection of sensitive unclassified information [17] consider "that sensitive information is not part of the same hierarchy as classified information". 
There are technical criteria for judging the trustworthiness of Interconnected Accredited AIS: an Interconnection Rule, which ensures that information conveyed between subsystems is labeled properly, and risk factors such as propagation of local risk and the cascading problem. These criteria are examined in some detail below. 
6.1 Agreement Between Accreditors
Interconnection of AIS between security domains requires a documented agreement identifying the interconnection requirements and all safeguards. This agreement will have many similarities to the MOA discussed in Section 3.2. It will probably have to reconcile different security policies and philosophies of protection, identifying the conditions under which specified classes of information can be exchanged among domains. In addition to the information included in> the MOA, this agreement between managers of different security domains should address the mappings of policy and countermeasures between the domains. In many ways this agreement takes on the character of an NSAD for the agreed upon information exchange between domains. 
________________________ 
13 A security domain is a collection of A[$ under the control of a single administrator that en-forces or operates under a specified policy. There can be sub-domains, (e.g., Army and Air Force are sub-domains under the Department of Defense.) 
6.1.1 Accreditation Range
An accreditation designates a system's mode of operation and range of data sensitivity' levels. The accreditation range reflects the Accreditor's judgment on the subsystem's ability to exchange information within an acceptable level of risk, with respect to its network connections, and in accord with the designated sensitivity levels. 
The range must be a single level in the case of a system high or dedicated device14. 
If the accreditation range comprises more than a single level, the system is trusted to reliably segregate data by level within its accreditation range, and label it accurately for transmission over multilevel interfaces. The accreditation range will be specified in the MOA. The accreditation range is used in determining whether communication between systems is permitted. 
Figure 1 
Information Levels and Accreditation Ranges 
TS
S-C S 
C 
C2 Evaluation Class B3 
S Accreditation Range TS-C 
SH Operating Mode MLS 
As shown in Figure 1, an AIS may contain information at levels that are below its accreditation range. For example, a C2 host which contsuns Secret (S) and Confidential  information, is not trusted to segregate this confidential and Secret information. Therefore, it is accredited to operate in system high (SH) mode at Secret (the highest sensitivity level of information on the system), and its accreditation range is the single level Secret. All exported information must be labeled with the system high sensitivity label until there is a manual review to assign the information a lower 14 Often in the discussion it is not appropriate to distinguish between a component and a sub-system; in that case we use the term device. 
classification level. In contrast, a B3 multilevel secure (MLS) host, which contains Top Secret (TS), Secret, and Confidential information could be assigned an accreditation range equal to the entire set of levels processed. In this case, the label of the exported data is equal to the actual level of the exported data, unless unclassified data is to be exported. 
Figure 2 illustrates the accreditation ranges of two interconnected subsystems. 
Although Subsystem Y is able to separate its three levels of information, it may exchange information with Subsystem X only at the S and C levels. 
Figure 2 
Accreditation Ranges of Two Interconnected Sub systems 
Subsystem X Subsystem Y 
TS
S ------------------------------- S 
C ------------------------------- C 
Class B1 Class B3 
In a network, an accreditation range bounds the sensitivity levels of information that may be sent (exported) to or received (imported) from each interconnected subsystem15. For example, if a network consists of only dedicated and system high subsystems, each subsystem will be assigned single-valued accreditation ranges (i.e., an accreditation range consisting of one sensitivity level). 
When the same communications channel processes information at;different levels, the data must be labeled through some protocol agreed upon by the communicating systems. 
______________ 
15 Note that information exported or imported to a subsystem having a single-level accredita-tion range is implicillylabeled at that level. It is also possible for a subsystem with a mul-tilevel accreditation range to employ network interface devices with single-level ports, in which case the data transferred over such ports is also implicitly labeled. 
DODD 5200.28 Enclosure (5) also addresses AI5 that have not been accredited: 
Untrusted, unaccredited AIS ... may be components of a network.... Only unclassified information, which does not include sensitive unclassified information, may be sent to ad from untrvsted, unaccredited AIS. 
This trvst requirement is satisfied by restricting the accreditation rage of the untrusted, unaccredited AIS to Unclassified (U). 
6.1.2 Device Range
A network subsystem is typically connected to another subsystem through some kind of 1/0 network interface or device (see Figures 3~) ad the same device may provide connection to multiple subsystems. 
Although a 1/0 device is part of a subsystem, it may be designated to process a more restricted set of sensitivity levels than the accreditation rage of the subsystem as a whole. This leads to the concept of a device range. Each 1/0 device in a subsystem that is used to communicate with other subsystems in the network must have a device rage. The device rage may be single level, or it may be a set of levels (in which case the device is referred to as multilevel), and it must be included within the subsystem accreditation range. The TCSEC states that "systems that have been evaluated at classes B2 ad above must support minimum ad maximum security labels for all multilevel 1/0 devices". The purpose of device labels is to document the constraints placed on the security levels of information authorized for the devices. 
Each physically attached multilevel system (if any) has a minimum ad maximum sensitivity level associated with it. A B1 or higher system interconnected to a second system must ensure that both imported and exported information is contained within appropriate sensitivity levels. 
6.1.3 Information Transfer Restrictions
The following points summarize the discussion on the restrictions imposed on information transfer between interconnected devices. 
Information exported or imported using a single-level device is labeled implicitly by the security level of the device. As shown in Figure 3, any information transferred between the single-level (S) devices on Subsystems X and Y is implicitly labeled S. 
Figure 3 
Implicit Labeling 
Subsystem X Subsystem Y 
Information exported from one multilevel device and imported at another multilevel device must be labeled through an agreed-upon protocol, unless it is labeled implicitly by using a communications link that always carries a single level. For instance, in Figure 4, Secret and Confidential information may be transferred between the multilevel devices. 
Figure 4 
Protocol Labeling 
Subsystem X Subsystem Y 
Figure5 
Compatibility Labeling 
Subsystem X Subsystem Y 
Information exported at a given security level can be sent only to a importing device whose device rage contains that level or a higher level. In Figure 5, Subsystem X is allowed to export only Secret information to Subsystem Y's multilevel device. Subsystem Y is allowed to export Secret ad Confidential information to Subsystem X, because the device rage Subsystem X is TS-S. If the importing device rage dominates the exported level, the information is implicitly or explicitly relabeled upon receipt at a higher level within the importing device range. 
Figure 6 
Relabeling 
Subsystem X Subsystem Y 
In Figure 6, Subsystem Y relabels information imported from Subsystem X. The information transfer restrictions also permit one-way communication (i.e., no acknowledgments) from one device to aother whose rages have no level in common, as long as each level in the sending device rage is dominated by some level in the receiving device rage. It is never permitted to send information at a given level to a device whose rage does not contain a dominating level. 
In most interconnected subsystems, the bidirectional flow of information is permitted. In this environment, the sensitivity level of any transmitted message must be within the accreditation range of both the sending and receiving systems. In some networks, an additional restriction on information flow may be unidirectional communications. This restriction may enhance security. The following discussions refer to Figure 7. 
Figure 7 
Bidirectional and Unidirectional Information Flow 
Subsystem X Subsystem Y 
TS (C or U) C 
U
SH (TS) Subsystem Z  MLS (C-U) 
TS 
S 
C 
MLS (TS-C) 
The system high mode is usually assigned to AIS that are unevaluated or are NCSC~valuated in class C. These AIS do not employ explicit labels because they cannot be trusted to differentiate between sensitivity levels. All information within these AIS is implicitly labeled. When exported on a single level channel, by default the information is labeled implicitly by the level of the channel. Human-readable output must be labeled at the system high level; it may be manually downgraded by an authorized reviewer. 
Explicit labels are required on a multilevel channel. In order to export explicit labels, Subsystem X would normally be expected to be NCSC-evaluated at BI or above, or employ an 1/0 device, such as those shown in Figure 6, NCSC~valuated at BI or above. Also, Subsystem X or the 1/0 device should be used as specified in Section 4 of this guideline. Lacking such NCSC~valuation, the MOA between the Accreditors would have to specifically address these labels. 
Subsystem X can import a message from Subsystem Y, but cannot acknowledge receipt of that message, because an exported acknowledgment (labeled TS) cannot be imported by Subsystem Y, which can only receive C or U information. Transmitting an acknowledgment from Subsystem X to Subsystem Y would constitute a write-down (i.e., writing information at a lower sensitivity level-generally a security violation.) 
Subsystems Y and Z can exchange information at C since this level is in the accreditation range of each subsystem. When only unidirectional communication (no acknowledgment) is utilized between two subsystems, write up is permitted if each sensitivity level in the source subsystem is dominated by a sensitivity level in the destination subsystem. The receiving subsystem must change the sensitivity level of the message when the message is received. For instance, U information sent from Subsystem Y will be labeled C by Subsystem Z. 
6.2 Interconnection Rule
The Interconnection Rule states that each device in the network must be separately accredited to operate in an approved security mode of operation and with a specific accreditation range. The device is accredited to participate in the network at those levels and only those levels. This means that information exported at a given sensitivity level can be sent only to an importing device whose accreditation range contains that level or a higher level. Information is relabeled, implicitly or explicitly, upon reception at a higher level within the importing device accreditation range only if the original level is not in that range. 
According to the Interconnection Rule, a multilevel network may contain devices with different operating modes: dedicated, system high, partitioned, and multilevel. Also the devices may differ in the sensitivity levels and categories which they process, and the formal access approvals of their users (some users may not have access to all information). 
Figure 7 illustrates the flexibility of the Interconnection Rule. For example, the interconnection Rule will allow, with certain restrictions, a multilevel subsystem to communicate with a single-level subsystem and with another multilevel subsystem (and 
the two MLS subsystems may have different accreditation ranges). It also allows for one-way communication to a higher-level system. It is intended to be a non-restricting rule and yet ensure that each system receives only information that it can properly mark and handle. Interconnection in the context of the Interconnection Rule means only direct connections, that is, without any intermediate accredited subsystem. 
The Interconnection Rule alone does not guarantee that classified information will not be exposed to greater risks in a network than in a stand-alone environment. One problem in networks that is dealt with at some length below is the cascading problem. 
Figure 8 
A Complex Interconnection 
Subsystem X Subsystem Y 
6.2.1 A Complex Example
The Interconnection Rule and device range allow for some rather challenging situations. Consider, for example, the connection depicted in Figure 8. The system on the left processes TS information of two types: categories A and P (where P is the union of categories C and D, P = C U D). The system on the right processes the categories C and Q (where Q is the union of categories A and B, Q = A U B). The two devices have no sensitivity levels in common. Yet this is a legitimate connection as long as only TS ,A and TS ,C information is transferred. Any information sent must be relabeled upon receipt. Information in category A is relabeled Q when received on the right, ad information in category C is relabeled P when received on the left 6.3 Risk Factors 
There are two global considerations that affect the interconnection of systems. 
The first is called propagation of local risk and the second is the cascading problem. Before discussing these considerations, the concepts of subsystem connection view and global network view need to be introduced. 
As discussed in the previous section, any subsystem that is connected to other subsystems must enforce the Interconnection Rule. Using the subsystem connection 
view, each subsystem responsible for maintaining the separation of multiple levels of information must decide locally whether or not information can be sent or received. This view, then, does not require a subsystem to know the accreditation ranges of all other subsystems on the network; only of those with which it can communicate without an intermediary. 
The Interconnection Rule applies to communication between any two (or more) accredited systems. However, even when the Interconnection Rule is followed, there may be other potential security problems that will require the implementation of additional constraints on the network. In order to address these problems, it is necessary to adopt a global view of the network. This view requires a knowledge of the accreditation ranges of all the subsystems in the network. That is, it is no longer determinable locally whether or not a constraint is being satisfied. These accreditation ranges are taken into account when determining whether or not a subsystem should be allowed to connect to the network. In this way, the potential damage that can occur when information is compromised or modified can be limited to an acceptable level. 
Two global concerns are discussed below. One concern is the propagation of local risk; the other is the cascading problem. 
6.3.1 Propagation of Local Risk
The term Propagation of Local Risk comes from the notion of jeopardizing the security of a system as a result of weaknesses in other systems to which it may be connected. Table 3 in Section 4 recommends minimum classes of trusted systems for specific environments. Unfortunately, in many cases, operational needs have led to the accreditation of systems for multilevel operation that would not meet the requirements of the recommended class. While this increased risk may be accepted by the Accreditor of a particular system, connection of such a system to a network exposes users of all other subsystems in the network to the additional risk. Consequently, when an unevaluated system, or one that does not meet the class recommended for its accreditation, is proposed for connection to a network, constraints should be considered, such as one-way connections, manual review of transmissions, cryptographic isolation, or other measures to limit the risk it introduces. 
In the special case of a common user network such as DDN, it may be necessary to provide communications capabilities among systems that do not conform to the security requirements established by the network Accreditor (i.e., a system meeting no security requirements may be connected to a network.) One common way to provide network service to these non~onforming systems while still protecting the other, conforming, systems would be to segregate the non-conforming systems into closed communities that could not directly communicate with conforming systems. This approach is discussed in detail in the Defense Data Network Security Architecture [18]. 
6.3.2 The Cascading Problem
One of the problems that the Interconnection Rule does not address is the cascading problem, discussed in Appendix C of the INI. The cascading problem exists when an attacker can take advantage of network connections to reduce the nominal system resistance against leaking information across a range of sensitivity levels. Most multilevel systems, evaluated or not, are vulnerable to some risk that information can be leaked from a higher to a lower level supported on the system. The accreditation range of a subsystem represents a judgment that the risk is acceptable for that range of classifications. The size of the range is one indication of the attractiveness of the system as a target, so larger ranges call for more care in system design and management. In particular, Section 4 of this guideline discusses computation of a risk index calculation based on the accreditation range, and recommends a minimum evaluation class for a given risk index. 
The cascading problem results from the observation that subsystems may be connected in such a way that the network covers a larger sensitivity level range than the individual systems are accredited to handle. Depending on the actual topology of the interconnection and the characteristics of the installations, the arnount of effort required for an attacker to take advantage of residual vnlnerabilities may be less than what is required for the network sensitivity range. 
To see how this is possible, consider two systems, each of which is accredited to handle two adjacent classifications of information, as shown in Figure 9. Subsystem A processes Secret and Top Secret information, and all users are cleared to at least the Secret level. Subsystem B processes Confidential and Secret information, and all users are cleared to at least the Confidential level. 
The network as a whole has three levels of information. However, the leakage resistance of the network is only that offered by two systems qualified for only two levels. To make Top Secret information available to Confidential users, an attacker might attempt to: 
1. Install a Trojan horse in Subsystem A to leak some Top Secret information to Secret 
2. Send that information across the network link to Subsystem B 
3. Install a Trojan horse in Subsystem B to leak the original Top Secret information, now labeled Secret, to Confidential. 
The path from Top Secret in Subsystem A to Confidential in Subsystem B is referred to as a cascading path, with three steps. Step 1 is from TS to S in Subsystem A, Step 2 is the network link, and Step 3 is from S to C in Subsystem B. Steps (1) and (3), the downgrading steps, offer resistance commensurate with strictly smaller ranges. Step (2), the network link, offers no additional resistance, given that the two Trojan horses have been written and installed. 
Figure 9 
Cascading Problem 
Subsystem A
TS Subsystem B 
S S 
C 
The question is, whether subverting two systems qualified for two levels of information is as hard as defeating one system qualified for three levels of information. In some cases it might be. Lee [19] gives an argument that if two systems have probabilistically independent flaw sources, "...the resistance to threat of a cascade of two B2 systems is approximately the same as, or even better than, that of a B3 system." 
But Lee also remarks that demonstrating effective independence of flaw sources m a practical case is not easy, and that two systems may have the same or equivalent flaws, particularly if their TCBs are the same, or are separate implementations of a single flawed design. Exploitation of the flaws on two or more systems does present additional resistance to the attacker, but it should be kept in mind that physical access to all interconnected systems is not necessary to send untrusted software to them, as our experience with viruses shows unmistakably. 
6.3.2.1 Tests for Cascading. 
For a relatively large and complex interconnection of systems, it might not be obvious whether a cascading problem exists. Appendix C of the TNI includes three approaches, with different degrees of complexity and precision, for recognizing a potential cascading problem. These range from a simple test that is rather pessimistic, called the nesting condition, to a complex procedure. Appendix A of this TNIEG reviews the nesting condition, and presents additional information concerning tests for the cascading problem. 
Whichever test for cascading is employed, its result is to focus attention on certain subsystems and their network connections that might potentially be subject to a cascading threat. The next step is to determine whether the systems involved are actually vulnerable to the multiple coordinated attack that is necessary for cascading, ad, if so, to consider countermeasures. 
6.3.2.2 Solutions. 
There are several ways to tackle a cascading problem. Since cascading depends on cooperative action by malicious software on the participating subsystems, one approach is to institute configuration controls to prevent installation of unscrvtinized software, or perhaps isolating it from network usage. 
Another solution is to use a more trusted subsystem at appropriate nodes in the network, so that an attacker will be forced to overcome a protection mechanism commensurate with the seriousness of the potential compromise. In Figure 9, for example, if either subsystem A or subsystem B is NCSC-evaluated at class B3, which is sufficient according to Table 3 in Section 4 of this guideline for a rangd of Top Secret to Confidential, then the attacker is presented with an acceptable level of difficulty. 
A cascading threat can also be interdicted by eliminating certain network connections, to break paths by which an attacker could compromise information with insufficient resistance. This solution is practical only when the links to be eliminated are not needed for operational reasons. Sometimes end-to-end encryption can be used to address a cascading threat while preserving necessary connectivity, by reducing the level of information available to intermediate systems on a communication path. 
APPENDIX A
Tests for the Cascading Problem
The cascading problem was discussed in Section 6. This appendix reviews the approaches presented in Appendix C of the TNI for testing whether a cascading problem exists in an interconnection of accredited subsystems. Three criteria are given there: the nesting condition, the cascade condition, and a heuristic procedure. The nesting condition is a simple but pessimistic test that can, in some cases, dismiss the possibility of a cascading problem. When it fails, there is not necessarily a cascading problem; other, more accurate, tests should then be applied to confirm and locate it. This appendix first summarizes the nesting condition, and then discusses other approaches briefly. A forthcoming report will provide further guidance on computational approaches for the cascading problem. 
A.l Nesting Condition
The nesting condition is evaluated solely on the basis of the accreditation ranges of the subsystems. In the form given both here and in the TNI, it is applicable only when all sensitivity levels are totally ordered - that is, if they can be placed in order such that each one is higher than the one before it. This is true, in particular, if they are pure classifications, with no categories or compartments. 
The nesting condition is satisfied, by definition, if the accreditation ranges of each pair of subsystems are either disjoint or nested. A pair of accreditation ranges is disjoint if they have no levels in common. They are nested if one range is included (as a subset) in the other. All possible pairs (not just those of adjacent subsystems) must be considered, but some pairs may be nested while others are disjoint. 
If the nesting condition is satisfied, there is no cascading problem. Because the nesting condition does not take into account which network subsystems are actually connected to one another, it can sometimes give a pessimistic result, i.e., there are cases when the nesting condition fails, but there is actually no cascading problem. 
Figure A-I 
Accreditation Ranges of Two Interconnected Sub systems 
Subsystem Y
Class B1
Example 1: Consider the situation illustrated in Figure A-I. The accreditation range of Subsystem X is nested within that of Subsystem Y (i.e., C-S is completely contained within C-TS). Therefore, the nesting condition is satisfied, and there is no cascading problem. 
Figure A-2 
Cascading Problem 
Subsystem A
TS Subsystem B 
S S 
C 
Example 2: Consider the situation illustrated in Figure A-2. The accreditation ranges of Subsystem A and Subsystem B are not disjoint; neither is one completely contained within the other. Therefore, the nesting condition fails, ad a cascading problem is possible. Note, however, that the nesting condition would still fail even if the two subsystems were not connected to one another, yet in that case there would be no cascading problem. 
The situation is more complex when sensitivity levels are drawn from a partially ordered set, so that the accreditation ranges of some subsystems have sensitivity levels that are incomparable. Two sensitivity levels are incomparable when neither is greater than or equal to the other. Sensitivity levels with category sets are, in general, incomparable. An extended form of the nesting condition has been devised that applies to partially ordered sensitivity level sets . [20] A.2 Other Approaches Appendix C of the TNI contains two other criteria for the cascading problem: the cascade condition, which is a mathematical characterization of the problem, and a heuristic procedure. These criteria have been superseded by improved methods since the publication of the TNI. The new approach is described in a separate report, in order to give adequate scope to the presentation of background and context necessary to apply it appropriately. 
The need for a new approach arose from a recognition of the limitations of the existing criteria. The cascade condition is accurate but it is not, in itself, a computational procedure. It is limited by its assumption that all of the interconnected subsystems have been given evaluation classes. The heuristic procedure is believed to provide a conservative approximate test for cascading, but only when applied to interconnections in which all communication paths are two-way, i.e., capable of both sending and receiving. A simpler procedure is now available. 
APPENDIX B
Background References
Neither the TNI nor this TNIEG contain tutorial information on security and networking; it is assumed that the reader will have some background in both areas. There is considerable literature available. Following are some references that provide background and related information concerning security in networks: 
1 M. D. Abrams and H. J. Podell, Computer and Network Security, a Tutorial, IEEE Computer Society Press 1987. 
2 D. W. Davies and W. L. Price, Security for Computer Networks, John Wiley & Sons 1984. 
3 D. E. Denning, Cryptography and Data Security, Addison-Wesley 1983. 
4 M. Gasser, Building a Secure Computer System, Van Nostrand Reinhold Company 1988. 
5 International Standards Organization, Information Processing Systems - Open System Interconnection - Basic Reference Model, 15 October 1984. International Standard 7498. 
Part 2: Security Architecture, February 1989.1507498-2-1988(E). 
6 Charles P. Pfleeger, Security in Computing, Prentice-Hall 1989. 
7 Andrew S. Tanenbaurn, Computer Networks, Second Edition, Prentice-Hall 1988. 
APPENDIX C
Encryption
May networks today use or plan to use encryption as a fundamental mechanism for providing security services. The encryption devices provide a security perimeter at the protocol layer at which they provide service (typically the Network or Transport Layer). This section presents some information on how an encryption system can be part of the NSAD. It discusses MAC and DAC, use of encryption to reduce the number of AIS, and the risk index of the encryption system. 
C.1 Use of Encryption
As indicated in the TNI, an encryption mechanism is evaluated differently than other mechanisms. Evaluating encryption mechanisms has a long history predating the TNI. Evaluation of an encryption mechanism is part of COMSEC. Generally, encryption mechanisms receive a rating of the highest level of classified information which may be protected using that mechanism. Therefore, the only rating applicable to an encryption mechanism is the classification level of the information that is to be protected. This classification level also establishes the requirement. 
In general, organizations using the TNI and this document select their encryption mechanisms from a list provided by an organization which is responsible for evaluating such mechanisms. In many cases, that organization is the NSA. 
A more complicated situation exists when encryption is employed above the Link Protocol Layer, layer 2. At layers 3 and 4 the protocols are concerned with the end systems or intermediate devices (e.g., hosts, network switches) that the links connect. Higher layers are concerned with other peer entities. Traditionally, encryption applied above layer 2 has been termed end-to-end encryption, or E3. 
An E3 system may be provided as (part of) an NTCB. When the E3 system is integral to the NTCB, the use of the E3 system requires evaluation under the TCSEC with interpretations in the TNI. The evaluation must consider (1) the accreditation rage of the user interface, (2) the risk index for the bypass in the E3 device, and (3) the risk index between the highest sensitivity data ad the lowest clearance of user on the network. 
Depending on the design, devices of an E3system may satisfy all requirements for a system evaluated under PartI of the TNI. MAC may be provided either explicitly or implicitly. Explicit MAC is provided if the packets sent by the encryption device include a security label. Implicit MAC is provided if the security level must be inferred from the encryption key used to protect the data. All data protected by that key must be classified at a single security level. 
DAC is often provided in an E3 system as well. Typically, keys for exchanging data are provided to the E3 devices only after DAC has been applied. The encryption devices can provide identification ad authentication. While identification is generally done explicitly (by transmitting an identifier), authentication can be done implicitly (i.e., by the use of a unique key). The encryption devices may perform certain types of auditing as well. Typically, a device collects information and forwards it to another device for storage. Information collected may include: connections established, connections refused, packets with inappropriate labels, ad misrouted packets. The granularity provided by these E3 mechanisms is determined by the protocol layer at which the service is offered. 
Figure C-1 
Typical Interconnected AIS 
AIS 1 AIS 2 AIS 3 AIS 4 AIS 5 AIS 6 AIS 7 
In a typical network there will be a number of AIS. For example, two hosts are often attached to separate local networks connected by a wide area network (WAN). As shown in Figure C-1, the path between the hosts (without E3) may involve 7 separate interconnected AIS. 
TNI Environments Guideline Encryption 
E3 can help reduce the number of AIS. By placing E3 devices between each host and the LAN to which it is connected ad incorporating suitable key distribution components, the LANs and WAN collapse into a single network system and the path now traverses only three AIS, as shown in Figure C-2. AIS 2 provides security services to the hosts, therefore, it may be part of the NTCB. 
Figure C-2 
Using End-to-End Encryption to Reduce Number of AIS 
AIS1 AIS 2 AIS 3 
There may be a hierarchy of trusted system views. For example, E3 may be provided at protocol layers 3,4, and 7. Depending on the architecture, the layers of E3 could constitute a single NTCB or each could be a separate NTCB. In the latter case, the devices supporting different layers would be part of different AIS and the interconnection rules would be applied between higher and lower protocol layers. 
In general, an AIS at a higher protocol layer encompasses more devices than one at a lower protocol layer. The granularity of services offered is also finer at the higher protocol layer. 
In a situation where the higher protocol layer encryption system also has a higher evaluation class, the lower protocol layers might be considered less trusted just as current E3 designs treat the subnetwork as untrusted. Continuing the analogy, just as certain physical security requirements are imposed on the untrusted suLbnetwork, the higher protocol layer encryption might rely on characteristics of the lower protocol layers. 
However, one may be faced with a dilemma that the higherprotocollayer E3 system has a lower security evaluation than the lower-protocol-layer trusted system. 
For example, a WAN with E3 at layer 3 might be evaluated Al. The system might also provide E3 at layer 4, but an NTCB that includes layer 4 might. only be rated B2. In this case, treating the subsystems constituting the separate layers as separate AIS and using the Interconnection Rule to accredit the network as a whole could prove advantageous, as illustrated in Figure C-3. 
Figure C-3 
Separate Layers Treated as Separate AIS 
B2 B2 
(N-C) (N-C) 
0SI Layer 3 Network
B2 B2 
(S-TS) (S-TS) 
C.2 Encryption Mechanisms
In a trvsted AIS, the recommended evaluation class is determined using a risk index based on the highest data classification and the lowest user clearance. In considering an E3 subsystem in a network, three separate indexes must be considered [21]: 
1. The subscriber's range of sensitivity levels. The cleartext side of the encryption subsystem must be sufficiently trusted to maintain separation among the cleartext data streams sent and received by the subscriber attached to the encryption subsystem. A risk index is based on the highest and lowest sensitivity levels sent or received by the subscriber through this encryption subsystem. 
2. The bypass. In an E3 system, protocol control information must be sent around the encryption unit through a bypass. The software and hardware to mimplement the bypass must be trusted not to send user data through the bypass. A risk index can be computed based on the difference between the sensitivity level of the cleartext information and the sensitivity level of the untrusted subsystems of the network. 
3. The range of sensitivity levels across the network. This risk index is concerned with the difference between the highest level of information on any host attached to the network and the lowest clearance of a user that could potentially get access to that information. Depending on the characteristics of the network, this risk index could be larger than either 
1. or 2. above. The worst case scenario occurs when some users have lower clearances than the level at which the network backbone is physically protected. For example, there are currently plans to allow some uncleared users on the DISNET segment of the DDN [22] which will be physically protected at the Secret level. In that case, the risk index for the bypass works the opposite of the normal case: the ciphertext side will be the higher of the two ratings. 
The subsystem which performs access control and key distribution must 
also be concerned with this risk range since improper key distribution could lead to compromise across the entire network. An erroneous distribution could potentially permit the lowest cleared user to access the highest classification of information. 
LIST OF REFERENCES
1. Department of Defense Computer Security Center, Computer Security Requirements - Guidance for Applying the Department of Defense Trusted Computer System Evaluation Criteria in Specific Environments, 25 June 1985. CSC-STD~03-85 
2. Department of Defense, Department of Defense Trusted Computer System Evaluation Criteria, 15 August 1983. Department of Defense 5200.28-STD 
3. National Computer Security Center, Trusted Network Interpretation of the Trusted Computer System Evaluation Criteria, Version 1, July 1987. NCSC-TG- 
005 
4. Department of Defense, Security Requirements for Automative Data Processing (ADP) Systems, March 1988. Department of Defense Directive 5200.28 
5. National Computer Security Center, Trusted Product Evaluation, A Guide for Vendors, draft 1 March 1988 (or most recent edition). NCSCTG~02, Version- 
6. National Security Agency, Information Security Products and Services Catalogue, (quarterly updates). 
7. National Institute of Standards and Technology, United States Department of Commerce, Guideline for Computer Security Certification and Accreditation, 27 
September 1983. FIPS PUB 102 
8. V. A. Ashby, Thomas Gregg, and Annabelle Lee, "Security Approach for Rapid Prototyping in Multilevel Secure Systems," Fifth Annual Computer Security Applications Conference, December 1989. 
9. International Standards Organization, Information processing systems - Open Systems Interconnection - Basic Reference Model, 15 October 1984. 
International Standard 7498 
10. Defense Intelligence Agency, Security Manual for the Uniform Protection of Intelligence Processed in Automated Information Systems and Networks (U), Supplement to Director of Central Intelligence Directive (DCID) 1/16 (U), SECRET, 19 July 1988. 
11. National Institute of Standards and Technology, United States Department of Commerce, Guideline for Automatic Data Processing Risk Analysis, August 
1979. FIPS PUB 65 
12. T. E. Bell, "Managing Murphy's Law: Engineering a Minimum-Risk System," IEEE Specrtum, pp. 2i27, June 1989. 
13. National Computer Security Center, Proceedings of the 1988 Computer Security Risk Management Model Builders Workshop, Fort Meade, MD, May 1988. 
14. Sammy Migues, "A Guide to Effective Risk Management," Third Aerospace Computer Security Conference Proceedings, December 1987. 
15. Carl E. Laudwehr and H.O. Lubbes, An Approach to Determining Computer Security Requirements for Navy Systems, 13 May 1987. 
16. International Standards Organization, Information Processing Systems - Open Systems Interconnection - Basic Reference Model - Part 2: Security Architecture, October 1988. International Standard 7498-2-1988(E) 
17. Ingrid M. Olson, Eugene F. Troy, Milan S. Kuchta, and Brian W. McKenney, "Disclosure Protection of Sensitive Information," 13th National Computer Security Conference Proceedings, 1A October 1990. 
18. Robert W. Shirey, "Defense Data Network Security Architecture," Computer Communication Review, April 1990. 
19. T. M. P. Lee, "Statistical Models of Trvst: TCB's vs. People," IEEE Symposium on Security and Privacy, 1989. 
20. Jonathan K. Millen and Martin W. Schwartz, "The Cascading Problem for Interconnected Networks," Fourth Aerospace Computer Security Applications Conference Proceedings, December 1988. 
21. R. W. Shirey and S.I. Schaen, "ARCHWAY Program Preliminary Planning," MTR~7W00093~2, The MITRE Corporation, December 1987. Not currently in the public domain. 
22. G. R. Mundy and R. W. Shirey, "Defense Data Network Security Architecture," MILCOM `87 Proceedings, 21 October 1987. 
ACRONYMS
ADP Automatic Data Processing 
AIS Automated Information System 
ASD Assistant Secretary of Defense 
AUTODIN Automated Digital Network 
BI Background Investigation 
C Confidential 
C&A Certification and Accreditation 
COMPUSEC Computer Security 
COMSEC Communications Security 
COTS Commercial~ffThe-Shelf 
CPU Central Processing Unit 
CBS Central Security Service 
CI Command, Control, Communications, and Intelligence 
CSSI Computer Security Subsystem Interpretation 
DAA Designated Approving Authority 
DAC Discretionary Access Control 
DCA Defense Communications Agency 
DDN Defense Data Network 
DIA Defense Intelligence Agency 
DISNET Defense Integrated Secure Network 
DOD Department of Defense 
DODD Department of Defense Directive 
DOS Denial of Service 
E3 End-to~nd Encryption 
ENQ Enquiry 
EPL Evaluated Products List 
FIPS PUB Federal Information Processing Standards Publication 
GOSIP Government 05I Profile 
I&A Identification and Authentication 
INFO SEC Information Security 
IPC Inter-Process Communication 
150 International Standards Organization 
1550 Information System Security Officer 
JCS Joint Chiefs of Staff 
LAN Local Area Network 
MAC Mandatory Access Control 
MLS Multilevel Secure 
MOA Memorandum of Agreement 
MOR Memorandum of Record 
N Not Classified but Sensitive 
NACS National Communications Security Instruction 
NCSC National Computer Security Center 
NDI Non-Development Item 
NIU Network Interface Unit 
NSA National Security Agency 
NSAD Network Security Architecture and Design 
NSAP Network Service Access Point 
NTCB Network Trusted Computing Base 
0SI Open System Interconnection 
OT&E Operational Test and Evaluation 
PDS Protected Distribution System 
PDU Protocol Data Unit (a.k.a. packet, datagram) 
POSIX Portable Operating System Interface for Computer Environments 
RFP Request for Proposal 
RI Risk Index 
S SECRET 
SBI Special Background Investigation 
SCI Special Compartmented Information 
SDNS Secure Data Network System 
SH System High 
SlOPESI Single Integrated Operational Plan-Extremely Sensitive Information 
ST&E Security Test and Evaluation 
STS Single Trusted System 
TCB Trusted Computing Base 
TCP/IP Transmission Control Protocol/Internet Protocol 
TCSEC Trusted Computer System Evaluation Criteria $ 
TEMPEST (Not an acronym) 
TNI Trusted Network Interpretation 
TNIEG TNI Environments Guideline 
TS TOP SECRET 
TSAP Transport Service Access Point 
WAN Wide Area Network 
U.S. GOVERNMENT PRINTING OFFICE : 1990 O - 274-353 : QL 3 
</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

thanks
 thank you thanks

est
-----BEGIN PGP SIGNATURE-----

iQGzBAEBCgAdFiEE3i2wWgNvAF3Ob0JwcToTfO0KdokFAmaZkXIACgkQcToTfO0K
dolYUQv/Vnij328U+HxGsgURG3SLLzfnC63c288LtPNcKeVcUB+FRKiX6UZnRSs1
WhIG9IQfbcXBtRVW05G+EIKOtdlPZSrHUmOVIV06q2iyWXjKO2yRMPSBwXcd+8qY
m0NXQJAP0bBcwlBlA1Ah4SdlZqSSeaBxu8hsVQnCfbBcxn3upZK6BU+LO8yq+Eq7
coh356SkD7VQdWxvxHG5ivcY78d/Otw7qGhlmb98sfxhEVYylP6jHCntVERV8Z3z
iJ1zmXRbqKrnnvFPi6Sy68j1VCVwyYlHK0W+iJfpuTKEjdEZyeywanq2Wx2kbzjo
cR7P0vMFjZJ/tLzheoesAlggCwuV1e6m3tp05hwFVexpoqqV84D1lPtfv12fo5Cq
L2nx9rYEq/v5Xm8hCaE+OfundY9sZkNLT7O1j/jxEufff5EClsXrewTKas7/V6Do
htPMZeGv4xbK3nRXvKcQIUnZzWURds6DtOlj0Ijx74n6SD4uG4HUdAqONbS7ageY
JKAyV7Fx
=BrGo
-----END PGP SIGNATURE-----
</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

testing
-----BEGIN PGP SIGNATURE-----

iQGzBAEBCgAdFiEE3i2wWgNvAF3Ob0JwcToTfO0KdokFAmaZkD4ACgkQcToTfO0K
don1PAv+PKsBNNt7g7VuLHhbqQw+cysaLYjHe4AH1bPEBQ+feveqptStwAzgY9tG
JZw/BO02uX6pI0KUHQl/X7jUKuG88XNSj2Xu1Etm4TpgOMJo9lMBJLN32tpsTULy
JD+psFs0+AmurPGTE8qo5xN0O7241iwOTH1KOe2dbSo5mYZ1W5RDaY+XZWmKDU1v
OUqpVaJyq5ytxXFYBCHH2EXn8P1YVy8z987BehraWk9EFoaB+Tyx6YJ3M3ERrxsO
EnCgLG/G2DqWRKu7DOh/uILWHg4kTIXCUpC5Lnfn9nSaWSW1sEllWMFz8PTzmtAI
WtllkzdBg60F/FpYv+tDpxHqjfQIBM4gCXMu9yOsKpdKyCjU1KOSDyDOEOAdHq2G
zoUjXiPjGPGT18TcKqy1XaSLolztNHFFwBdt6SsSYijdXYRivMZZaDBf0ZOxzH2p
t3GgEljIwzX0znc3oIENA7TzDlUjqTpyvXAG1c/BMhVUi3TKnSh80oZrn/5R05HT
Fohu68Za
=Wo2N
-----END PGP SIGNATURE-----
</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">Below is an order form for compusec publications from NSA.


DISTRIBUTION POLICY:  Those requestors requiring an immediate
copy of any of the listed documents due to a bidding or contract
deadline may fill out the mailing label/form below.  After the 
request is received, their order will be handled as quickly as
possible.  Those desiring multiple or informational copies
should contact the Government Printing Office directly.

----------------------------------------------------------------
WRITTEN REQUESTS:                  TELEPHONE ORDERS:

Superintendent of Documents         (202) 512-1800
U.S. Government Printing Office     0800 - 1600 hrs.
Washington, DC 20402                (Mastercard, VISA, CHOICE)
----------------------------------------------------------------
DoD Trusted Computer System Evaluation Criteria (DoD 5200.28-STD)
GPO STOCK NUMBER:  008-000-00461-7 (Orange Book)    COST: $6.00

SCOMP Final Evaluation Report (CSC-EPL-85/001)
GPO STOCK NUMBER:  008-000-00438-2 (Tan Book)       COST: $3.00

PC Security Considerations (CSC-WA-002-85)
GPO STOCK NUMBER:  008-000-00439-1 (Light Blue Book)COST: $1.00

DoD Password Management Guideline (CSC-STD-002-85)
GPO STOCK NUMBER:  008-000-00443-9 (Green Book)     COST: $1.75

Guidance for Applying the DoD Trusted Computer System Evaluation
Criteria in Specific Environments (CSC-STD-003-85)
GPO STOCK NUMBER:  008-000-00442-1 (Yellow Book 03) COST: $1.00

Technical Rationale Behind CSC-STD-003-85:
Computer Security Requirements (CSC-STD-004-85) (Yellow Book 04)
GPO STOCK NUMBER:  008-000-00441-2                  COST: $2.00

Trusted Network Interpretation (NCSC-TG-005, Version 1)
GPO STOCK NUMBER:  008-000-00486-2 (Red Book)       COST: $13.00


                                   -----------------------------
                                   SIGNATURE

                                   -----------------------------
                                   (AREA CODE) TELEPHONE NUMBER

----------------------------------------------------------------
FROM                               MAILING LABEL   PRINT CLEARLY

Department of Defense         NAME______________________________
National Security Agency      POSITION/TITLE____________________
9800 Savage Road              COMPANY/ORG_______________________
Fort George J. Meade,         DIVISION__________________________
  Maryland 20755-6000         COMPLETE MAILING ADDRESS:
                              __________________________________
Circle Desired Publications   __________________________________
Orange, Red, Lt. Blue, Tan    __________________________________
Yellow 03, Yellow 04, Green   __________________________________


</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">
                         CSL BULLETIN
                           July 1993


CONNECTING TO THE INTERNET:  SECURITY CONSIDERATIONS

This bulletin focuses on security considerations for organizations
considering Internet connections.  Spurred by developments in high-
speed networking technology and the National Research and Education
Network (NREN), many organizations and individuals are looking at
the Internet as a means for expanding their research interests and
communications.  Consequently, the Internet is now growing faster
than any telecommunications system thus far, including the
telephone system.

New users of the Internet may fail to realize, however, that their
sites could be at risk to threats such as intruders who use the
Internet as a means for attacking systems and causing various forms
of computer security incidents.  Consequently, new Internet sites
are often prime targets for malicious activity, including break-
ins, file tampering, and service disruptions.  Such activity may be
difficult to discover and correct, may be highly embarrassing to
the organization, and can be very costly in terms of lost
productivity and damage to data.

New and existing Internet users need to be aware of the high
potential for computer security incidents from the Internet and the
steps they should take to secure their sites.  Many tools and
techniques now exist to provide sites with a higher level of
assurance and protection.

The Internet
The Internet is a world-wide "network of networks" that use the
TCP/IP protocol suite for communications.  The component networks
are interconnected at various points to provide multiple routes to
destinations and a high level of overall service to users.  Many
academic, business, and government organizations are connected to
the Internet.  In 1993, over five million users were connected,
with roughly half being business users.

The Internet provides several types of services, including terminal
emulation and remote system access (telnet), file exchange (ftp),
electronic mail (smtp), and a number of other services for
information exchange.

As outlined in CSL Bulletin TCP/IP or OSI?  Choosing a Strategy for
Open Systems, NIST advises that agencies procure Open Systems
Interconnect (OSI) networking products for new network
implementations and for multivendor information exchange.  At the
same time, it is practical for agencies to consider connections to
the Internet for the purpose of exchanging e-mail and files with
the large number of existing Internet sites.

Security Problems on the Internet
In recent years, a number of security problems with the Internet
have become apparent.  Newspapers have carried stories of high-
profile "cracker" attacks via the Internet against government,
business, and academic sites.  Crackers often roam the Internet
with impunity, covering their tracks by moving from system to
system.  Intruders have been known to use systems illegally to
exchange copyrighted software, to obtain sensitive information such
as business secrets, and in general to cause mischief.  System
administrators are often unaware of break-ins and unauthorized
users until they learn by accident.  A number of factors have
contributed to this state of affairs.

Complexity of Configuration:  Many sites connect systems to the
Internet with little thought to the complexity of system
administration and the increased potential for abuse from the
Internet.  New systems often arrive "out of the box" with network
access controls configured for maximum, i.e., least secure, access. 
The access controls are usually complex to configure and monitor. 
As a result, controls that are accidentally misconfigured can
result in unauthorized access.

Ease of Spying and Spoofing:  The vast majority of Internet traffic
is unencrypted and therefore easily readable.  As a result, e-mail,
passwords, and file transfers can be monitored and captured using
readily available software.  Intruders have been known to monitor
connections to well-known Internet sites for the purpose of gaining
information that would allow them to crack security or to steal
valuable information.  This information sometimes permits intruders
to spoof legitimate connections, i.e., trick system security into
permitting normally disallowed network connections.

Inherent Problems with TCP/IP Protocols:  The TCP/IP protocol
suite, as implemented in the Internet, does not contain provisions
for network security.  A number of the TCP/IP services, e.g.,
rlogin, rsh, etc., rely on mutually trusting systems and are
inherently vulnerable to misuse and spoofing.  Ironically, some of
these services, e.g., nis and nfs, are widely used to coordinate
local area network security and to distribute system resources
among other local systems.  If the vulnerabilities in these
services are exploited, security on the local area network could be
badly compromised.

Wide-Open Network Policies:  Many sites are configured
unintentionally for wide-open Internet access without regard to the
potential for abuse from the Internet.  Some systems still employ
password-less guest accounts or anonymous ftp accounts that can be
written to without restriction.  Others keep sensitive information
on network-accessible systems where it can be easily read.  The
vast majority of sites permit more TCP/IP services than they
require for their operations and do not attempt to limit access to
information about their computers that could prove valuable to
intruders.

Recommendations for New and Existing Internet Connections
New and existing Internet sites need to take strong and specific
measures to improve computer security.  These measures include
creating a TCP/IP service access policy, using strong
authentication, and using a secure Internet gateway that can imple-
ment network access policies.

  Service Access Policy
                              
                                               
        Local                      
        Area            strong      Secure   INTERNET
        Network     authentication  Gateway  OSI WANs
        Systems                    
                                               
                              
  

Network Service Policy:  The first step is to create a policy that
details what types of connectivity will be permitted.  If, for
example, e-mail is the only service required, then other forms of
access such as telnet and ftp can be restricted and overall risks
reduced.  Eliminating the TCP/IP services that are not needed will
help to provide a simpler, more manageable network environment. 
The following figure is a partial list of TCP/IP services that
should be restricted or blocked from passing through a site's
Internet gateway:

                    High-Risk TCP/IP Services
 DNS zone transfers leaks names of internal
systems tftp intruders can read
password file RPC (eg., NIS,
NFS) intruders can read/write
files rlogin, rsh, etc. relies on mutually
trusting systems X windows,        
OpenWindows intruders can monitor
users' sessions telnet, ftp, smtp can be abused, access
should be re-
 stricted to selected
systems
Strong Authentication:  Systems that can be accessed from the
Internet or via modem should require strong authentication such as
provided by smart cards and authentication tokens.  These systems
use one-time passwords that cannot be spoofed, regardless of
whether the passwords are monitored.  CSL Bulletin Advanced
Authentication Technology contains more information on strong
authentication techniques.

Secure Gateways:  Secure gateways, or firewalls, are highly
effective for improving site network security.  A secure gateway is
a collection of systems and routers placed at a site's central
connection to a network whose main purpose is to restrict access to
internal systems.  A secure gateway forces all network connections
to pass through the gateway where they can be examined and
evaluated.  The secure gateway may then restrict access to or from
selected systems or block certain TCP/IP services or provide other
security features.  A simple network usage policy that can be
implemented by a secure gateway is to provide access from internal
to external systems, but little or no access from external to
internal systems (except perhaps for e-mail).

For small sites, a simple router with packet-filtering capability
may serve as an effective gateway.  This type of router can
typically restrict access to selected systems and services by
examining each packet according to a sequence of filtering rules. 
A more flexible and robust approach is to combine the router with
other systems capable of logging network access and restricting
access and services on a finer basis.  Some secure gateways
implement proxy services that require all ftp or telnet connections
to be first authenticated at the gateway before being allowed to
continue.

Without a secure gateway, a site's security depends entirely on the
collective security of its individual systems.  As the number of
systems increases, it becomes more difficult to ensure that network
security policies are enforced.  Errors and simple mistakes in one
system's configuration can cause problems for other interconnected
systems.

Securing Modem Pools:  Unrestricted incoming and outgoing modem
pools (including PABX systems) can create backdoors that would let
intruders get around the access controls of secure gateways.  Modem
pools need to be configured to deny access to unauthorized users. 
Systems that can be accessed from modem pools should require strong
authentication such as one-time passwords.  Modem pools should not
be configured for outgoing connections unless access can be
carefully controlled.

Securing Public Access Systems:  Public access systems such as
anonymous ftp archives are often prime targets for abuse.  Such
systems, if misconfigured to allow writing, can permit intruders to
destroy or alter data or software, which can prove highly
embarrassing to the organization.  CSL Bulletin Security Issues in
Public Access Systems provides guidance on securing public access
systems.

System Security Tools:  The existence of a secure gateway does not
negate the need for stronger system security.  Many tools are
available for system administrators to enhance system security and
provide additional audit capability.  Such tools can check for
strong passwords, log connection information, detect changes in
system files, and provide other features that will help
administrators to detect signs of intruders and break-ins.

Keeping Up-to-Date
Sites need to be aware of other resources and information that will
permit them to update site security as new vulnerabilities are
discovered and as new tools and techniques to improve security
become available.  In particular, sites need to know who to contact
when trouble arises.

Vendor Support:  Several system vendors now regularly distribute
software update notifications and related security information via
e-mail.  Customers need to contact vendors and determine whether
they can receive such information.

Incident Handling Teams:  A number of vendors, other businesses,
and government-affiliated organizations have created computer
security incident handling teams.  These groups typically provide
assistance in determining whether an incident has occurred and how
to correct any vulnerabilities that were exploited.  NIST helps to
coordinate the Forum of Incident Response and Security Teams
(FIRST).  FIRST provides guidance and overall coordination of teams
and incident handling information.  For more information about
incident response teams and FIRST, contact NIST (see below).

For More Information
NIST will be issuing more guidance on open systems security and on
secure gateways.  For more information on Internet security and
other computer security issues, contact the National Institute of
Standards and Technology at the following address:  NIST, Building
225, Room A-216, Gaithersburg, MD 20899-0001; telephone (301) 975-
3359; fax (301) 948-0279.

NIST also maintains a computer security bulletin board system (BBS)
and Internet-accessible site for computer security information open
to the public at all times.  These resources provide information on
computer security publications, CSL Bulletins, alert notices,
information about viruses and anti-virus tools, a security events
calendar, and sources for more information.

To access the BBS, you need a computer with communications
capability and a modem.  For modems at 2400 bits per second (BPS)
or less, dial (301) 948-5717.  For 9600 BPS, dial (301) 948-5140. 
Modem settings for all speeds are 8 data bits, no parity, 1 stop
bit.

Internet users with telnet or ftp capability may telnet to the BBS
at cs-bbs.nist.gov (129.6.54.30).  To download files, users need to
use ftp as follows:  ftp to csrc.nist.gov (129.6.54.11), log into
account anonymous, use your Internet address as the password, and
locate files in directory pub; an index of all files is available
for download.  For users with Internet-accessible e-mail
capability, send e-mail to docserver@csrc.nist.gov with the
following message:  send filename, where filename is the name of
the file you wish to retrieve.  send index will return an index of
available files.

References
The sources used to develop this bulletin provide excellent
resources for further information on Internet security and related
topics.  Ordering information is provided when appropriate.  All
references except [1] and [6] are available from the NIST BBS or
via ftp.

[1]    Cerf, Vinton, "A National Information Infrastructure," 
Connexions, June 1993.

[2]    "TCP/IP or OSI? Choosing a Strategy for Open Systems," CSL
       Bulletin, National Institute of Standards and Technology, June
       1992.  

[3]    Bellovin, Steve, "Security Problems in the TCP/IP Protocol
       Suite," Computer Communication Review, April 1989.

[4]    Holbrook, Paul, and Joyce Reynolds, "Site Security Handbook,"
       RFC 1244 prepared for the Internet Engineering Task Force,
       1991.  

[5]    "Advanced Authentication Technology," CSL Bulletin, National
       Institute of Standards and Technology, November 1991.

[6]    Curry, David, Unix System Security, Addison Wesley, 1992.

[7]    Ranum, Marcus, "Thinking About Firewalls," Proceedings of
       Second International Conference on System and Network
       Security, April 1993.

[8]    "Security Issues in Public Access Systems," CSL Bulletin,
       National Institute of Standards and Technology, May 1993.

[9]    Polk, W. Timothy, Automated Tools for Testing Computer System
       Vulnerability, NIST Special Publication 800-6, National
       Institute of Standards and Technology, December 1992.  Order
       from GPO, 202-783-3238, SN003-003-03189-9, or NTIS, 703-487-
       4650, PB93-146025.

[10]   Wack, John, Establishing A Computer Security Incident Response
       Capability, NIST Special Publication 800-3, National Institute
       of Standards and Technology, November 1991.  Order from NTIS,
       703-487-4650, PB92-123140.

</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content"> 


                                                 CSC-STD-002-85







                   DEPARTMENT OF DEFENSE

                   PASSWORD MANAGEMENT

                         GUIDELINE






              Approved for public release;
              distribution limited.




                        12 April 1985



                      DEPARTMENT OF DEFENSE
                     COMPUTER SECURITY CENTER
               Fort George G. Meade, Maryland 20755





                                                           
                                                CSC-STD-002-85
                                           Library No. S-226,994





                                  FOREWORD


This publication, "Department of Defense Password management
Guideline," is being issued by the DoD Computer Security Center
(DoDCSC) under the authority of and in accordance with DoD
Directive 5215.1, "Computer Security Evaluation Center." The
guidelines described in this document provide a set of good
practices elated to the use of password-based user authentication
mechanisms in automatic data processing systems employed for
processing classified and other sensitive information. Point of
contact concerning this publication is the Office of Standards
and Products, Attention: Chief, Computer Security Standards.








Robert L. Brotman                         12 April 1985          
Director
DoD Computer Security Center
    


                    ACKNOWLEDGMENTS


Special recognition is extended to Sheila L. Brand, DoD Computer
Security Center (DoDCSC), and Jeffrey D. Makey, formerly DoDCSC,
as principal authors of this publication.

Acknowledgment is also given for the contributions of: Daniel J.
Edwards, Mary E. Flaherty, Steven J. Padilla, DoDCSC, John J.
Stasak III, Gregory L. Wessel and Bernard Peters, Department of
Defense, Col. Roger R. Schell, formerly DoDCSC, and James P.
Anderson, James P. Anderson & Co, who gave generously of their
time and expertise in the formulation and review of this
document.
























                   ii


                 CONTENTS

FOREWORD.....................................................  i
ACKNOWLEDGMENTS..............................................  ii
CONTENTS......................................................iii
INTRODUCTION.................................................   1

1.0 
SCOPE...........................................................1
2.0 CONTROL OBJECTIVES..................................... ....2
3.0 DEFINTIONS...............................................   3
4.0  GUIDELINES..............................................   4
  4.1  SSO Responsibilities..................................   4
           4.1.1 Initial System Passwords...............        4
           4.1.2 Initial Password Assignment...............     4
           4.1.3 Password Change Authorization.............     6
           4.1.4 Group IDs................................      6
           4.1.5 User ID Revalidation.......................    6
      4.2 User Responsibilities..............................   6
           4.2.1 Security Awareness........................     6
           4.2.2 Changing Passwords........................     6
           4.2.3 Log into a Connected System..................  8
           4.2.4 Remembering Passwords....................      8
      4.3 Authentication Mechanism Functionality............    9
           4.3.1 Internal Storage of Passwords .............    9
           4.3.2 Entry......................................    9
           4.3.3 Transmission...............................   10
           4.3.4 Login Attempt Rate.........................   10
           4.3.5 Auditing....................................  10
      4.4  Password Protection..............................   11
           4.4.1 Single Guess Probability..................    11
           4.4.2 Password Distribution ......................  11
APPENDIX A:  Password Generation Algorithm...................  13
APPENDIX B:  Password Encryption Algorithm...................  13
APPENDIX C:  Determining Password Length.....................  17


                                   iii


APPENDIX D:  Protection Basis for Passwords..............      23
APPENDIX E:  Features for Use in Very Sensitive Applications   25
APPENDIX F:  On the Probability of Guessing a Password.....    27
REFERENCES..................................................   31




































                                    iv
                                                            
                             INTRODUCTION



In August 1983, the DoD Computer Security Center published CSC-STD-001-83,
Department of Defense Trusted Computer System Evaluation Criteria.  That
publication defines and describes feature and assurance requirements for six
hierarchical classes of enhanced security protection for computer systems that
are to be used for processing classified or other sensitive information.  A
major requirement common to all six classes is accountability:
            "Individual accountability is the key to securing and
            controlling any system that processes information on behalf
            of individuals or groups of individuals.  A number of
            requirements must be met in order to satisfy this objective.

            "The first requirement is for individual user identification.
            Second, there is a need for authentication.  Without
            authentication, user identification has no credibility.
            Without a credible identity (no) security policies can be
            properly invoked because there is no assurance that proper
            authorizations can be made." (2)

This guideline has been developed `to assist in providing that much needed
credibility of user identity by presenting a set of good practices related to
the design, implementation and use of password-based user authentication
mechanisms.  It is intended that features and practices described in this
guideline be incorporated into DoD automatic data processing (ADP) systems
used for processing classified or other sensitive information.

1.0 SCOPE

  The security provided by a password system depends on the passwords being
kept secret at all times.  Thus, a password is vulnerable to compromise
whenever it is used, stored, or even known.  In a password-based
authentication mechanism implemented on an ADP system, passwords are
vulnerable to compromise due to five essential aspects of the password system:
	1) a password must be initially assigned to a user when enrolled on
the ADP system; 
	2) a user's password must be changed periodically; 
	3) the ADP system must maintain a "password database"; 
	4) users must remember their passwords; and 
	5) users must enter their passwords into the ADP system' at
authentication time.  

This guideline prescribes steps to be taken to minimize
the vulnerability of passwords in each of these circumstances.


  Specific areas addressed in this guideline include the responsibilities of
the system security officer and of users, the functionality of the
authentication mechanism, and password generation.  The major features
advocated in this guideline are:

      * Users should be able to change their own passwords.

      * Passwords should be machine-generated rather than
user-created.

    *   Certain audit reports (e.g., date and time of last login)
should be
        provided by the system directly to the user.

    For certain sensitive applications such as Command and Control Systems,
pertinent DoD directives should be referenced in order to assess the need for
additional identification and authentication features.

2.0 CONTROL OBJECTIVES

  The CSC-STD-001-83 gives the following as the Accountability
Control Objective:

        "Systems that are used to process or handle classified or
	other sensitive information must assure individual
	accountability whenever either a mandatory or discretionary security
	policy is invoked. Furthermore, to assure accountability, the
	capability must exist for an authorized and competent agent to
	access and evaluate accountability information by a secure means,
	within a reasonable amount of time, and without undue difficulty."(2)

    In order to attain the individual accountability required, it is necessary
for the ADP system to be able to uniquely identify each person who uses it.
In many cases, a password scheme will be used to achieve this.  The
Accountability Control Objective, applied to password systems, leads to the
following control objectives for password systems.

      * Personal Identification

        Password systems used to control access to ADP systems that process or
handle classified or other sensitive information must assure the capability to
uniquely identify each individual user of the system.
      
      * Authentication

        Password systems used to control access to ADP systems that process or
handle classified or other sensitive information must assure unequivocal
authentication of the user's claimed identity.
                                                                 

      * Password Privacy

        Password systems must assure, to the extent possible, protection of
the password database consistent with protection afforded the classified or
other sensitive information processed or handled by the ADP system in which
the password systems operate.

      * Auditing

        Password systems used to control access to ADP systems that process or
handle classified or other sensitive information must be able to assist in the
detection of password compromise.

3.0 DEFINITIONS

    * Access Port A logical or physical identifier that a computer uses to
distinguish different terminal input/output data streams.

    * Expired Password - A password that must be changed by the
user before login may be completed.

    * Password - A character string used to authenticate an identity.
Knowledge of the password that is associated with a user ID is considered
proof of authorization to use the capabilities associated with that user ID.

    * Password System - A part of an ADP system that is used to authenticate a
user's identity.  Assurance of unequivocal identification is based on the
user's ability to enter a private password that no one else should know.

    * System Security Officer (SSO) - The person responsible for the security
of an ADP system.  The SSO is authorized to act in the "security
administrator" role defined in CSC-STD-001-83.  Functions that the SSO is
expected to perform include: auditing and changing security characteristics of
a user.

    * Trusted Identification Forwarding - An identification method used in
networks where the sending host can verify that an authorized user on its
system is attempting a connection to another host.  The sending host transmits
the required user authentication information to the receiving host.  The
receiving host can then verify that the user is validated for access to its
system.  This operation may be transparent to the user.

    * User ID - A unique symbol or character string that is used by an ADP
system to uniquely identify a user.  The security provided by a password
system should not rely on secrecy of the user's ID.


			        4


4.0 GUIDELINES

    In the remainder of this document, guidelines for good practice are
presented in bold print, while amplifications, examples, and rationale are
presented in normal print.  The guidelines are given with two degrees of
emphasis.  Those that are most important to the security of a password system
are presented with such wording as "The SSO should ..." (the word "should" is
the key), while less critical functions are presented with such wording as "It
is recommended that." ("recommended" is the key).  Because it is anticipated
that diverse user communities will adopt this guideline, all recommendations
are presented in general rather than specific terminology, divorced from
vendor-specific hardware or system software.  Where features require the
setting of a specific value (e.g., password maximum lifetime), it is suggested
that these be designed as parametric settings leaving the determination of
exact values to local security management who understand the particular
security requirements of their user environment.

    It is recommended that, whenever possible, the mechanisms discussed in
this guide be automated.  Automation will result in a minimal burden on the
    system administration and on the users, and thus in greater effectiveness
of the mechanisms by eliminating situations where passwords might be exposed
to people.

  4.1 550 Responsibilities
  4.1.1 Initial System Passwords
    Many ADP systems come from the vendor with a few standard user IDs
(e.g., SYSTEM, TEST, MASTER, etc.) already enrolled in the system.  The System
Security Officer (SSO) should change the passwords for all standard user IDs
before allowing the general user population to access the system.  This can be
easily assured if the standard user IDs are initially identified by the system
as having "expired" passwords.  (See section 4.2.2.1 for discussion of expired
passwords.)


    4.1.2 Initial Password Assignment
         The SSO is responsible for generating and assigning the initial
password for each user ID.  The user must then be informed of this password.
In some areas, it may be necessary to prevent exposure of the password to the
SSO.  In other cases, the user can easily nullify this exposure.

    4.1.2.1 Preventing Exposure
         There are methods that can be implemented to prevent exposure of
a password to the SSO after it has been generated.  One technique is to print
the user's password on a sealed multipart form in such a way that it is not
visible on the top page of the form.  The SSO would then protect the sealed
password appropriately until it could be delivered to the user.  In this case,
the password is generated randomly by the ADP system and is not known by the
SSO.
                                                                 
			        5



         The password should be seated so it is not visible and cannot be made
visible without breaking the seal.  Delivery of the password in this manner
could require several days.

         Another method of preventing exposure is to have the user present at
password generation.  The SSO must initiate the procedure and the user must
shield the generated password and then remove or erase it from the display.
This method cannot be used when user terminals are at remote locations.

         It is recommended that a technique comparable to one of the
         above be used to prevent exposing a user's initial password to
         the SSO.  Whatever method is used to distribute passwords, the SSO
         must receive an acknowledgment of receipt of the password within a
         specified time period.

  4.1.2.2 Nullifying Exposure

         When a user's initial password must be exposed to the SSO, this
exposure may be nullified by having the user immediately change the password
by the normal procedure.  (Presumably, this change procedure does not expose
the new password to the SSO.)

         When a user's initial password is not protected from exposure
         to the SSO, the user ID should be identified by the system as
         having an "expired password" which will require the user to
         change the password by the usual procedure (see section
         4.2.2.3) before receiving authorization to access the system.

  4.1.2.3 Classification Assignment

         Where the password must be classified, the initial classification
assignment should be entered by the SSO to designate the highest security
level that may be associated with each user's initial password and its
successors.

4. 13 Password Change Authorization

      Occasionally, a user will forget the password or the SSO may determine
that a user s password may have been compromised.  To be able to correct these
problems, it is recommended that the SSO be permitted to change the password
of any user by generating a new one.  The SSO should not have to know the
user's password in order to do this, but should follow the same rules for
distributing the new password that apply to initial password assignment (see
section 4.1.2).  Positive identification of the user by the SSO is required
when a forgotten password must be replaced.

			        6


  4. 1.4 Group IDs

        Throughout the lifetime of an ADP system, each user ID should be
assigned to only one person.  In other words, no two people may ever have the
same user ID at the same time, or even at different times.  It should be
considered a security violation when two or more people know the password for
a user ID (except in the case when the SSO is the other person and the user ID
is identified by the system as having an "expired password">.  Note that there
is no intention of prohibiting alternate forms of user identification (e.g.,
group IDs,functional titles) for non-authentication purposes (e.g., data
access control, mail).  If alternate IDs are used, they must be based on user
IDs.

  4.1.5 User ID Revalidation

        The SSO should be responsible for the development of a procedure
whereby prompt notification is given to the SSO when a user ID and password
must be removed from the ADP system (e.g., when an employee leaves the
sponsoring organization>.  In addition, all user IDs should be revalidated
periodically, and information such as sponsor and means of off-line contact
(e.g., phone number,mailing address) updated as necessary.  It is recommended
that this revalidation be done at least once per year.

4.2 User Responsibilities

  4.2.1 Security Awareness

        Users should understand their responsibility to keep passwords private
and to report changes in their user status, suspected security violations,
etc.  To assure security awareness among the user population, it is
recommended that each user be required to sign a statement to acknowledge
understanding these responsibilities.

  4.2.2 Changing Passwords

        The simplest way to recover from the compromise of a password is to
change it.  Therefore, passwords should be changed on a periodic basis to
counter the possibility of undetected password compromise.  They should be
changed often enough so that there is an acceptably low probability of
compromise during a password's lifetime.  To avoid needless exposure of users'
passwords to the SSO, users should be able to change their passwords without
intervention by the SSO.

    4.2.2.1 Password Lifetime

           The most obvious threat to the security provided by a password
system is from the compromise of passwords.  The greater the length of time
during which a password is used for authentication purposes,the more
opportunities there are for exposing it.  In a useful password system, the
probability of compromise of a password increases during its lifetime.  For a
period of time, this probability could be considered

                                                                 
                          7


acceptably low while after a longer period of time, it would be considered
unacceptably high.  At this latter point, use of the password should be
considered suspect rather than a reliable proof of identity.  By appropriately
limiting the length of time (called the password lifetime) during which a
password can be used,the vulnerability of the password can remain acceptable.
There should be a maximum lifetime for all passwords.  To protect against
unknown threats, it is recommended that the maximum lifetime of a password be
no greater than 1 year.  The presence of known threats may indicate a need for
a shorter maximum lifetime.  Also, depending on the size of the password space
and on how fast a penetrator can execute a login attempt, it may be necessary
to change passwords even more frequently.  See Appendix C for a discussion of
the relationship between password lifetime, password space and the guess rate.
A password should be invalidated at the end of its maximum lifetime.  It is
recommended that, at a predetermined period of time prior to the expiration of
a password's lifetime, the user ID it is associated with be notified by the
system as having an "expired" password.  A user who logs in with an ID having
an expired password should be required to change the password for that user ID
before further access to the system is permitted.  If a password is not
changed before the end of its maximum lifetime, it is recommended that the
user ID it is associated with be identified by the system as "locked." No
login should be permitted to a locked user ID, but the SSO should be able to
unlock the user ID by changing the password for that user ID, following the
same rules that apply to initial password entry (see section 4.1.2).  After a
password has been changed, the lifetime period for the password should be
reset to the maximum value established by the system.  4.2.2.2 Change
Authorization To be consistent with the Password Privacy control objective,
users (other than the SSO) should be permitted to change only their own
passwords.  To ensure this, it is recommended that the user enter the old
password and the user ID/password combination be validated as part of the
password changing procedure.  


4.2.2.3 Change Procedure
        Changing a password in a secure manner involves several steps.  The
following procedure is recommended:
            The procedure should be invoked at the user's request or
            when a user logs in with an expired password.  If the change is
	  necessary due to an expired password, the user should be so
	  informed.  The user should be presented with a brief summary of
	  the major steps in changing a password, including a caution that
	  the user should ensure that no one else is watching what the user
	  is doing.  Except
            

			        8



             when the change procedure is part of the login procedure (e.g.,
	   logging in with an expired password>, the user's current password
	   should be entered to re-authenticate identity.  The change
	   procedure should display a new password for the user.  The new
	   password should be different from the old one and should
	   be generated by angenerated by any algorithm that satisfies the
	   specifications in Appendix A.  The user should then enter the new
	   password twice so the procedure can verify that the user can
	   consistently enter the password correctly.  The new password
	   should be obliterated by techniques such as overprinting or
	   terminal screen erasing.  If the two entered passwords are
	   identical to the generated password, the password data base
	   should be updated (i.e., the old password deleted or invalidated
	   andthe new password associated with the user ID) and a message to
	   this effect should be displayed.  Failure by the user to
	   correctly enter the current password or the generated password
	   should result in a useful error message to the user and in the
	   change procedure being aborted without changing the password.
	   When the attempt to change an expired password is not successful,
	   the password should be retained as expired and the user given the
	   option to again change the password or logout.  An audit record
	   should be generated that indicates whether or not the change was
	   successful.

4.2.3 Login to a Connected System

      Users should be required to authenticate their identities at "login"
      time by supplying their password along with their user ID.  It is
      recommended that some form of trusted identification forwarding
      be used between hosts when users connect to other ADP systems
      through a network.  When trusted identification forwarding is not
      used, a remote host should require the user's ID and password
      when logging in through a network connection.  Note that user IDs
      on different hosts for the same user may be different, and that
      corresponding machine-generated passwords almost certainly will be
      different.  Note also that a password required by a remote host is
      vulnerable to compromise by the local host or intermediate hosts.

4.2.4 Remembering Passwords

      Since users must supply their passwords to the ADP system at
      authentication time, it follows that they must know what their passwords
      are.  It is recommended that users memorize their passwords and
      not write them on any medium.  If passwords must be written,they
      should be protected in a manner that is consistent with the damage
      that could be caused by their compromise.  See Appendix D for
      guidance on the protection of passwords.
                                                                 

			        9



4.3 Authentication Mechanism Functionality

  4.3.1 Internal Storage of Passwords

        It is normally necessary for the ADP system to store internally the
user ID for each authorized system user as well as some representation of the
password and, when required, the clearance and authorizations that are
associated with each user ID.  Without some form of access control over this
information, it will be possible for unauthorized users to read an-or modify
the password database.  Unauthorized reading and writing of the password
database are a concern.  Reading it could result in disclosure of passwords to
unauthorized users.  Being able to write it could result, for example, in user
A changing user B's password so user A could log in under user B's identity.
Note that it is necessary for the login process to be able to read the
password database and the password changing process to be able to read and
write the password database.

        Stored passwords should be protected by access controls provided by
the ADP system, by password encryption, or by both.

    4.3.1.1 Use of Access Control Mechanisms

            Access control mechanisms (e.g., mandatory or discretionary
controls as discussed in CSC-STD-001-83) should be used to protect the
password data base from unauthorized modification and disclosure.

    4.3.1.2 Use of Encryption

            Encryption of stored passwords should be used whenever the access
control mechanisms provided by the ADP system are not adequate to prevent
exposure of the stored passwords.  It is recommended that password encryption
be used even when other access controls are considered adequate, as this helps
protect against possible exposure when access controls are bypassed (e.g.,
system dumps).  When encryption is used to protect stored passwords, it is
recommended that the algorithm meet the specifications in Appendix B.  It is
recommended that encryption be done immediately after entry, that the memory
containing the plaintext password be erased immediately after encryption, and
that only the encrypted password be used in comparisons.  There is no need to
be able to decrypt passwords.  Comparisons can be made by encrypting the
password entered at login and comparing the encrypted form with the encrypted
password stored in the password database.

  4.3.2 Entry

            Encryption of stored passwords should be used whenever the access
control mechanisms provided by the ADP system are not adequate to prevent
exposure of the stored passwords.  It is recommended that password encryption
be used even when other access controls are considered adequate, as this helps
protect against possible exposure when access controls are bypassed (e.g.,
system dumps).  When encryption is used to protect stored passwords, it is
recommended that the algorithm meet the specifications in Appendix B.  It is
recommended that encryption be done immediately after entry, that the memory
containing the plaintext password be erased immediately after encryption, and
that only the encrypted password be used in comparisons.  There is no need to
be able to decrypt passwords.  Comparisons can be made by encrypting the
password entered at login and comparing the encrypted form with the encrypted
password stored in the password database.  Passwords should be entered after
providing a user ID to the system.  If the entry is correct, the system should
then display the date and time of the user's last login.

        It is recommended that the system not echo passwords that users type
in.  When the system cannot prevent a password from being



			        10



echoed (e.g., in a half-duplex connection), it is recommended that a random
overprint mask be printed before or after the password is entered, as
appropriate, to conceal the typed password.  The complete password as entered
by the user should be an exact match, character for character, with the user's
current password.


4.3.3 Transmission

      During transmission of a password from a user's terminal to the computer
in which the authentication is done, passwords should be protected in a manner
that is consistent with the damage that could be caused by their compromise.
Since passwords are no more sensitive than the data they provide access to,
there is generally no reasonto protect them, during transmission, to any
greater degree (e.g.,encryption) than regular data is protected.  See Appendix
D for guidanceon the protection of passwords.

4.3.4 Login Attempt Rate

      By controlling the rate at which login attempts can be made (where each
attempt constitutes a guess of a password), the number of guesses a penetrator
can make during a password's lifetime is limited to a known upper bound.  To
control attacks where a penetrator attempts many logins through a single
access port, the password guess rate should be controlled on a per-access port
basis.  That is, each access port should be individually controlled to limit
the rate at which login attempts can be made at each port.  When a penetrator
can easily switch among multiple access ports, it is recommended that the
password guess rate also be controlled on a per-user ID basis.  It is
recommended that maximum login attempt rates fall within the range of one per
second to one per minute.  This range provides reasonable user-friendliness
without permitting so many login attempts that an extremely large password
space or an extremely short password lifetime is necessary.  See Appendix C
for a discussion of the relationship between the guess rate, password
lifetime, and password space.  Note that it is not intended that login be an
inherently slow procedure, for there is no reason to delay a successful login.
However, in the event of an unsuccessful login attempt, it is quite reasonable
to use an internal timer to enforce the desired delay before permitting the
next login attempt.  The user should not be able to bypass this procedure.

4.3.5 Auditing

  4.3.5.1 Audit Trails

         The system should be able to create an audit trail of password usage
and changes.  Such an audit trail should not contain actual passwords or
character strings that were incorrectly given as passwords, since this could
expose the password of a legitimate user who mistyped his user ID or password.
Auditableevents should include: successful login, unsuccessful login
                                                                 
			        11



attempts, use of the password changing procedure, and the locking of a user ID
due to its password reaching the end of its lifetime.  For each recorded
event, the audit record should include: date and time of the event, type of
event, offered user ID for unsuccessful logins or actual user ID for other
events, and origin of the event (e.g., terminal or access port 11').  Audit
records of password changes should also indicate whether or not the change was
successful.

    4.3.5.2 Real-time Notification to System Personnel

   It is recommended that each accumulation of 5 consecutiveunsuccessful login
attempts from a single access port or against a single user ID results in
immediate notification of the event to the ADP system operator or the SSO.
While there is no requirement for the SSO or operator to take any action upon
receiving the notification, frequent notifications may indicate that a
penetration attempt is in progress and may warrant investigation and possible
corrective action.

    4.3.5.3 Notification to the User

     Upon successful login, the user should be notified of:

             *  The date and time of user's last login;

             * The location of the user (as can best be determined) at last
                login; and

             * Each unsuccessful login attempt to this user ID since the
                last successful login.

      This provides a means for the user to determine if someone else is
            using or attempting to guess this user ID and
password.

4.4 Password Protection

  4.4.1 Single Guess Probability

        The probability that any single attempt at guessing a password will be
successful is one of the most critical factors in a password system.  This
probability depends on the size of the password space and the statistical
distribution within that space of passwords that are actually used.  Since
many user-created passwords are particularly easy to guess all passwords
should be machine generated using an algorithm that meets the specifications
in Appendix A.

  4.4.2 Password Distribution

        During distribution to the user.  passwords should be protected to the
same degree as the information to which they provide access.machine-generated
passwords should be displayed on the user's terminal at time of change, along
with appropriate cautions to the

			        12


user to protect the password.  At the completion of the change procedure, it
is recommended that displayed passwords be erased or overstruck, as
appropriate for the terminal type.  Passwords changed by the 550 should be
distributed in a manner that is consistent with the damage that could be
caused by their compromise.  See Appendix D for guidance on the protection of
passwords.
                                                                 
			        13


                                 APPENDIX A

                       Password Generation Algorithm


This appendix describes the requirements to be met by an acceptable password
generation algorithm.  The issues involved relate to the specifications for
password space, random seed generation, pseudo-random number generation and
"user- friendly" passwords.

A.1 Password Space

  The size of the password space is a function of the size of the alphabet and
the number of characters from that alphabet that are used to create passwords.
(The maximum size of the password space can be expressed as 5 A where 5 is the
maximum password space, A is the alphabet size and M is the password length.)

  To determine the minimum size of the password space needed to satisfy the
security requirements for an operational environment, equation [3] in Appendix
C can be used.  The password generation algorithm selected should be able to
generate at least that number of passwords.  In addition, the generated
passwords should be, at a minimum, 6 characters in length.

A.2 Random Seeds

  When a pseudo-random number generator is used in a password generation
algorithm, it should accept as input random data that would provide output
which has a high degree of unpredictability.  This random data (seed) can be
derived from a number of available parameters such as a system clock, system
registers, date, time, etc.  The parameters should be selected to ensure that
the number of unique seeds that can be generated from these inputs should be
at least equal to the minimum number of passwords that must be generated.
When passwords are used to protect classified information, the seed generator
should be approved by the DoD Computer Security Center.

A.3 Pseudo-Random Number Generator

  Using a random seed as input, the pseudo-random number generator that drives
a password generation algorithm should have the property that each bit in the
pseudo-random number that it generates is a complex function of all the bits
in the seed.  The Federal Data Encryption Standard (DES), as specified in FIPS
46, (9) is an example of a pseudo-random number generator with this property.
If DES is used, it is suggested that the 64-bit Output Feedback (OFB) mode be
used as specified in FIPS 81 (10).  In this case, the seed used as input could
consist of:

      * An initialization vector
      * A cryptographic key
      * Plaintext
			        14



  Factors that can be used as input to these parameters are:

    For the initialization vector:

      * System clock
      * System ID
      * User ID
      -Date and time

    For the cryptographic key:

      * System interrupt registers
      * System status registers
      * System counters

    The plain text can be an external randomly generated 64-bit value (8
characters input by the 550).

  The resulting pseudo-random number that is output will be the 64 bits of
cipher text generated in the 64-bit OFB mode.  The password generation
algorithm can either format this pseudo-random number into a password or use
it as an index (or indices) into a table and use the contents from this table
to form a password or a passphrase.


A.4 "User-Friendly" Passwords

  To assist users in remembering their passwords, the password generation
algorithm should generate passwords or passphrases that are "easy" to
remember.  Passwords formed by randomly choosing characters are generally
difficult to remember.  Passwords that are pronounceable are often easy to
remember, as are passphrases that are formed by concatenating real words into
a phrase or sentence.
                                                                 
			        15


                                 APPENDIX B

                        Password Encryption Algorithm


Password encryption is advocated as a password protection measure.  The
algorithm selected for this would be determined by the system environment.
Some environments may require that a classified encryption algorithm be used,
while for other environments an unclassified algorithm would be required.

B.1 Encryption Algorithm

A conventional or public key cryptographic algorithm which is configured as a
"one-way" encryption algorithm may be used for password encryption, but
whatever algorithm is used, the protection the encryption algorithm provides
should rely on its complexity.  If there is a key that can be used with the
algorithm to decrypt passwords, that key should not be stored in the ADP
system.

B.2 Assurance for Unique Encrypted Passwords

If a password encryption system depends only on the password and other fixed
information, there is a possibility that two different users will have
identical encrypted passwords.  A user who discovers another user with an
identical encrypted password will then know that the same password will work
for both user IDs even if they don't have identical plaintext passwords.  To
minimize this possibility, it is recommended that the encryption algorithm use
the ADP system name (in network environments) and the user's ID as factors in
the encryption.  (This can be easily accomplished by concatenating the system
ID, user ID and password, and then applying the encryption algorithm to the
resulting string.)
			        16



                                 APPENDIX C

                        Determining Password Length


The security afforded by passwords is determined by the probability that a
password can be guessed during its lifetime.  The smaller that probability,
the greater the security provided by the password.  All else being equal, the
longer the password, the greater the security it provides.  This appendix
reviews the mathematics involved in establishing how long a password should
be.

The basic parameters that affect the length of the password needed to provide
a given degree of security are:

L = maximum lifetime that a password can be used to log into the system.

P = probability that a password can be guessed within its lifetime, assuming
    continuous guesses for this period.

R = number of guesses per unit of time that it is possible to make.

S = password space, i.e., the total number of unique passwords that the
    password generation algorithm can generate.


C.1 Relationship

  Considering only the cases where S is greater than L x R and therefore P is
less than 1, the relationship between these parameters is expressed by the
equation:

  P = L x R                                                      
             [I]


  A detailed explanation of the derivation of this basic equation
is given in Appendix F.


C.2 Guess Rate

  Several factors contribute to the rate at which attempts can be made to gain
access to the data on a system when a valid password is not known.  First and
foremost is the protection given to the password data base itself.  If the
password data base is unprotected (i.e., can be read by anyone as ordinary
data), then "guessing" may not be required.

  If the password data base can be read.  but the passwords are encrypted (see
Appendix B), a very high guess rate may be possible by using a computer to try
a dictionary of possible passwords to see if ciphertext can be generated that
is the same as one in the password data base.  A similar situation frequently
occurs where only passwords are used to protect files.
 
			        16


  Finally, if the password data base has effective access controls and the
login procedure cannot be bypassed, the guess rate can be controlled by
setting limits on the number of login or other attempts that can be made
before terminating the connection or process.

C.3 Password Lifetime

  All other things being equal, the shorter the lifetime of a password, the
fewer the number of guesses that can be made and thus the greater the degree
of password security.  As stated in 4.2.2.1, the maximum password lifetime
should not exceed one year.

C.4 Password Space

  Password length and alphabet size are factors in computing the maximum
password space requirements.  Equation [2] expresses the relationship between
S, A, and M where:

  S = password space
  A = number of alphabet symbols
  M = password length

  S = AM                                                         
           [2]

  To illustrate: If passwords consisting of 4 digits using an alphabet of 10
digits (e.g., 0-9) are to be generated:

  S = 104

  That is, 10,000 unique 4-digit passwords could be generated.  Likewise, to
generate random 6-character passwords from an alphabet of 26 characters (e.g.,
AZ):

  S = 266

  That is 3.089 * 108 unique 6-character passwords could be
generated.

  "User-friendly" passwords (sometimes referred to as passphrases) could be
generated by using, for example, 3 symbols from an alphabet (dictionary) of
2000 symbols, where each symbol was a pronounceable word of 4, 5, or 6
characters.

  Using equation [2] and setting:

  A = 2000 symbols (words)
  M = 3

  Then S = 20003

  That is, 8 * 109 unique passwords could be generated where each password was
made up of 3 words taken from a dictionary of 2000 words.
                                                                 
			        19


C.5 A Procedure for Determining Password Length

  What is important in using passwords is how long to make the password to
resist exhaustive penetration attacks.  We can do this by using the following
procedure:

  a.  Establish an acceptable probability, P, that a password will be guessed
during its lifetime.  For example, when used as a login authenticator, the
probability may be no more than 1 in 1,000,000.  In another case, where very
sensitive data is involved, the value for P may be set at 10-20.

  b.  Solve for the size of the password space, 5, with the equation derived
from equation [1]

  S =  G                                                         
           [3]
       P

  where G    L x R

  c. Determine the length of the password, M, from the equation

       M =          log S                                        
           [4]
           log (number of symbols in the "alphabet")

  M will generally be a real number that must be rounded up or down to the
nearest whole number.  Examples of calculating many of the values described
above are given below.

C.6 Worked Examples

  An example shown here is drawn from a real network case.  The problem is to
determine the needed password length to reduce to an acceptable level the
probability that a password will be guessed during its lifetime.

  The network to which this is applied supports both a 300-baud and a
1200-baud service.  Experiments on the network have determined that it is
possible to make about 8.5 guesses per minute on the 300-baud service and 14,
guesses per minute on the 1200-baud service.  (The reason that the "guess
rate' for the 1200-baud service is not 4 times that of the 300-baud service is
that the system response time, which is not affected by the improved
transmission speed, becomes the limiting factor in how many guesses can be
accomplished in a given amount of time.)

  In this example, the arbitrary value of 10-6 is used for the probability (P)
of guessing the password in its lifetime.  As we will see below, the password
lifetime is not the critical factor here as long as the password is changed at
least once per year.

  The statement of the problem is to find a password length that will resist
being guessed with a probability of 1 in 106 in 1 year of continuous guesses.

  When three parameters in equation [1] are known, the fourth value can be
found.  To find the password space required by our examples, the following
parameters are given:

			        20



L is set for 6 months and 12 months.  P is set for 1 in 1,000,000 (acceptable
probability of guessing the password).  R is set at 8.5 guesses per minute
(guess rate possible with 300-baud service).

At 8.5 guesses per minute, the number of guesses per day would be
12,240.

Substituting 183 days for 6 months then using equation [3],

    S = G    183x12240 -  2.23992x1012 passwords
        P      -000001

The 12-month value is twice that of the 6-month case.

With this data, and using equation [4], we can determine the length of the
passwords as a function of the size of the alphabet from which they are drawn.
We will assume two alphabet sizes: a 26-letter alphabet and a
36-letter-and-number alphabet.


M  =  log (2.23992 x 1012) 8.72 (for 6-month lifetime)
            log 26

M  =  log (4.4676x1012)     8.94 (for 12-month lifetime)
            log 26

M  =  log (2.23992x1012)     7.93 (for 6-month lifetime)
            log 36

M  =  log (4.4676 x 1012) 8.13 (for 12-month lifetime)
            log 36

Table 1 presents the results.


                             TABLE 1

     MAXIMUM                   Length of Password
     LIFETIME
      (months)
                  26-Character alphabet   36-Character alphabet

        6                   9                       8
                  (rounded up from 8-72)  (rounded up from 7.93)

       12                   9                       8
                  (rounded up from 8.94)  (rounded down from 8.13)
                                                                 
        21


C.7 Passphrases
  A "passphrase" is a concatenation of words drawn from a dictionary.  The
dictionary is merely the collection of symbols making up the "alphabet" from
which the password is generated.  As an example, suppose the passphrase is
made up of words drawn from a dictionary of 4, 5 and 6 letter words.  There
are approximately 3,780 4-letter words, 7,500 5-letter words and 12,000
6-letter words in English.  The "alphabet size" for generating passphrases is
approximately 23,300.  We can compute how many words, drawn at random from the
dictionary of 23,300 words, are needed to produce a passphrase that will be
resistant to exhaustive attack with the probability of 1 x 10-6.

  We have to solve for 5 as before, and from that, solve for M, the length of
the password (i.e., number of alphabet symbols or words).

  For L = 12 months, 5=4.4676*1012, log S = 12.6500
  For L = 6 months, 5=2.2399*1012,  log S = 12.3502
  Log 23300 4.3669

  Using equation (4) we obtain:
  For L = 12 months  M 12.6500   3 (rounded from 2.89)
                       4.3669
  For L = 6 months  M  12.3502   3 (rounded from 2.82)
                       4.3669
  Thus, for the passphrase algorithm described, namely selection at random
from a dictionary of 23,300 words, only 3 words are needed in a passphrase to
obtain the desired resistance to exhaustive enumeration.  In using the
algorithm, each word of the phrase is drawn independently from the dictionary.
This may result in a word appearing more than once in the passphrase.
 
                                                                 
			        23


                           APPENDIX D
                 Protection Basis for Passwords


Passwords are used to prevent people who have physical access to an ADP system
from gaining access to data belonging to another user.  Thus, a password
should be protected in a manner that is consistent with the damage that might
be caused by its exposure to someone who has the opportunity to use it (i.e.,
has physical access to the ADP system terminals).  Exposure of a password to
someone who is physically prevented from attempting to use it is not a threat.

D.1 Systems Containing Only Unclassified Information

  Although an ADP system may process only unclassified information, it still
may require that the data be protected from unauthorized use.  Although the
password is unclassified, the obligation remains that the user protect this
password so that only those with a need-to-know can access the data.

D.2 Systems Containing Classified Information

  Passwords that are used in AD P systems that operate in the dedicated or
system high security modes (3) should not be classified, but should be
protected to the same degree as For Official Use Only information.  In this
case, there is no need to classify passwords since access to the area in which
the system resides is restricted to those with a clearance as high as the
highest classification level of the information processed.  A person who
obtained a password for a system running in dedicated or system high security
mode but who did not possess the proper security clearance would be unable to
gain physical access to the system and use the password.

  For systems operating in the multilevel security mode (3), passwords may or
may not have to be classified.
  When the ability to access classified information is based on the physical
protection of the terminal rather than on the identity of the user (i.e., when
all terminals are single-level devices), passwords should not be classified,
but should be protected to the same degree as For Official Use Only
information.  There is no need to classify passwords that can only be used on
single-level terminals, since physical access to single-level terminals is
controlled to the level associated with the terminal.  When the ability to
access classified information is based on the user's identity and is not
restricted by the level of the terminal (i.e., multilevel terminals), each
password must be classified to the highest level of the information to which
it provides access.  When multilevel terminals are used, the system determines
the user's access authorizations to classified material based on his identity,
and authenticates the identity by requiring a password.  Thus.  the ADP system
can protect the information it processes only to the extent that passwords are
protected.  For example, a user with a Secret clearance can access Secret
information.
			        24


Compromise of that user's password could result in the compromise of Secret
information; therefore, the password would be classified Secret.  In the case
of a system with multilevel terminals, disclosure of a Top Secret user's
password to a Secret user would allow the Secret user to login as the Top
Secret user and thus gain access to Top Secret information.  Disclosure of Top
Secret information to someone with only a Secret clearance can cause
exceptionally grave damage to the national security.  Since disclosure of the
Top Secret user's password could lead to this, the password must be classified
Top Secret (5).

Note that classified passwords must not be used on terminals that are not
authorized for data at the level of the password (e.g., a Top Secret password
must not be used on a Secret terminal).  The presence of both single-level and
multilevel terminals on a system may indicate the need for passwords at each
security level.  At a minimum, an unclassified password should be available
for use on terminals that are only authorized for unclassified data.
                                                                 
			        25


                           APPENDIX E

         Features for Use in Very Sensitive Applications


The following features can be used to enhance the security provided by a
password system.  Because they are somewhat "user-unfriendly," they are
recommended for environments only when there is a high threat of password
compromise.

E.1 One-Time Passwords

  One-time passwords (i.e., those that are changed after each use) are useful
when the password is not adequately protected from compromise during login
(e.g., the communication line is suspected of being tapped).  The difficult
part of using one-time passwords is in the distribution of the new passwords.
If a one-time password is changed often because of frequent use, the
distribution of new one-time passwords becomes a significant point of
vulnerability.  There are products on the market that generate such passwords
through a cryptographic protocol between the destination host and a hand-held
device the user can carry.

E.2 Failed Login Attempt Limits

  In some instances, it may be desirable to count the number of unsuccessful
login attempts for each user ID and to base password expiration and user ID
locking on the actual number of failed attempts.  (Changing a password would
reset the count for that user ID to zero.) For example, the password could be
identified as expired after 100 failed login attempts, and the user ID locked
after 500.
 
                                                                 
			        27


                           APPENDIX F

            On the Probability of Guessing a Password


Appendix C discusses the techniques for finding a password length that will
resist exhaustive enumeration over the lifetime of the password with a given
probability.  This appendix derives the probability of guessing a password
during its lifetime.  As in Appendix C, we use the parameters:

  L = password lifetime
  R = guess rate
  S = size of the password space
  P = probability of guessing a password during its lifetime

The total number of guesses, (G), that can be made during a password's
lifetime is:

  G = R x L                                                      
               [1]

At this point, we need to consider the relation of the size of the password
space, 5, to G.  Clearly, if 5 is so small that one could try all possible
passwords before the lifetime of the password expires, the probability of
guessing the password is l.  As a result, we consider only cases where 5 is
greater than G.  The probability question then is, "For the case where 5 is
greater than G, what is the probability that in G guesses the password will be
guessed?" This is the same as asking the question, "What is the probability
that in the lifetime of the password, it will be guessed?" The probability
sought is:

       How many ways one can make G guesses (of S objects)

P =                 that include the password

       How many different ways one can make G guesses of S objects Note that
the probability that is appealed to is of the simplest form.  It is derived
from the definition of probability that the probability of an event is given
by the number of ways the event can happen divided by the number of ways an
event can happen or fail.  We first observe that the total number of ways one
can make G guesses of 5 things is given by sCg (the combinatorial notation
that means the number of combinations of "s" things taken "g" at a time).
(Lower case letters are used with the combinatorial notation in order to make
the expressions more readable.) This is determined by:
      s!
    g!(s-g)!
Thus, if 5 - A B C,D,E, one could make 3 guesses in 5C3 different
ways,
5*4*3*2*1/3*2*1*2*1 10.

			        28


(Enumerating, they are ABC~ABD,ABE,ACD,ACE,ADE,BCD,BCE,BDE~C~~.) The problem
of finding the number of guesses of this total that include a specific
password, e.g., an "A", is addressed by considering a reduced set without the
specific password and asking how many ways one can make G guesses with the
reduced set.  Then, the total number of ways to make G guesses that include
the specified password is the difference between the two values.  This is
given by:

  sCg-(s-1)Cg                                                    
           [2]

That is, remove the designated password from the set 5, compute the number of
ways of making G guesses without the password, then consider the difference
between the two values.

If we ask in our example how many ways to make 3 guesses that do NOT include a
particular password from the set of 5 (say an "A"), this is given by:

  4C3  4*3*2*1/3*2*1*1 = 4

Enumerating for the specific case of an "A", they are BCD,BCE,BDE,CDE.

The number of ways to make 3 guesses that include the designated element is
10-4 6.  Thus, the probability of guessing a designated password in 3 guesses
is 6/10 or 6.


Simplification:

It is indeed fortuitous that there is a theorem in any number of books on
Probability Theory that states:

 nCr  (n-1)C(r-1) + (n-1)Cr                                      
           [3]

This may also be expressed as:

 nCr- (n-1)Cr  (n-1)C(r-1)                                       
           [4]

Substituting s for n and g for r we obtain the expression:

 (s-1)C(g-1)                                                     
           [5]

for the number of ways of making G guesses that include a specific password.
Then, the probability that a given password will be guessed during the
lifetime of that password is given by:

  P    (s-1)C(g-1)                                               
           [6]
         sCg
                                                               
			        29


Evaluating this expression gives:

            (s-1)!             (s-1)!
P =  (g-1)!((s-1)-(g1))! =  (g-1)1(s-g)!   =  g!(s-1)!  = g
             s!                  s!           (g-1)!s!    s
          g!(s-g)!           g!(s-g)!

This derivation of the probability of guessing a password during
its lifetime, i.e.,

P = G                                                         [8]


is important in that it allows us to derive the size of the
password space

  S = G                                                       [9]
      P

given an acceptable probability of not guessing the password
during its lifetime.
			        30
                                                                 



                          REFERENCES



1. Brown, R. L. Computer System Access Control Using Passwords,
1985 , Aerospace Corporation, 16 January 1984.

2. DoD Computer Security Center. Department of Defense Trusted
Computer System Evaluation Criteria, CSC-STD-00183, 15 August 1983.

3.  DoD Directive 5200.28, Security Requirements for Automatic Data Processing
(ADP) Systems, revised April 1978.

4.  Downey, P.  J.  Multics Security Evaluation: Password and File Encryption
Techniques, ESD-TR-74-193, Vol.  III, AD-A045279, AFSC Electronic Systems
Division, Hanscom AFB, Mass., June 1977.  

5.  Executive Order 12356, National Security Information, 6 April 1982.  

6.  Gasser, M.  A Random Word Generator for Pronounceable
Passwords, MTR-3006, ESD-TR-75-97, AD-A017676, MITRE Corp., Bedford,
Mass.,November 1975.  

7.  Wood, H.M.  The Use of Passwords for Controlled Access to Computer
Resources, NBS Special Publication 500-9, U.S.  Department of Commerce,
National Bureau of Standards, May 1977.

8. National Bureau of Standards. Federal Information Processing
Standards Publication 112, Password Usage Standard, 30 May 1985.

9. National Bureau of Standards. Federal Information Processing
Standards Publication 46, Data Encryption Standards, 15 January 1977.

10.  National Bureau of Standards.  Federal Information Processing Standards
Publication 81, DES Modes of Operation, 2 December 1980.

</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content"> this is another test

thanks

#hashtag
</div>
    <div class="message-hashtags">#hashtag</div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">-----BEGIN PGP PUBLIC KEY BLOCK-----

mE0EZnIFewECAKkHHyK+oZO6Ce5CJ8hbAn3kRytIF5S+M7gvgy0Zz+lKOuq5V1tU
KSQsBkdG4FE5hyka9fRwZjTKylUCAhxjuiMAEQEAAbQFaWx5YWeIdQQQAQgAKQUC
ZnIFewYLCQcIAwIJEOvpzL/wiJT7BBUICgIDFgIBAhkBAhsDAh4BAABjvwH/bbxo
4MjRM9r/X2/Nn8/G2aajYQzIVMzAw5Uk0uA5Q2+PLUm+41ghH6uZnAENAPAyoLFl
DkAzdgTo/lO7p/0IpbhNBGZyBXsBAgCttbwOApEcCq3Y8TZ4Azwesh4eGHNgHSyN
2wKUlLb35mc6SsnXlM3b5clI18YeML6EkYivYylwJRveRZmW2L1PABEBAAGIXwQY
AQgAEwUCZnIFewkQ6+nMv/CIlPsCGwwAAAQCAf9cdnxexf9+8iu5IH65hVSvK6u0
UG4JJaUPyjIhoSp/SGpF5rDu3Whsg1BUk7S1tCPk8JJdWZEgU4OMixU5ZyHdmE0E
Zow6PQECAJTTuzED5x5Zd29P8IZ2f3RA5AS6Pismg41A+ciiitHBG94TYjaKXL0g
0+wZhgODf1RcnGC4lsBzy2Kgce6FwaMAEQEAAbQFaWx5YWeIdQQQAQgAKQUCZow6
PQYLCQcIAwIJEJMNKD36XKdGBBUICgIDFgIBAhkBAhsDAh4BAAC+ywH9F/XCV7jk
BM2hlZctdQRN17+gxN3RFMB3GWKhJyWTnHxw2NR7VSVKsXgUljkW2EPhmKkxVATZ
k89zvcmhjzXEN7hNBGaMOj0BAf99kwxHJT6dC39EeYiCl280Zo37FKE5A7JK3PkL
zx8xrElWz+rCmBP2soR+3GxjFkuTSkC4CFG/8dOwrPd68PWbABEBAAGIXwQYAQgA
EwUCZow6PQkQkw0oPfpcp0YCGwwAALj1Af9qo8PYDNkpL3Atc2EAwpz8R/tZ/1Kw
aRdAyz5VSh6+xQHAv5j3AeR/1rFNVKi4IyPWHlPk1BFol2BaUA34O/G0
=b+XX
-----END PGP PUBLIC KEY BLOCK-----
</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

banana
-----BEGIN PGP SIGNATURE-----

wlwEAQEIABAFAmaZcu8JEN1kS26iRLO1AACXlgH+P9fmio8JZx7JwYLbHwNQ
8tVeDRNMxCqsQsLi6w5OcCKbOdTU3nCJIHZ6H70jmDuXt0S34oLXAJomGkaz
cc5wpA==
=LyNf
-----END PGP SIGNATURE-----
</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">A GUIDE TO WRITING THE SECURITY FEATURES USERS GUIDE FOR TRUSTED SYSTEMS
NCSC-TG-026 
Library No. 5-237,294 
Version t 
FOREWORD
The National Computer Security Center is publishing A Guide to Writing the Security Features User's Guide for Trusted Systems as part of the "Rainbow Series" of documents our Technical Guidelines Program produces. In the Rainbow Series, we discuss in detail the features of the Department of Defense Trusted Computer System Evaluation Criteria (DoD 5200.28-STD) and provide guidance for meeting each requirement. The National Computer Security Center, through its Trusted Product Evaluation Program, evaluates the security features of commercially-produced computer systems. Together, these programs ensure that organizations are capable of protecting their important data with trusted computer systems. 
A Guide to Writing the Security Features User's Guide for Trusted Systems expands on the Trusted Computer System Evaluation Criteria requirement for a Security Features User's Guide by discussing the intent behind the requirement and the relationship it has to other requirements in the Trusted Computer System Evaluation Criteria. The guide's target audience is the author of the Security Features User's Guide for a specific trusted system undergoing evaluation as a trusted product; however, many of the recommendations apply to any system that must satisfy the Trusted Computer System Evaluation Criteria requirements. 
As the Director, National Computer Security Center, 1 invite your recommendations for revision to this technical guideline. We plan to review and update this document periodically in response to the needs of the community. 
Please address any proposals for revision through appropriate channels to: 
National Computer Security Center 
9800 Savage Road 
Ft. George G. Meade, MD 20755-6000 
Attention: Chief, Standards, Criteria, and Guidelines Division 
Patrick R. Gallagher, September 1991 
Director 
National Computer Security Center 
INTRODUCTION
1.1 PURPOSE
This guideline explains the motivation and meaning of the Department of Defense Trusted Computer System Evaluation Criteria (TCSEC) requirement for a Security Features Users Guide (SFUG), which reads as follows: 
"A single summary, chapter, or manual in user documentation shall describe the protection mechanisms provided by the TCB, guidelines on their use, and how they interact with one another." [TCSEC; x.x.4.1] 
The reader is assumed to be the potential author of a SFUG; to be familiar with the basic principles of technical writing, computer science, and trusted systems; and to have a detailed understanding of the specific trusted system that will be described in the SFUG. 
1.2 SCOPE
This guideline identifies and discusses the considerations that influence the development and evaluation of a SFUG, such as its audience, content, and organization. It is intentionally descriptive, as opposed to prescriptive, in its discussion of the SFUG requirement. That is, it describes the various approaches to writing a SFUG that have been accepted by trusted product evaluators in the past, without making judgments about the "correct" ones to choose - although preferred approaches may be noted. 
Throughout this guideline there will be statements made that are not included in the TCSEC as requirements. These statements will fall into three categories. First, some describe a strongly recommended course of action: these statements will be prefaced by the word "should." Second, others describe one of several equally appropriate recommended courses of action: these statements will be prefaced by the word "could." Finally, a few suggest an optional course of action: these statements will be prefaced by the word "can." 
1.3 ORGANIZATION
The remainder of this guideline presents information that may be useful to a writer developing a SFUG. Chapter 2 discusses the developmental aspects of writing the SFUG, including the audience and possible packaging options, presentation styles, and the security topics that should be addressed in the SFUG (as derived from TCSEC feature requirements). Chapter 3 contains two example annotated outlines of SFUGs to illustrate some of the topics discussed in the body of the guideline and provide a starting point for the reader to develop a SFUG. The bibliography includes a list of the documents accepted as SFUGs for all products on the Evaluated Product List (EPL) at the time the guideline was published. 
2. DEVELOPING THE SECURITY FEATURES USER'S GUIDE
The primary purpose of a SFUG is to explain how the security mechanisms in a specific system work, so that users are able to consistently and effectively protect their information. To properly communicate this information, the SFUG author must identify the audience for the SFUG and the information that audience needs to use the security mechanisms in the system and then select an appropriate way to present the information. 
2.1 AUDIENCE AND PACKAGING
The SFUG requirement starts with "A single summary, chapter, or manual in user documentation . . .,, "User" in this context refers to a person who uses the system, but has no special privileges to affect the configuration of the system. The user for most general purpose trusted systems is often assumed to be a person with little or no computer experience, but this is not always the case. For example, the users of the UNIX system have traditionally been considered programmers or computer professionals with fairly extensive knowledge of computer concepts. In any system, the users are the audience for the SFUG and the SFUG author will have to characterize them to determine both the format and the level of discourse for the material presented in the SFUG. 
In many cases, the SFUG requirement is satisfied by changing an existing document, which is one of the reasons that the SFUG requirement is so general. 
As stated in the requirement, the SFUG could be: 
 A summary of the security features and user responsibilities, 
 A chapter devoted to these issues, or 
 A whole manual devoted to security. 
Some presentation schemes that previous participants in the Trusted Product Evaluation Program have used include: 
A separate manual devoted to the general user of the system that covers the security features and responsibilities pertaining to users. This is usually the best choice when a document of this sort is already in place and the security functions have always been present in the system in some form anyway. For a system in which user services are provided by individual subsystems, one of which provides all the security functionality, and the user guide is the collection of user guides `for the individual subsystems, the SFUG would most likely be a stand-alone manual addressing only the security issues. 
 A subsection of the manual produced to satisfy the Trusted Facility Manual (TFM) requirement of the TCSEC. From a security standpoint, this is considered unwise, since it tends to make the system configuration and vulnerability information available to anyone looking for information on how to use the security features of the system. From a documentation standpoint, it seems the easiest, since it places all of the security discussion in one place and allows a certain amount of synergy in the writing process, i.e., privileged users do many of the same activities as general users. This approach eliminates the need to document those facilities in two places. 
 A chapter or an appendix of a user manual that discusses the user's security responsibility and then provides an index to the detailed discussions of individual functions that are already part of the general user manual. An extension of this could be a small pamphlet that does the same thing but can be reproduced separately and given out as needed - something like a pocket guide to system security. 
Trusted product evaluators tend to favor centralization of information, because that makes it easier to determine whether the system satisfies the TCSEC (Orange Book) requirements. Given that bias, bullet one would usually be the most preferred option, since it satisfies the requirement in one unique place. Bullet two is a less desirable option, because, in addition to the procedural security considerations, it requires some discrimination to identify which parts of the document satisfy the SFUG requirement and which parts satisfy the TFM requirement. Bullet three is least desirable for two reasons. First, it involves pointers to other information, making it more cumbersome for both evaluators and users to get to some aspects of the information. Second, there might be a tendency to make the document so terse that it excludes some information that is relevant to system security. 
2.2 PRESENTATION
The SFUG provides the users of the system with the necessary background and specific information to use the protection features of the system correctly. Its purpose is twofold. First, it provides the information that a user needs to enter the system and start working-within the system security constraints. Second, it explains the user's role in maintaining the security of the system. Its scope should be limited to documenting only the features available to all users and only the responsibilities that all users have for system security. To accomplish this purpose, within the scope, the SFUG should explain what security means in the system, what security features are present and why, how the features work, and how to use the features properly. The SFUG should be clear, concise, and complete to increase its readability. 
This information can be organized either by the security features present in the system or by the tasks performed by a user that require the use of these features. A feature-oriented presentation is more natural to a user who is already familiar with the system. In the SFUG, this organization would usually look like the TCSEC itself, with descriptions of each feature required by the TCSEC and explanations of the commands that make those features available to users. A task-oriented presentation is the more common approach taken in most user manuals, since it is oriented towards the specific actions that are necessary to enter a system and start working. Such a presentation will often take the form of a tutorial that describes the interactions that a user will usually have with the system, e.g., logging on, setting file access, changing the password, etc. 
2.3 CONTENT
Because this guideline is devoted to explaining a TCSEC requirement, it will consider the content of a SFUG only from the perspective of the features required by the TCSEC that should be documented in the SFUG. OtheLr security-relevant features not addressed by the TCSEC (e.g., object downgrading or network commands) might also be included in the SFUG, but will not be discussed in this guideline. 
The remainder of this section will list the features required by the TCSEC, identify the specific requirements that define them, and discuss how they apply to the SFUG. Many of the requirements cited use the acronym TCB, which expands to Trusted Computing Base. As defined in the TCSEC, the TCB is: 
"The totality of protection mechanisms within a computer system-including hardware, firmware, and software-the combination of which is responsible for enforcing a security policy. A TCB consists of one or more components that together enforce a unified security policy over a product or system. The ability of a TCB to correctly enforce a security policy depends solely on the mechanisms within the TCB and on the correct input by system administrative personnel of parameters (e.g., a user's clearance) related to the security policy." [TCSEC, p. 116] 
2.3.1 TECHNICAL SECURITY POLICY]
The technical security policy is the description of the access control model that the system enforces. This description can be either informal or formal for classes Cl through BI, but classes B2 to Al must have a formal description. The TCSEC design documentation requirement mandates that the informal description exist for all criteria classes where it states: 
"Documentation shall be available that provides a description of the manufacturer's philosophy of protection . . .," [x.x.4.4] 
Starting at BI, the design specification and verification requirement strengthens this notion of a technical security policy with the explicit requirement that: 
"An informal or formal model of the security policy supported by the TCB shall be maintained over the life cycle of the ADP system and demonstrated to be consistent with its axioms." 
[x.x.3.2.2] 
At class B2, the design specification and verification requirement is changed to mandate a formal technical security policy model. Classes 83 and Al incorporate new requirements for additional supporting documentation thatk makes it possible to trace the basis for each feature in the system from the technical security policy to the implementation. 
In the context of the TCSEC, neither the philosophy of protection nor the formal model have to be available to the user; however, the fact that the features of the system flow from these fundamental statements makes either one an appropriate starting point for describing how the system works. The philosophy of protection is probably the better choice for the SFUG, since it is usually written in a more intuitive style than a precisely stated security policy statement. In either case, the technical policy would be presented early in the SFUG to provide the overall context for the rest of the discussion, effectively becoming the thesis for the SFUG. 
2.3.2 IDENTIFICATION AND AUTHENTlCATlON
The single largest and most crucial section of the SFUG, both from the perspective of the TCSEC and of overall system documentation,is the section that discusses how users identify and authenticate themselves (i.e., logon) to the system. The process of identification and authentication (l&A) defines the identity of the subject that the TCB creates to act on the user's behalf. For division B and A multilevel systems, the I&A process defines the upper and lower bounds on the security level of the subject as well. All subsequent access control decisions depend on this information being correct. The SFUG should therefore be very specific in describing both the l&A procedures and the user's responsibilities for protecting any information that is expected to be kept secret (e.g., passwords or personal identification numbers). 
The TCSEC requirement for division C computer systems is shown below, with bold type showing the C2 requirements that go beyond those at Cl. 
"The TCB shall require users to identify themselves to it before beginning to perform any other actions that the TCB is expected to mediate. Furthermore, the TCB shall use a protected mechanism (e.g., passwords) to authenticate the user's identity. The TCB shall protect authentication data so that it cannot be accessed by any unauthorized user. The TCB shall be able to enforce individual accountability by providing the capability to uniquely identify each individual ADP system user. The TCB shall also provide the capability of associating this identity with all auditable actions taken by that individual." [2.2.2.1] 
Based on this requirement, the SFUG for a division C system should describe the identification process, including the use of a protected authentication mechanism. To complement the protection that the TCB must give the authentication data, the SFUG should make it clear that the user must protect the data too, for example, by not sharing a password with other users or writing it down on a sheet of paper next to the terminal. 
For divisions B and A, the addition of multiple security levels changes the requirement, primarily by requiring the use of a user'sclearance as a bound on the security label of any subject that the TCB creates for that user. The BI requirement, which does not change for the higher classes, is shown below, with bold type showing additional wording and struck-out type showing wording that was deleted. 
"The TCB shall require users to identify themselves to it before beginning to perform any other actions that the TCB is expected to mediate. Furthermore, the TCB shall maintain authentication data that includes information for verifying the identity of individual users (e.g., passwords) as well as information for determining the clearance and authorizations of individual users. This data shall be used by the TCB to authenticate the user's identity and to ensure that the security level and authorization of subjects external to the TCB that may be created to act on behalf of the individual user are dominated by the clearance and authorization of that user. 
The TCB shall protect authentication data so that it cannot be accessed by any unauthorized user. The TCB shall be able to enforce individual accountability by providing the capability to uniquely identify each individual ADP system user. The TCB shall also provide the capability of associating this identity with all auditable actions taken by that individual." [3.1.2.1] 
For all division B and A systems, the SFUG should incorporate a discussion of the relationship between a user's clearance (i.e., his or her general authorization to see information of a particular sensitivity-whether or not it is electronic) and the security level that the TCB associates with a particular subject (e.g., computer process or interactive session) that is acting on that user's behalf. Additionally, the practical consideration of how to establish the security level of that subject, for example, by using a logon option or a specific terminal, should be explained in the SFUG. 
Starting at B2, there is an additional requirement for a trusted path to strengthen the confidence of both the user and the TCB that the l&A process is happening correctly. This requirement is shown below in both the B2 and B3/Al forms. 
"The TCB shall support a trusted communication path between itself and user for initial login and authentication. 
Communications via this path shall be initiated exclusively by a 
user." [3.2.2.1.1(B2)] 
"The TCB shall support a trusted communication path between itself and users for use when a positive TCB-to-user connection J5 required (e.g., Iogin, change subject security level). Communications via this trusted path shall be activated exclusively by a user or the TCB and shall be logically isolated and unmistakably distinguishable from other paths." [3.3.2.1.1 
(B3/Al)] 
Trusted path is useless if it is not used; therefore, the SFUG should be written so that the user understands how to initiate the trusted path, especially at logon, and why it is important to do so. For systems that satisfy the B3 trusted path requirement, the SFUG should also explain how the initiation of a trusted path during a session, whether by the user or the TCB, affects the currently running subject, as well as how to recognize the trusted path. 
2.3.3 DISCRETIONARY ACCESS CONTROL FACILITY
The discretionary access control (DAC) facility provides the mechanism by which the individual user can control access to his or her data. Some form of DAC is required for every class of the TCSEC. After the procedures for identifying and authenticating themselves to the system, the DAC facilities will be the aspects of the system security of most interest to most users. 
The DAC facility is first defined by the Cl DAC requirement that: "The TCB shall define and control access between named users and named objects (e.g., files and programs) in the ADP system. The enforcement mechanism (e.g., self/group/public controls, access control lists) shall allow users to specify and control sharing of those objects by named individuals or defined groups or both." [2.1.1.1] At C2 this requirement is enhanced to read (bold type shows added words): "The TCB shall define and control access between named users and named objects (e.g., files and programs) in'the ADP system. The enforcement mechanism (e.g., self/group/public controls, access control lists) shall allow users to specify and control sharing of those objects by named individuals, or defined groups of individuals, or by both, and shall provide controls to limit propagation of access rights. The discretionary access control mechanism shall, either by explicit user action or by default, provide that objects are protected from unauthorized access. These access controls shall be capable of including or excluding access to the granularity of a single user. Access permission to an object by users not already possessing access permission shall only be assigned by authorized users." [2.2.1.1] 
After this it remains the same until B3, when it is changed to read (bold type shows added words, struck-out type shows deleted words): 
"The TCB shall define and control access between named users and named objects (e.g.,files and programs) in the ADP system. The enforcement mechanism (e.g., self/group/public controls, access control lists) shall allow users to specify and control sharing of those objects by named individuals, or defined groups of individuals, or by both, and shall provide controls to limit propagation of access rights. The discretionary access control mechanism shall, either by explicit user action or by default, provide that objects are protected from unauthorized access. These access controls shall be capable of specifying, for each named object, a list of named individuals and a list of groups of named individuals with their respective modes of access to that object. 
Furthermore, for each such named object, it shall be possible to specify a list of named individuals and a list of groups of named individuals for which no access to the object is to be given. including or excluding access to the granularity of a single user. Access permission to an object by users not already possessing,,access permission shall only be assigned by authorized users. [3.3.1.1] 
For any version of this requirement, the goal for the SFUG author is the same -to describe to users how to use the DAC enforcement mechanism to control access to the objects that they own. The SFUG should provide enough information for the user to understand what a named object, a named user, and a group are, as well as what types of objects can be controlled with DAC. It should also explain how a new user or group is defined to the system. The SFUG should also describe the process by which access rights are initially determined and then propagated. Finally, the SFUG should describe the system commands and procedures for using the DAC facility. 
2.3.4 ELECTRONIC LABELS
The distinguishing feature of all division B and A computer classes is the electronic label. An electronic label is an attribute of each subject and object under TCB control that indicates the sensitivity of the information that a subject is authorized to see or that is contained in an object. The real world equivalents of these concepts are security clearances and classification markings. Many users who are familiar with these real world examples have trouble adapting to electronic labels; therefore, the SFUG written for a multilevel system should discuss labels and their effect on a user's actions. The basic label requirement is defined by the following words at Bl: "Sensitivity labels associated with each subject and storage object under its control (e.g., process, file, segment, device) shall be maintained by the TCB. These labels shall be used as the basis for mandatory access control decisions. In order to import non-labeled data, the TCB shall request and receive from an authorized user the security level of the data, and all such actions shall be auditable by the TCB." [3.1.1.3] At B2, the first sentence is changed to read: "Sensitivity labels associated with each ADP system resource (e.g., subject, storage object, ROM) that is directly or indirectly accessible by subjects external to the TCB shall be maintained by the TCB." [3.2.1.3] This reflects the general B2 through Al requirement that all computer resources be under the control of the TCB. 
Another label-related requirement that affects the users of a system is the one for labeling human-readable output, which states that: 
"The ADP system administrator shall be able to specify the printable label names associated with exported sensitivity labels. The TCB shall mark the beginning and end of all human-readable, paged, hardcopy output (e.g., line printer output) with human-readable sensitivity labels that properly represent the sensitivity of the output. The TCB shall, by default, mark the top and bottom of each page of human- readable, paged, hardcopy output (e.g., line printer output) with human-readable sensitivity labels that properly represent the overall sensitivity of the output or that properly represent the sensitivity of the information on the page. The TCB shall, by default and in an appropriate manner, mark other (forms of human-readable output (e.g., maps, graphics) with human- readable sensitivity labels that properly represent the sensitivity of the output. Any override of these marking defaults shall be auditable by the TCB." [3.1.1.3.2.3] The above requirement is the same for classes Bl through Al. 
These two requirements, for subject sensitivity labels and labeled human-readable output, apply to any multilevel system; therefore, the SFUG for all B and A level systems should, at the least, explain: 
 How labels are attached to subjects and objects, 
 The relationship between the "clearance" that a user has and the label that is associated with a particular computer session, and 
 The reason for job and page labels on printed output and terminal or window labels on computer displays (as well as cautions about disabling the display of such labels). 
The last requirement that affects users is one for subject sensitivity labels that requires that: 
"The TCB shall immediately notify a terminal user of each change in the security level associated with that user during an interactive session. A terminal user shall be able to query the TCB as desired for a display of the subject's complete sensitivity label." [3.2.1.3.3] 
The above requirement applies to classes B2 through Al; therefore, the SFUG for these systems should explain the mechanism used to notify a user of a security level change. 
2.3.5 MANDATORY ACCESS CONTROL FACILITY
Closely associated with, but separate from, the requirement for labels is the requirement for mandatory access control (MAC). MAC refers to the set of rules that control a subject's access to an object based on the label attached to each. 
The MAC facility is first defined by the BI MAC requirement that: "The TCB shall enforce a mandatory access control policy over all subjects and storage objects under its control (e.g., processes, files, segments, devices). These subjects and objects shall be assigned sensitivity labels that are a combination of hierarchical classification levels and non- hierarchical categories, and the labels shall be used as the basis for mandatory access control decisions. The TCB shall be able to support two or more such security levels. The following requirements shall hold for all accesses between subjects and objects controlled by the TCB: A subject can read an object only if the hierarchical classification in the subject's security level is greater than or equal to the hierarchical classification in the object's security level and the non- hierarchical categories in the subject's security level include all the non-hierarchical categories in the object's security level. A subject can write an object only if the hierarchical classification in the subject's security level is less than or equal to the hierarchical classification in the object's security level and all the non-hierarchical categories in the subject's security level are included in the non-hierarchical categories in the object's security level. Identification and authentication data shall be used by the TCB to authenticate the user's identity and to ensure that the security level and authorization of subjects external to the TC8 that may be created to act on behalf of the individual user are dominated by the clearance and authorization of that user." [3.1.1.4] 
For classes B2 through Al, the requirement is enhanced to reflect the pervasive TCB control required by these higher classes. (The bold type in the following quote shows the additional wording, while the struck-out type shows the phases deleted.) 
"The TCB shall enforce a mandatory access control policy over all resources (i.e., subjects, storage objects, and 1/0 devices) that are directly or indirectly accessible by subjects external to the TCB. 
These subjects and objects shall be assigned sensitivity labels that are a combination of hierarchical classification levels and non-hierarchical categories, and the labels shall be used as the basis for mandatory access control decisions. The TCB shall be able to support two or more such security levels. The following requirements shall hold for all accesses between all subjects external to the TCB and all objects directly or indirectly accessible by these subjects: A subject can read an object only if the hierarchical classification in the subject's security level is greater than or equal to the hierarchical classification in the object's security level and the non-hierarchical categories in the subject's security level include all the non-hierarchical categories in the object's security level. A subject can write an object only if the hierarchical classification in the subject's security level is less than or equal to the hierarchical classification in the object's security level and all -the non- hierarchical categories in the subject's security level are included in the non-hierarchical categories in the object's security level. Identification and authentication data shall be used by the TCB to authenticate the user's identity and to ensure that the security level and authorization of subjects external to the TCB that may be created to act on behalf of the individual user are dominated by the clearance and authorization of that user." [3.2.1.4] 
Because the TCB, rather than the user, controls the actual interaction between the labels of subjects and objects, the SFUG only needs to explain to users how MAC constrains their actions. This discussion is probably most natural under the section that addresses the technical security policy. In most cases, a user can have only one effect on the MAC policy-to change the label for a session, which is already described under either the discussion of identification and authentication or labels. 
2.3.6 TRUSTED FACILITY MANAGEMENT
Beginning at B2, there is a TCSEC requirement that: "The TCB shall support separate operator and administrator functions." [3.2.3.1.4] 
This mandates a separation of duties in the administration of computer systems that are supposed to be protecting information. This corresponds to the natural separation of duties found in most human activity. Although this is not a requirement until B2, many sites that are concerned about security are instituting programs `rvhere the responsibility for security administration of the computer system is centralized in a person with the title of computer, or information system, security officer (CSO or 1550, respectively). Whether the computer system being described in the SFUG satisfies the trusted facility management requirement or not, the author of the SFUG for that system may want to postulate the existence of such a position to represent the entity that is responsible for security issues that are outside the control of the users. This both allows the SFUG to be written in a more active voice and simplifies the job of conveying distinctions between user security responsibilities and site management security responsibilities. 
3. EXAMPLES OF SFUG PRESENTATION STYLES
This chapter presents two sample stand-alone SFUGs to show what could go into a SFUG and possibly give the reader some ideas for organizing a system specific SFUG. The actual contents and organization of a real SFUG will be different to reflect the specific mechanisms of the individual system and the organization of the rest of the system documentation. The first example uses a feature-oriented style presentation, while the second shows a task-oriented style. 
In addition to these generic examples, the reader may find it helpful to review the SFUGs of previously evaluated systems to see what worked for them. Entries 2 through 16 in the bibliography list the Final Evaluation Reports (FERs) for products on the Evaluated Products List that had published FERs at the time this guideline was printed. Each entry is annotated with the document(s) identified in the FER as satisfying the SFUG requirement for that product. 
THE FEATURE-ORIENTED SFUG
At a high level, the feature-oriented example SFUG is arranged in the following fashion: 
1. INTRODUCTION TO THE SFUG 
2. SYSTEM SECURITY OVERVIEW 
2.1 SYSTEM PHILOSOPHY OF PROTECTION 
2.2 DEFINITION OF TERMS AND SERVICES 
2.3 THE INFORMATION SYSTEM SECURITY OFFICER 
2.4 USER SECURITY RESPONSIBILITIES 
3. SECURITY-RELATED COMMANDS FOR USERS 
3.1 USER IDENTIFICATION AND AUTHENTICATION 
3.1.1 Trusted Path 
3.1.2 Logging On to the System 
3.1.3 Password Considerations 
3.1.4 Changing Group Membership 
3.1.5 Changing Current MAC Authorizations 
3.1.6 Logging Off of the System 
3.1.7 I&A Errors and Their Causes 
3.2 DISCRETIONARY ACCESS CONTROL FACILITIES 
3.2.1 Setting DAC on Named Objects 
3.2.2 Default DAC Protection 
3.2.3 DAC Groups 
3.2.4 DAC Errors and Their Causes 
3.3 MANDATORY ACCESS CONTROL FACILITIES 
3.3.1 Printing Labeled Objects 
3.3.2 Accessing Single-Level Devices 
3.3.3 Accessing Multilevel Devices 
3.3.4 Downgrading Labeled Objects 
3.3.5 MAC Errors and Their Causes 
3.4 OBJECT MANIPULATION FACILITIES 
3.4.1 Object Creation, Reuse, and Deletion 
3.4.2 Importing Machine-Readable Objects 
3.4.3 Exporting Machine-Readable Objects 
3.4.4 Determining the Properties of Objects 
3.4.5 Object Manipulation Errors and Their Causes 
The annotated outline follows. 
1. INTRODUCTION TO THE SFUG
This part of the SFUG should identify what the SFUG is, who it is written for, what it will cover, and where to go for more information, if needed. 
2. SYSTEM SECURITY OVERVIEW
This section provides the background on the overall operation of the security controls in the system so that users can then understand the options and actions of individual security-relevant commands. 
2.1 SYSTEM PHILOSOPHY OF PROTECTION
This section should describe the general environment for which the system is designed and briefly explain how this environment motivates the approach to protecting information stored in the system. The purpose of this section is to lay the foundation for the user's understanding of the system's security features, with later sections detailing what specific security services are available and when and how to use them. 
2.2 DEFINITION OF TERMS AND SERVICES
This section should first introduce the terms that will be used to describe the security services available in the system and then proceed to introduce those services, without detailing exactly how they are used. Recommended topics for this section are: 
 An explanation of the general concepts of subjects and objects, followed by the identification of the subjects and objects in the system. 
 An explanation of object reuse and its role in protecting information in the system. 
 An explanation of the components of the l&A (identification and authentication) process (e.g., user-id, password, or smartcard) in the system and the importance of l&A to system security. 
 An explanation of DAC, groups, privileges, protection bits/ACLs, and any other terms and concepts related to the system's DAC policy, followed by a description of how the DAC policy applies to the systern subjects and objects. 
 An explanation of MAC, security labels, sensitivity levels, categories, authorizations, and any other terms and concepts related to the system's MAC policy, followed by a description of how the MAC policy applies to the system subjects and objects. 
2.3 THE INFORMATION SYSTEM SECURITY OFFICER
This section discusses the role of the Information System Security Officer (1550) in maintaining the security of the system. It can also explain which problems should be reported to the 1550 and which should be reported to the system administrator (if the roles are separate). If the format of the SFUG allows it, this section could have space for site-specific notes on the 1550/user relationship. 
2.4 USER SECURITY RESPONSlBlLlTlES
This section discusses the user's responsibilities with respect to properly using the system security features. This would optimally be a tutorial that teaches effective use of the system security services, but any presentation that relates the security services to the user's day-to-day use of the system is appropriate. Some issues that might be addressed are: 
 Authentication token (e.g., password or smartcard) protection. 
 Warnings about leaving a terminal unattended. 
 Procedures for "locking" a process when the terminal must be left unattended, but logged in. 
 Default DAC access for named objects (e.g., files andkdirectories). 
 Cautions about using programs that are not part of the standard system configuration (e.g., utilities or applications that have not been reviewed and tested by the system administrator(s)). 
 Cautions about the effect of network access on system and data security. 
3.SECURITY-RELATED COMMANDS FOR USERS
This section comprises the majority of the SFUG since it describes in detail the commands and procedures for actually using the system. 
3.1 USER IDENTIFICATION AND AUTHENTICATION
This section should step through the procedures for logging on to and off of the system and for manipulating privileges and participation in the system. Additionally, any of the errors that might occur during the use of these commands and the corrective actions should be described here. 
3.1.1 Trusted Path
In 82 and above systems, the first thing that a user will have to do to Iogon is establish a trusted path between his terminal and the system TCB. This section should describe that process. For 83 and Al systems, this trusted path is available for any direct interaction between the TC8 and the user; therefore, in-session invocation of the trusted path and its effects on currently executing processes should be described here. 
3.1.2 Logging On to the System
The procedure for logging on to the system should be described. If the system has MAC, the procedures for logging on with specific, non-default authorizations should be described. 
3.1.3 Password Consideration
The procedures and commands for setting, changing, and protecting passwords should be described. 
3.1.4 Changing Group Membership
In systems with the concept of DAC groups, the mechanisms for users to specify the group membership(s) that should be used in making DAC access decisions (if such capability is present) should be described. 
3.1.5 Changing Current MAC Authorizations
In systems with MAC, if the user can change their current authorization level and category set without logging off, the mechanism and procedure should be described. 
3.1.6 Logging Off of the System
The command or procedure for logging off the system should be described. 
3.1.7 I&A Errors and Their Causes
The possible error messages that can occur when l&A commands are improperly invoked should be noted and the correct or expected inputs should be explained. 
3.2 DISCRETIONARY ACCESS CONTROL FACILITIES
This section should describe the DAC-related commands and procedures for the system. This section will be present in some form at all levels of the criteria. 
3.2.1 Setting DAC on Named Objects
This section should describe how users can set the discretionary access permissions, and what the permissions mean, for the different types of named objects in the system. 
3.2.2 Default DAC Protection
The means for determining and setting the default discretionary access controls on user controlled or owned named objects should be described. 
3.2.3 DAC Groups
When the capability exists for users to define groups of users for the purpose of lDAC, the mechanisms for defining these groups should be described. 
3.2.4 DAC Errors and Their Causes
The possible error messages that can occur when DAC commands are improperly invoked should be noted and the correct or expected inputs should be explained. 
3.3 MANDATORY ACCESS CONTROL FACILITIES
This section is for systems in the B and A classes. It describes the commands that a general user will need for dealing with labeled objects. 
3.3.1 Printing Labeled Objects
This section describes the mechanism for printing or otherwise producing non-electronic versions of labeled objects. Of specific interest is the mechanism that would be used for overriding the default printing of the object's label in human-readable form. The description of this capability could be accompanied by a discussion of the security considerations that go with its use. 
3.3.2 Accessing Single-Level Devices
This section should discuss the constraints on the use of single-level devices in the presence of multiple authorization levels. For example, this section could discuss how the TCB determines a user's access to a single-level device based on the user's authorization level. 
3.3.3 Accessing Multilevel Devices
This section should discuss the rules for the interaction between users at multiple authorization levels and multilevel devices. 
3.3.4 Downgrading Labeled Objects
Although it is not a part of TCSEC evaluations, if the system offers an object downgrade facility that is available to the target audience of the SFUG, this facility and cautions on its proper use should be described. 
3.3.5 MAC Errors and Their Causes
The possible error messages that can occur `when MAC commands are improperly invoked should be noted and the correct or expected inputs should be explained. 
3.4. OBJECT MANIPULATION FACILITIES
This section should discuss the commands and mechanisms available for dealing with objects. 
3.4.1 Object Creation, Reuse, and Deletion
This section should discuss how the system creates, reuses, and deletes user visible objects. Any commands which allow the creation of user owned objects (e.g., mailboxes or blank files) should be described. The information on object reuse should be for informational purposes only, since all C2 and above systems are required to do object reuse without user intervention. For systems with MAC, this section should describe how sensitivity labels and discretionary access lists are assigned to an object. 
3.4.2 Importing Machine-Readable Objects
The mechanisms for a user to introduce a machine-readable object into the system from an external source (e.g., tape, removable diskette, or network) and assign discretionary and mandatory access control properties to it should be described if such a facility exists. 
3.4.3 Exporting Machine-Readable Objects
The mechanisms for a user to export a machine readable object from the system to an external source (e.g., tape, removable diskette, or,network), along with its discretionary and mandatory access control properties, should be described if such a facility exists. 
3.4.4 Determining the Properties of Objects
The commands or mechanisms for determining the discretionary and mandatory access control properties of an object should be described. 
3.4.5 Object Manipulation Errors and Their Causes
The possible error messages that can occur when object manipulation commands are improperly invoked should be noted and the correct or expected inputs should be explained. 
THE TASK-ORIENTED SFUG
At a high level, the task-oriented example SFUG is arranged in the following fashion: 
1. INTRODUCTION TO THE SFUG 
2. SYSTEM SECURITY OVERVIEW 
2.1 SYSTEM PHILOSOPHY OF PROTECTION 
2.2 DEFINITION OF TERMS AND SERVICES 
2.3 THE SYSTEM SECURITY OFFICER 
2.4 USER SECURITY RESPONSIBILITIES 
3. SECURITY-RELATED COMMANDS FOR USERS 
3.1 SYSTEM ACCESS 
3.1.1 Session Initiation 
3.1.2 Changing the Session Profile 
3.1.3 Changing the User Profile 
3.1.4 Potential Access Problems and Solutions 
3.2 ACCESS CONTROL FACILITIES 
3.3 PROTECTING REMOVABLE OBJECTS 
3.4 LOGGING SECURITY-RELEVANT EVENTS 
The annotated outline follows. 
1. INTRODUCTION TO THE SFUG
This part of the SFUG should identify what the SFUG is, who it is written for, and what it will cover. It might also explain where the SFUG fits in with the rest of the user documentation. If appropriate, it can also describe the relationship between the SFUG and the TFM. 
2. SYSTEM SECURITY OVERVIEW
This section provides the background on the overall operation of the security controls in the system so that users can then understand the options and actions of individual security-relevant commands. 
2.1 SYSTEM PHILOSOPHY OF PROTECTION
This section should describe the general environment for which the system is designed and briefly explain how this environment motivates the approach to protecting information stored in the system. The purpose of this section is to lay the foundation for the user's understanding of the system's security features, with later sections detailing what specific security services are available and when and how to use them. 
2.2 DEFINITION OF TERMS AND SERVICES
This section should first introduce the terms that will be used to describe the security services available in the system and then proceed to introduce those services, without detailing exactly how they are used. Recommended topics (and the criteria classes for.which they are relevant) for this section are: 
 An explanation of the general concepts of subjects and objects, followed by the identification of the subjects and objects in the system. 
 An explanation of object reuse and its role in protecting information in the system. 
 An explanation of the components of the I&A (identification and authentication) process (e.g., user-id, password, or smartcard) in the system and the importance of I&A to system security. 
 An explanation of DAC, groups, privileges, protection bits/ACLs (access control lists), and any other terms and concepts related to the system's DAC policy, followed by a description of how the DAC policy applies to the system subjects and objects. 
 An explanation of MAC, security labels, sensitivity levels, categories, authorizations, and any other terms and concepts related to the system's MAC policy, followed by a description of how the MAC policy applies to the system subjects and objects. 
2.3 THE INFORMATION SYSTEM SECURITY OFFICER
This section discusses the role of the information system security officer (1SS0) in maintaining the security of the system. It can also explain which problems should be reported to the 1SS0 and which should be reported to the system administrator (if the roles are separate). If the format of the SFUG allows it, this section could have space for site-specific notes on the 1SS0/user relationship. 
2.4 USER SECURITY RESPONSIBILITIES
This section discusses the user's responsibilities with respect to properly using the system security features. This would optimally be a tutorial that teaches effective use of the system security services, but any presentation that relates the security services to the user's day-to-day use of the system is appropriate. Some issues that might be addressed are: 
 Authentication token (e.g., password or smartcard) protection. 
 Warnings about leaving a terminal unattended. 
 Procedures for "locking" a process when the terminal must be left unattended, but logged in. 
 Default DAC access for named objects (e.g., files and directories). 
 Cautions about using programs that are not part of the standard system configuration (e.g., utilities or applications that have not been reviewed and tested by the system administrator(s)). 
 Cautions about the effect of network access on system and data security. 
3. SECURITY-RELATED COMMANDS FOR USERS
This section comprises the majority of the SFUG since it describes in detail the commands and procedures for actually using the system. It should describe both the usage of the commands and reemphasize their role as tools to protect information stored on the system. For example, this part might consist of command reference pages (e.g., UNIX "man" pages) grouped by subject, possibly with a brief introduction at the beginning of each subject area. Alternatively, this section could contain general descriptions of the operation and options of individual commands or groups of commands, along with pointers to the detailed documentation of the invocation sequence(s) for the commands. 
3.1 SYSTEM ACCESS
This section should explain the procedures for logging on and off the system. It should also discuss how the TCB assigns privileges and authorizations during the login process and how the user can change them during the session (if the system allows in-session changes). This section might also discuss how users can prevent and detect compromise of their accounts. For systems that provide trusted path during a session, this section of the SFUG should describe the mechanism for invoking the trusted path and the effect of the invocation on the currently running process. Finally, the errors that might occur during the use of these commands and corrective actions should be described here. 
3.1.1 Session Initiation
This section should describe the procedures that a user goes through to establish a session with the system. In B2 nd above systems, this discussion will start by describing how a user establishes a trusted path between the terminal and the TCB. For any system, it will discuss the procedure for presenting the identification and authentication tokens (typically a user-id and password) to the system so that the system can establish a subject to act on behalf of the user. When the login process provides the means for overriding the default group/project and subject sensitivity level, the use of these options should be described. 
3.1.2 Changing the Session Profile
When the system provides the facilities for the user to dynamically modify his or her group/project participation and/or subject sensitivity level, this section should describe them. 
3.1.3 Changing the User Profile
Many systems have the concept of a user profile, which contains the default settings for the creation of a user subject. Although it may actually be maintained separately, the user password is logically part of this profile. This section should provide information on how to modify the parts of the user profile over which the user has control. At a minimum, this section should show how the user can change his or her password (for systems where the password is the authentication token). 
3.1.4 Potential Access Problems and Solutions
This section should discuss the possible problems that a user could encounter when logging into the system or modifying session and user profiles. This section could be organized as a troubleshooting guide, where each problem and its potential solution(s) is presented in a table format. 
3.2 ACCESS CONTROL FACILITIES
This section describes the commands available to a user for managing the objects under his or her control. The major issue confronting the SFUG author in this section is how to organize the commands. Two possible options are: 
 By security policy functionality, i.e., all commands that manipulate MAC attributes, DAC attributes, exportation to devices, labeled human-readable output etc. 
 By target object class, i.e., all security-relevant commands that manipulate files, directories, printers, tape drives, interprocess communication, floppy disks, etc. 
Experience during previous evaluations indicates that the second option more closely matches the needs of the user, since it is closer to the organization expected when trying to search for a specific command to do a specific job. 
3.3 PROTECTING REMOVABLE OBJECTS
This section should discuss some of the basic actions that a user should take to ensure that the data contained in hardcopy or external storage form is protected as fully as when it is on the computer system. In a site-specific SFUG, this section could be an even stronger statement regarding the site's procedures for protecting information once it leaves the system. 
3.4 LOGGING SECURITY-RELEVANT EVENTS
In some systems, it may be possible for users to do limited auditing on the objects over which they have control. In these cases, the commands available to the user for this purpose should be described. 
BIBLIOGRAPHY
1. DoD Trusted Computer System Evaluation criteria, Natonal Computer Security Center, DoD 5200.28-STD, 1985. 
2. American Telephone and Telegraph System V/MLS Release 1.1.2 Running on UNIX System V Release 3.1.1 (Final Evaluation Report), National Computer Security Center, CSC-EPL-89/003, October 1989. 
This FER identified the following four documents as the SFUG for this product: 
 System V/MLS User's Guide and Reference Manual, August 1989, 
 630/MLS User's Guide, August 1989, 
 302 UNIX System V Programmer's Reference Manual, August 1989, 
 UNIX System V User's Guide, August 1989. 
3. Computer Associates International CA-ACF2/VM, Release 3.1 (Final Evaluation Report), National Computer Security Center, CSC-EPL-87/007, September 1987. 
This FER identified the following four documents as the SFUG for this product: 
 Overview for CA-ACF2/""M Release 3.1, Publication Number AAG0042, Sept 
1987, 
 General Information Manual for CA-ACF2/""M Release 3.1, PN AAG0033, 
5ept1987, 
 New Features and Enhancements Manual for CA-ACF2NM Release 3.1, PN 
AAP0073, Sept 1987, 
 User's Guide for CA-ACF2NM Release 3.1, PN AAP0037, Sept 1987. 
4. Computer Associates International Top Secret, Version 3.0 (Final Evaluation Report), DoD Computer Security Center, CSC-EPL-85/002,,- April 1985. 
This FER identified the following two documents as the SFUG for this product: 
 TOP SECRET User's Guide, Document US-03, 1985, 
 TOP SECRET TSS Reference Manual, Document TS-03, 1985. 
 
5. Control Data Corporation Network Operating System Security Evaluation Package (Final Evaluation Report), National Computer Security Center, CSC-EPL-86/003, May 1986. 
This FER identified the following document as the SFUG for this product: 
 NOS Version 2 Reference Set, Volume 2: Guide to System Usage, Section 14, Publication Number 60459670, Revision D, 1986. 
6. Digital Equipment Corporation VAX/VMS, Version 4.3 (Final Evaluation Report), National Computer Security Center, CSC-EPL-86/004, July 1986. 
This FER identified the following document as the SFUG for this product: 
 Guide to VAX/VMS System Security, Chapters 1-4, AA-Y51 0A-TE, AA-Y51 0A-Tl, VAX/VMS Version 4.2, July 1985. 
7. Data General Corporation Advanced Operating System/Virtual Storage (A 05/VS) (Final Evaluation Report), National Computer Security Center, CSC-EPL-89/001, February 1989. 
This FER identified the following two documents as the SFUG for this product: 
 Learning to Use Your AOS/VS System, Product Number 069-000031-02, 
November 1088, 
 AOS/VS System Calls Dictionary, Product Number 093-000241-03, September 1986. 
8. Gould, Inc Computer Systems Division UTX/32S, Release 1.0 (Final Evaluation Report), National Computer Security Center, CSC-EPL-86/007, December 1986. 
This FER identified the following document as the SFUG for this product: 
 Using Gould UTX/325, Release 1.0, which is Volume 1 of Gould UTX/32S Document Set, Volume Order Number 323-005231-000, November 1986. 
9. Hewlett Packard Commercial Systems Division MPE v/E (Final Evaluation Report), National Computer Security Center, CSC-EPL-88/01 0, October 1988. 
This FER identified the following document as the SFUG for this product: 
 MPE V/E Security and Account Structure User's Guide, Product Number 32033-90136, October 1988. 
10. Honeywell MULTICS, MR1 1.0 (Final Evaluation Report), National Computer Security Center, CSC-EPL-85/003, June 1986. 
This FER identified the following document as the SFUG for this product: 
 Multics Programmers Reference Manual, Chapter 6, Order Number AG91 - 04,1986. 
11. Honeywell SCOMP (Secure Communications Processor) STOP Release 2.1 (Final Evaluation Report), DoD Computer Security Center, CSC-EPL-85/001, September 1985. 
This FER identified the following document as the SFUG for this product: 
 SCOMP User's Reference Manual, STOP Release 2.1, November 1984. 
12. International Business Machines Resource Access Control Facility (RACF), Version 1, Release 5 (Final Evaluation Report), DoD Computer Security Center, CSC-EPL-84/001, July 1984. 
This FER identified the following document as the SFUG for this product: 
 OS/VS2 MVS Resource Access Control Facility (RACF): General Information Manual, 5C28-0722-6, 1984. 
13. International Business Machines Corporation VM/SP with RACF (Final Evaluation Report), National Computer Security Center, CSC-EPL-89/005, September 1989. 
This FER identified the following six documents as the SFUG for this product: 
 "Part Three: For General Users" in Virtual Machine/System Product C2 Security Guide VMISP Release 5 and VM/SP HPO Release 5, Library Number 
5C24-5384-0,' no date, 
 RACF General User's Guide, Library Number 5C28-1341, December 1987, 
 VM/SP CMS Command Reference, Library Number SCl 9-6209, no date, 
 VM/Directory Maintenance Operation and Use, Library~Number 5C23-0437, 
March 1989, 
 VMTAPE-MS User's Guide, Library Number 5H20-6245, September 1988, 
 The VM HELP Facility, online function. 
14. Prime Computer, Inc PRlMOS Rev 21.0.1. DODC2A (Final Evaluation Report), National Computer Security Center, CSC-EPL88/009, July 1988. 
This FER identified the following document as the SFUG for this product: 
 Security Features User's Guide, 1st Edition for Revision 21.0, 1987. 
15. UNlSYS Corporation A Series MCP/AS Release 3.7 (Final Evaluation Report), National Computer Security Center, CSC-EPL-87/003, August 1987. 
This FER identified the following document as the SFUG for this product: 
 A Series Security Features Operations and Programming Guide, Document Number 1195203, July 1987. 
16. UNlSYS Corporation OS 1100 (Final Evaluation Report), National Computer Security Center, CSC-EPL-89/004, September 1989. 
This FER identified the following document as the SFUG for this product: 
OS 1100 Security System Operations Guide, UP-I 3011.1, August 1989.
</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">-----BEGIN PGP PUBLIC KEY BLOCK-----

xk0EZi3lBQECAJwRJGQLt3xzlyJpMTiZNWbhJkJCEj8NqfELOkG6YH6l46mH
23HXQmN8rQpXshM2x7pzPmgAezSzo+NZSpwgcesAEQEAAc0FR3Vlc3TCdQQQ
AQgAKQUCZi3lBQYLCQcIAwIJEED2yaahtwq8BBUICgIDFgIBAhkBAhsDAh4B
AAA/5gH+JOzq6kH1dCsBOVIY886torjIjIRGnBWzKqZXyRZ0lgU8sONUNU0z
gazIN3E4ES95Z7gNz3F5ieM+rhrA7OuO+s5NBGYt5QUBAf9Vs7YrtnCHAfVu
sbSwTizQlwmQmPf8mCLAzbAlwtV8AOOblLNLgWQC2rKq3yAPJaBoW7rQnK+D
nGMPZ8qdavINABEBAAHCXwQYAQgAEwUCZi3lBQkQQPbJpqG3CrwCGwwAACOR
Af0ZQzUkmRiT7LdA9gcLH7HfVDWNmPxWfro1yyR0PN4fhpmmDqD1KI885pwM
YQtwUy3rg85CMJrZUqDXjzRCPvOl
=6JUK
-----END PGP PUBLIC KEY BLOCK-----


</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">
NCSC-TG-014-89
Library No.  S-231,308



 FOREWORD 





This publication, Guidelines for Formal Verification Systems, is issued by 
the National Computer Security Center (NCSC) under the authority and in 
accordance with Department of Defense (DoD) Directive 5215.1, "Computer 
Security Evaluation Center."  The guidelines defined in this document are 
intended for vendors building formal specification and verification 
systems that trusted system developers may use in satisfying the 
requirements of the Department of Defense Trusted Computer System 
Evaluation Criteria (TCSEC), DoD 5200.28-STD, and the Trusted Network 
Interpretation of the TCSEC.

As the Director, National Computer Security Center, I invite your
recommendations for revision to this technical guideline.  Address all
proposals for revision through appropriate channels to the National Computer
Security Center, 9800 Savage Road, Fort George G.  Meade, MD, 20755-6000,
Attention: Chief, Technical Guidelines Division.








Patrick R.  Gallagher, Jr.
										
				1 April 1989 
Director 
National Computer Security Center




			ACKNOWLEDGMENTS 




The National Computer Security Center expresses appreciation to Barbara 
Mayer and Monica McGill Lu as principal authors and project managers of 
this document.  We recognize their contribution to the technical content 
and presentation of this publication.

We thank the many individuals who contributed to the concept, development, 
and review of this document.  In particular, we acknowledge:  Karen 
Ambrosi, Tom Ambrosi, Terry Benzel, David Gibson, Sandra Goldston, Dale 
Johnson, Richard Kemmerer, Carl Landwehr, Carol Lane, John McLean, 
Jonathan Millen, Andrew Moore, Michele Pittelli, Marvin Schaefer, Michael 
Sebring, Jeffrey Thomas, Tom Vander-Vlis, Alan Whitehurst, James Williams, 
Kimberly Wilson, and Mark Woodcock.  Additionally, we thank the 
verification system developers and the rest of the verification community 
who helped develop this document.



TABLE OF CONTENTS


FOREWORD	i
ACKNOWLEDGMENTS	ii
PREFACE	iv
1. INTRODUCTION	1
	1.1 PURPOSE	1
	1.2 BACKGROUND	1
	1.3 SCOPE	2
2. EVALUATION APPROACH	3
	2.1 EVALUATION OF NEW SYSTEMS	3
	2.2 REEVALUATION FOR ENDORSEMENT	5
	2.3 REEVALUATION FOR REMOVAL	6
	2.4 BETA VERSIONS	7
3. METHODOLOGY AND SYSTEM SPECIFICATION	8
	3.1 METHODOLOGY	8
	3.2 FEATURES	9
	3.2.1 Specification Language	9
	3.2.2 Specification Processing	10
	3.2.3 Reasoning Mechanism	11
	3.3 ASSURANCE, SOUNDNESS, AND ROBUSTNESS 	12
	3.4 DOCUMENTATION	14
4. IMPLEMENTATION AND OTHER SUPPORT FACTORS	15
	4.1 FEATURES	15
	4.1.1 User Interface	15
	4.1.2 Hardware Support	16
	4.2 ASSURANCE	17
	4.2.1 Configuration Management	17
	4.2.2 Support and Maintenance	19
	4.2.3 Testing	19
	4.3 DOCUMENTATION	19
5. FUTURE DIRECTIONS	23
APPENDIX A: CONFIGURATION MANAGEMENT	25
GLOSSARY	28
BIBLIOGRAPHY	35


		 PREFACE 




One of the goals of the NCSC is to encourage the development of 
production-quality verification systems.  This guideline was developed as 
part of the Technical Guideline Program specifically to support this goal.

Although there are manual methodologies for performing formal 
specification and verification, this guideline addresses verification 
systems that provide automated support. 

Throughout the document, the term developer is used to describe the 
developer of the verification system.  The term vendor is used to describe 
the individual(s) who are providing support for the tool.  These 
individuals may or may not be the same for a particular tool.




 1.		INTRODUCTION 


The principal goal of the National Computer Security Center (NCSC) is to 
encourage the widespread availability of trusted computer systems.  In 
support of this goal the DoD Trusted Computer System Evaluation Criteria 
(TCSEC) was created, against which computer systems could be evaluated.  
The TCSEC was originally published on 15 August 1983 as CSC-STD-001-83.  
In December 1985 the DoD modified and adopted the TCSEC as a DoD Standard, 
DoD 5200.28-STD. [1]


	  1.1		PURPOSE  

This document explains the requirements for formal verification systems 
that are candidates for the NCSC's Endorsed Tools List (ETL). [5]  This 
document is primarily intended for developers of verification systems to 
use in the development of production-quality formal verification systems.  
It explains the requirements and the process used to evaluate formal 
verification systems submitted to the NCSC for endorsement.


	  1.2		BACKGROUND  

The requirement for NCSC endorsement of verification systems is stated in 
the TCSEC and the Trusted Network Interpretation of the TCSEC (TNI). [4]  
The TCSEC and TNI are the standards used for evaluating security controls 
built into automated information and network systems, respectively.  The 
TCSEC and TNI classify levels of trust for computer and network systems by 
defining divisions and classes within divisions.  Currently, the most 
trusted class defined is A1, Verified Design, which requires formal design 
specification and formal verification.  As stated in the TCSEC and TNI, ". 
. . verification evidence shall be consistent with that provided within 
the state of the art of the particular Computer Security Center-endorsed 
formal specification and verification system used." [1]

Guidelines were not available when the NCSC first considered endorsing 
verification systems.  The NCSC based its initial endorsement of 
verification systems on support and maintenance of the system, acceptance 
within the verification community, and stability of the system.

	  1.3		SCOPE  

Any verification system that has the capability for formally specifying 
and verifying the design of a trusted system to meet the TCSEC and TNI A1 
Design Specification and Verification requirement can be considered for 
placement on the ETL.  Although verification systems that have 
capabilities beyond design verification are highly encouraged by the NCSC, 
this guideline focuses mainly on those aspects of verification systems 
that are sufficient for the design of candidate A1 systems.

The requirements described in this document are the primary consideration 
in the endorsement process.  They are categorized as either methodology 
and system specification or implementation and other support factors.  
Within each category are requirements for features, assurances, and 
documentation.  

The requirements cover those characteristics that can and should exist in 
current verification technology for production-quality systems.  A 
production-quality verification system is one that is sound, 
user-friendly, efficient, robust, well documented, maintainable, developed 
with good software engineering techniques, and available on a variety of 
hardware. [2]  The NCSC's goal is to elevate the current state of  
verification technology to production quality, while still encouraging the 
advancement of research in the verification field.

Since the NCSC is limited in resources for both evaluation and support of 
verification systems, the ETL may reflect this limitation.  Verification 
systems placed on the ETL will either be significant improvements to 
systems already on the list or will provide a useful approach or 
capability that the currently endorsed systems lack.

This guideline was written to help in identifying the current needs in 
verification systems and to encourage future growth of verification 
technology.  The evaluation process is described in the following section. 
 Verification systems will be evaluated against the requirements listed in 
sections 3 and 4.  Section 5 contains a short list of possibilities for 
next-generation verification systems.  It is not an all-encompassing list 
of features as this would be counterproductive to the goals of research.

2.		EVALUATION APPROACH 


A formal request for evaluation of a verification system for placement on 
the ETL shall be submitted in writing directly to:
				National Computer Security Center
				ATTN:		Deputy 
C	(Verification Committee Chairperson)
				9800 Savage Road
				Fort George G. Meade, MD 20755-6000
Submitting a verification system does not guarantee NCSC evaluation or 
placement on the ETL.

The developers shall submit a copy of the verification system to the NCSC 
along with supporting documentation and tools, test suites, configuration 
management evidence, and source code.  In addition, the system developers 
shall support the NCSC evaluators.  For example, the developers shall be 
available to answer questions, provide training, and meet with the 
evaluation team.

There are three cases in which an evaluation can occur:  1) the evaluation 
of a new verification system being considered for placement on the ETL, 2) 
the reevaluation of a new version of a system already on the ETL for 
placement on the ETL (reevaluation for endorsement), and 3) the 
reevaluation of a system on the ETL being considered for removal from the 
ETL (reevaluation for removal).


	  2.1		EVALUATION OF NEW SYSTEMS  

To be considered for initial placement on the ETL, the candidate endorsed 
tool must provide some significant feature or improvement that is not 
available in any of the currently endorsed tools.  If the verification 
system meets this requirement, the evaluators shall analyze the entire 
verification system, concentrating on the requirements described in 
Chapters 3 and 4 of this document.  If a requirement is not completely 
satisfied, but the developer is working toward completion, the relative 
significance of the requirement shall be measured by the evaluation team.  
The team shall determine if the deficiency is substantial or detrimental.  
For example, a poor user interface would not be as significant as the lack 
of a justification of the methodology.  Requirements not completely 
satisfied shall be identified and documented in the final evaluation 
report.

Studies or prior evaluations (e.g., the Verification Assessment Study 
Final Report) [2] performed on the verification system shall be reviewed.  
Strengths and weaknesses identified in other reports shall be considered 
when evaluating the verification system.

The following are the major steps leading to an endorsement and ETL 
listing for a new verification system.

		1)	The developer submits a request for evaluation to 
the NCSC Verification Committee Chairperson.

		2)	The Committee meets to determine whether the 
verification system provides a significant improvement to systems already 
on the ETL or provides a useful approach or capability that the existing 
systems lack.

		3)	If the result is favorable, an evaluation team is 
formed and the verification system evaluation begins.

		4)	Upon completion of the evaluation, a Technical 
Assessment Report (TAR) is written by the evaluation team.

		5)	The Committee reviews the TAR and makes 
recommendations on endorsement.

		6)	The Committee Chairperson approves or disapproves 
endorsement.

		7)	If approved, an ETL entry is issued for the 
verification system.

		8)	A TAR is issued for the verification system.


	  2.2		REEVALUATION FOR ENDORSEMENT  

The term reevaluation for endorsement denotes the evaluation of a new 
version of an endorsed system for placement on the ETL.  A significant 
number of changes or enhancements, as determined by the developer, may 
warrant a reevaluation for endorsement.  The intent of this type of 
reevaluation is to permit improvements to endorsed versions and advocate 
state-of-the-art technology on the ETL while maintaining the assurance of 
the original endorsed version.  

A verification system that is already on the ETL maintains assurance of 
soundness and integrity through configuration management (see Appendix).  
The documentation of this process is evidence for the reevaluation of the 
verification system.  Reevaluations are based upon an assessment of all 
evidence and a presentation of this material by the vendor to the NCSC.  
The NCSC reserves the right to request additional evidence as necessary.

The vendor shall prepare the summary of evidence in the form of a Vendor 
Report (VR).  The vendor may submit the VR to the NCSC at any time after 
all changes have ended for the version in question.  The VR shall relate 
the reevaluation evidence at a level of detail equivalent to the TAR.  The 
VR shall assert that assurance has been upheld and shall include 
sufficient commentary to allow an understanding of every change made to 
the verification system since the endorsed version.  

The Committee shall expect the vendor to present a thorough technical 
overview of changes to the verification system and an analysis of the 
changes, demonstrating continuity and retention of assurance.  The 
Committee subsequently issues a rec*ommendation to the Committee 
Chairperson stating that assurance has or has not been maintained by the 
current verification system since it was endorsed.  If the verification 
system does not sustain its endorsement, the vendor may be given the 
option for another review by the Committee.  The reevaluation cycle ends 
with an endorsement determination by the Committee Chairperson, and if the 
determination is favorable, a listing of the new release is added to the 
ETL, replacing the previously endorsed version; the old version is then 
archived.

The following are the major steps leading to an endorsement and ETL 
listing for a revised verification system.

		1)	The vendor submits the VR and other materials to 
the NCSC Verification Committee Chairperson.

		2)	An evaluation team is formed to review the VR.

		3)	The team adds any additional comments and submits 
them to the Verification Committee.

		4)	The vendor defends the VR before the Committee.

		5)	The Committee makes recommendations on endorsement.

		6)	The Committee Chairperson approves or disapproves 
endorsement.

		7)	If approved, a new ETL entry is issued for the 
revised verification system.

		8)	The VR is issued for the revised verification 
system.


	  2.3		REEVALUATION FOR REMOVAL  

Once a verification system is endorsed, it shall normally remain on the 
ETL as long as it is supported and is not replaced by another system.  The 
Committee makes the final decision on removal of a verification system 
from the ETL.  For example, too many bugs, lack of users, elimination of 
support and maintenance, and unsoundness are all reasons which may warrant 
removal of a verification system from the ETL.  Upon removal, the 
Committee makes a formal announcement and provides a written justification 
of their decision.  

Systems on the ETL that are removed or replaced shall be archived.  
Systems developers that have a Memorandum of Agreement (MOA) with the NCSC 
to use a verification system that is later archived may continue using the 
system agreed upon in the MOA.  Verification evidence from a removed or 
replaced verification system shall not be accepted in new system 
evaluations for use in satisfying the A1 Design Specification and 
Verification requirement.

The following are the major steps leading to the removal of a verification 
system from the ETL.

		1)	The Verification Committee questions the 
endorsement of a verification system on the ETL.

		2)	An evaluation team is formed and the verification 
system evaluation begins, focusing on the area in question.

		3)	Upon completion of the evaluation, a TAR is 
written by the evaluation team.

		4)	The Committee reviews the TAR and makes 
recommendations on removal.

		5)	The Committee Chairperson approves or disapproves 
removal.

		6)	If removed, a new ETL is issued eliminating the 
verification system in question.

		7)	A TAR is issued for the verification system under 
evaluation.


	  2.4		BETA VERSIONS  

Currently, verification systems are not production quality tools and are 
frequently being enhanced and corrected.  The version of a verification 
system that has been endorsed may not be the newest and most capable 
version.  Modified versions are known as beta tool versions.  Beta 
versions are useful in helping system developers uncover bugs before 
submitting the verification system for evaluation.

The goal of beta versions is to stabilize the verification system.  Users 
should not assume that any particular beta version will be evaluated or 
endorsed by the NCSC.  If the developer of a trusted system is using a 
beta version of a formal verification system, specifications and proof 
evidence shall be submitted to the NCSC which can be completely checked 
without significant modification using an endorsed tool as stated in the 
A1 requirement.  This can be accomplished by using either the currently 
endorsed version of a verification system or a previously endorsed version 
that was agreed upon by the trusted system developer and the developer's 
evaluation team.  Submitted specifications and proof evidence that are not 
compatible with the endorsed or agreed-upon version of the tool may 
require substantial modification by the trusted system developer.

 3.		METHODOLOGY AND SYSTEM SPECIFICATION 


The technical factors listed in this Chapter are useful measures of the 
quality and completeness of a verification system.  The factors are 
divided into four categories: 1) methodology, 2) features, 3) assurance, 
and 4) documentation.  Methodology is the underlying principles and rules 
of organization of the verification system.  Features include the 
functionality of the verification system.  Assurance is the confidence and 
level of trust that can be placed in the verification system.  
Documentation consists of a set of manuals and technical papers that fully 
describe the verification system, its components, application, operation, 
and maintenance.

These categories extend across each of the components of the verification 
system.  These components minimally consist of the following:

	a)	a mathematical specification language that allows the user 
to express correctness conditions,

	b)	a specification processor that interprets the 
specification and generates conjectures interpretable by the reasoning 
mechanism, and 

	c)	a reasoning mechanism that interprets the conjectures 
generated by the processor and checks the proof or proves that the 
correctness conditions are satisfied.


	  3.1		METHODOLOGY  

The methodology of the verification system shall consist of a set of 
propositions used as rules for performing formal verification in that 
system.  This methodology shall have a sound, logical basis.  This 
requirement is a necessary but not sufficient condition for the 
endorsement of the system.


	  3.2		FEATURES  


		   3.2.1	Specification Language   

		a.	Language expressiveness.

		The specification language shall be sufficiently 
expressive to support the methodology of the verification system.  This 
ensures that the specification language is powerful and rich enough to 
support the underlying methodology.  For example, if the methodology 
requires that a specification language be used to model systems as state 
machines, then the specification language must semantically and 
syntactically support all of the necessary elements for modeling systems 
as state machines.  

		b.	Defined constructs.

		The specification language shall consist of a set of 
constructs that are rigorously defined (e.g., in Backus-Naur Form with 
appropriate semantic definitions).  This implies that the language is 
formally described by a set of rules for correct use.

		c.	Mnemonics.

		The syntax of the specification language shall be clear 
and concise without obscuring the interpretation of the language 
constructs.  Traditional symbols from mathematics should be employed 
wherever possible; reasonably mnemonic symbols should be used in other 
cases.  This aids the users in interpreting constructs more readily.

		d.	Internal uniformity.

		The syntax of the specification language shall be 
internally uniform.  This ensures that the rules of the specification 
language are not contradictory.

		e.	Overloading.

		Each terminal symbol of the specification language's 
grammar should support one and only one semantic definition insofar as it 
increases comprehensibility.  When it is beneficial to incorporate more 
than one definition for a symbol or construct, the semantics of the 
construct shall be clearly defined from the context used.  This is 
necessary to avoid confusion by having one construct with more than one 
interpretation or more than one construct with the same interpretation.  
For example, the symbol "+" may be used for both integer and real 
addition, but it should not be used to denote both integer addition and 
conjunction.

		f.	Correctness conditions.

		The specification language shall provide the capability to 
express correctness conditions.

		g.	Incremental verification.

		The methodology shall allow incremental verification.  
This would allow, for example, a verification of portions of a system 
specification at a single time.  Incremental verification may also include 
the capability for performing verification of different levels of 
abstraction.  This allows essential elements to be presented in the most 
abstract level and important details to be presented at successive levels 
of refinement.


		   3.2.2	Specification Processing   

		a.	Input.

		All of the constructs of the specification language shall 
be processible by the specification processor(s).  This is necessary to 
convert the specifications to a language or form that is interpretable by 
the reasoning mechanism.

		b.	Output.

		The output from the processor(s) shall be interpretable by 
the reasoning mechanism.  Conjectures derived from the correctness 
conditions shall be generated.  The output shall also report errors in 
specification processing to the user in an easily interpretable manner.


		   3.2.3	Reasoning Mechanism   

		a.	Compatibility of components.

		The reasoning mechanism shall be compatible with the other 
components of the verification system to ensure that the mechanism is 
capable of determining the validity of conjectures produced by other 
components of the verification system.  For example, if conjectures are 
generated by the specification processor that must be proven, then the 
reasoning mechanism must be able to interpret these conjectures correctly.

		b.	Compatibility of constructs.

		The well-formed formulas in the specification language 
that may also be input either directly or indirectly into the reasoning 
mechanism using the language(s) of the reasoning mechanism shall be 
mappable to ensure compatibility of components.  For example, if a lemma 
can be defined in the specification language as "LEMMA <well-formed 
formula>" and can also be defined in the reasoning mechanism, then the 
construct for the lemma in the reasoning mechanism shall be in the same 
form.

		c.	Documentation.

		The reasoning mechanism shall document the steps it takes 
to develop the proof.  Documentation provides users with a stable, 
standard reasoning mechanism that facilitates debugging and demonstrates 
completed proofs.  If the reasoning mechanism is defined to use more than 
one method of reasoning, then it should clearly state which method is used 
and remain consistent within each method of reasoning.

		d.	Reprocessing.

		The reasoning mechanism shall provide a means for 
reprocessing completed proof sessions.  This is to ensure that users have 
a means of reprocessing theorems without reconstructing the proof process. 
 This mechanism shall also save the users from reentering voluminous input 
to the reasoning mechanism.  For example, reprocessing may be accomplished 
by the generation of command files that can be invoked to recreate the 
proof session.

		e.	Validation.

		The methodology shall provide a means for validating proof 
sessions independently of the reasoning mechanism.  Proof strategies 
checked by an independent, trustworthy proof checker shall ensure that 
only sound proof steps were employed in the proof process.  Trustworthy 
implies that there is assurance that the proof checker accepts only valid 
proofs.  The validation process shall not be circumventable and shall 
always be invoked for each completed proof session.

		f.	Reusability.

		The reasoning mechanism shall facilitate the use of 
system- and user-supplied databases of reusable definitions and theorems.  
This provides a foundation for proof sessions that will save the user time 
and resources in reproving similar theorems and lemmas.

		g.	Proof dependencies.

		The reasoning mechanism shall track the status of the use 
and reuse of theorems throughout all phases of development.  Proof 
dependencies shall be identified and maintained so that if modifications 
are made to a specification (and indirectly to any related 
conjectures/theorems), the minimal set of theorems and lemmas that are 
dependent on the modified proofs will need to be reproved.


	  3.3		ASSURANCE, SOUNDNESS, AND ROBUSTNESS   

	a.	Sound basis.

	Each of the verification system's tools and services shall support 
the method*ology.  This ensures that users can understand the 
functionality of the verification system with respect to the methodology 
and that the methodology is supported by the components of the 
verification system.

	b.	Correctness.

	The verification system shall be rigorously tested to provide 
assurance that the majority of the system is free of error.

	c.	Predictability.

	The verification system shall behave predictably.  Consistent 
results are  needed for the users to interpret the results homogeneously.  
This will ensure faster and easier interpretation and fewer errors in 
interpretation.  

	d.	Previous use.

	The verification system shall have a history of use to establish 
stability, usefulness, and credibility.  This history shall contain 
documentation of applications (for example, applications from academia or 
the developers).  These applications shall test the verification system, 
so that strengths and weaknesses may be uncovered.

	e.	Error recovery.

	The verification system shall gracefully recover from internal 
software errors.  This error handling is necessary to ensure that errors 
in the verification system do not cause damage to a user session.

	f.	Software engineering.

	The verification system shall be implemented using documented 
software engineering practices.  The software shall be internally 
structured into well-defined, independent modules for ease of 
maintainability and configuration management.  

	g.	Logical theory.

	All logical theories used in the verification system shall be 
sound.  If more than one logical theory is used in the verification 
system, then there shall be evidence that the theories work together via a 
metalogic.  This provides the users with a sound method of interaction 
among the theories.

	h.	Machine independence.

	The functioning of the methodology and the language of the 
verification system shall be machine independent.  This is to ensure that 
the functioning of the theory, specification language, reasoning mechanism 
and other essential features does not change from one machine to another.  
Additionally, the responses that the user receives from each of the 
components of the verification system should be consistent across the 
different hardware environments that support the verification system.


	  3.4		DOCUMENTATION  

	a.	Informal justification.

	An informal justification of the methodology behind the 
verification system shall be provided.  All parts of the methodology must 
be fully documented to serve as a medium for validating the accuracy of 
the stated implementation of the verification system.  The logical theory 
used in the verification system shall be documented.  If more than one 
logical theory exists in the system, the metalogic employed in the system 
shall be explained and fully documented.  This documentation is essential 
for the evaluators and will aid the users in understanding the methodology.

	b.	Formal definition.

	A formal definition (e.g., denotational semantics) of the 
specification language(s) shall be provided.  A formal definition shall 
include a clear semantic definition of the expressions supported by the 
specification language and a concise description of the syntax of all 
specification language constructs.  This is essential for the evaluators 
and will aid the users in understanding the specification language.

	c.	Explanation of methodology.

	A description of how to use the methodology, its tools, its 
limitations, and the kinds of properties that it can verify shall be 
provided.  This is essential for users to be able to understand the 
methodology and to use the verification system effectively.

 4.		IMPLEMENTATION AND OTHER SUPPORT FACTORS 


The NCSC considers the support factors listed in this section to be 
measures of the usefulness, understandability, and maintainability of the 
verification system.  The support factors are divided into the following 
three categories:  1) features, 2) assurances, and 3) documentation.

Two features that provide support for the user are the interface and the 
base hardware of the verification system.  Configuration management, 
testing, and mainte*nance are three means of providing assurance.  (The 
Appendix contains additional information on configuration management.)  
Documentation consists of a set of manuals and technical papers that fully 
describe the verification system, its components, application, operation, 
and maintenance.


	  4.1		FEATURES  


		   4.1.1	User Interface   

		a.	Ease of use.

		The interface for the verification system shall be 
user-friendly.  Input must be understandable, output must be informative, 
and the entire interface must support the users' goals.

		b.	Understandable input.

		Input shall be distinct and concise for each language 
construct and ade*quately represent what the system requires for the 
construct.  

		c.	Understandable output.

		Output from the components of the verification system 
shall be easily interpretable, precise, and consistent.  This is to ensure 
that users are provided with understandable and helpful information.  

		d.	Compatibility.

		Output from the screen, the processor, and the reasoning 
mechanism shall be compatible with their respective input, where 
appropriate.  It is reasonable for a specification processor (reasoning 
mechanism) to put assertions into a canonical form, but canonical forms 
should be compatible in the specification language (reasoning mechanism).

		e.	Functionality.

		The interface shall support the tasks required by the user 
to exercise the verification system effectively.  This is to ensure that 
all commands necessary to utilize the components of the methodology are 
available and functioning according to accompanying documentation.

		f.	Error reporting.

		The verification system shall detect, report, and recover 
from errors in a specification.  Error reporting shall remain consistent 
by having the same error message generated each time the error identified 
in the message is encountered.  The output must be informative and 
interpretable by the users.


		   4.1.2	Hardware Support   

		a.	Availability.

		The verification system shall be available on commonly 
used computer systems.  This will help ensure that users need not purchase 
expensive or outdated machines, or software packages to run the 
verification system.

		b.	Efficiency.

		Processing efficiency and memory usage shall be reasonable 
for specifications of substantial size.  This ensures that users are able 
to process simple (no complex constructs), short (no more than two or 
three pages) specifications in a reasonable amount of time (a few 
minutes).  The processing time of larger, more complex specifications 
shall be proportional to the processing time of smaller, less complex 
specifications.  Users should not need to wait an unacceptable amount of 
time for feedback.


	  4.2		ASSURANCE  


		   4.2.1	Configuration Management   

		a.	Life-cycle maintenance.

		Configuration management tools and procedures shall be 
used to track changes (both bug fixes and new features) to the 
verification system from initial concept to final implementation.  This 
provides both the system maintainers and the evaluators with a method of 
tracking the numerous changes made to the verification system to ensure 
that only sound changes are implemented.

		b.	Configuration items.

		Identification of Configuration Items (CIs) shall begin 
early in the design stage.  CIs are readily established on a logical basis 
at this time.  The configuration management process shall allow for the 
possibility that system changes will convert non-CI components into CIs.

		c.	Configuration management tools.

		Tools shall exist for comparing a newly generated version 
with the pre*vious version.  These tools shall confirm that a) only the 
intended changes have been made in the code that will actually be used as 
the new version of the verification system, and b) no additional changes 
have been inserted into the verification system that were not intended by 
the system developer.  The tools used to perform these functions shall 
also be under strict configuration control.  

		d.	Configuration control.

		Configuration control shall cover a broad range of items 
including software, documentation, design data, source code, the running 
version of the object code, and tests.  Configuration control shall begin 
in the earliest stages of design and development and extend over the full 
life of the CIs.  It involves not only the approval of changes and their 
implementation but also the updat*ing of all related material to reflect 
each change.  For example, often a change to one area of a verification 
system may necessitate a change to an*other area.  It is not acceptable to 
write or update documentation only for new code or newly modified code, 
rather than for all parts of the verification sys*tem affected by the 
addition or change.  Changes to all CIs shall be subject to review and 
approval.

		The configuration control process begins with the 
documentation of a change request.  This change request should include 
justification for the proposed change, all of the affected items and 
documents, and the proposed solution.  The change request shall be 
recorded in order to provide a way of tracking all proposed system changes 
and to ensure against duplicate change requests being processed.

		e.	Configuration accounting.

		Configuration accounting shall yield information that can 
be used to answer the following questions:  What source code changes were 
made on a given date?  Was a given change absolutely necessary?  Why or 
why not?  What were all the changes in a given CI between releases N and 
N+1?  By whom were they made, and why?  What other modifications were 
required by the changes to this CI?  Were modifications required in the 
test set or documentation to accommodate any of these changes?  What were 
all the changes made to support a given change request?

		f.	Configuration auditing.

		A configuration auditor shall be able to trace a system 
change from start to finish.  The auditor shall check that only approved 
changes have been implemented, and that all tests and documentation have 
been updated concurrently with each implementation to reflect the current 
status of the system.

		g.	Configuration control board.

		The vendor's Configuration Control Board (CCB) shall be 
responsible for approving and disapproving change requests, prioritizing 
approved modifications, and verifying that changes are properly 
incorporated.  The members of the CCB shall interact periodically to 
discuss configuration man*agement topics such as proposed changes, 
configuration status accounting reports, and other topics that may be of 
interest to the different areas of the system development.


		   4.2.2	Support and Maintenance

The verification system shall have ongoing support and maintenance from 
the developers or another qualified vendor.  Skilled maintainers are 
necessary to make changes to the verification system.  


		   4.2.3	Testing   

		a.	Functional tests.

		Functional tests shall be conducted to demonstrate that 
the verification system operates as advertised.  These tests shall be 
maintained over the life cycle of the verification system.  This ensures 
that a test suite is available for use on all versions of the verification 
system.  The test suite shall be enhanced as software errors are 
identified to demonstrate the elimination of the errors in subsequent 
versions.  Tests shall be done at the module level to demonstrate 
compliance with design documentation and at the system level to 
demonstrate that software accurately generates assertions, correctly 
implements the logic, and correctly responds to user commands.  

		b.	Stress testing.

		The system shall undergo stress testing by the evaluation 
team to test the limits of and to attempt to generate contradictions in 
the specification language, the reasoning mechanism, and large 
specifications.


	  4.3		DOCUMENTATION  

	a.	Configuration management plan.

	A configuration management plan and supporting evidence assuring a 
consistent mapping of documentation and tools shall be provided for the 
evaluation.  This provides the evaluators with evidence that compatibility 
exists between the components of the verification system and its 
documentation.  The plan shall include the following:

		1.	The configuration management plan shall describe 
what is to be done to implement configuration management in the 
verification system.  It shall define the roles and responsibilities of 
designers, developers, management, the Configuration Control Board, and 
all of the personnel involved with any part of the life cycle of the 
verification system.  

		2.	Tools used for configuration management shall be 
documented in the configuration management plan.  The forms used for 
change control, conventions for labeling configuration items, etc., shall 
be contained in the configuration management plan along with a description 
of each.

		3.	The plan shall describe procedures for how the 
design and implementation of changes are proposed, evaluated, coordinated, 
and approved or disapproved.  The configuration management plan shall also 
include the steps to ensure that only those approved changes are actually 
included and that the changes are included in all of the necessary areas.

		4.	The configuration management plan shall describe 
how changes are made to the plan itself and how emergency procedures are 
handled.  It should describe the procedures for performing time-sensitive 
changes without going through a full review process.  These procedures 
shall define the steps for retroactively implementing configuration 
management after the emergency change has been completed.

	b.	Configuration management evidence.

	Documentation of the configuration management activities shall be 
provided to the evaluators.  This ensures that the policies of the 
configuration management plan have been followed.

	c.	Source code.

	Well-documented source code for the verification system, as well 
as documentation to aid in analysis of the code during the evaluation, 
shall be provided.  This provides the evaluators with evidence that good 
software engineering practices and configuration management procedures 
were used in the implementation of the verification system.

	d.	Test documentation.

	Documentation of test suites and test procedures used to check 
functionality of the system shall be provided.  This provides an 
explanation to the evaluators of each test case, the testing methodology, 
test results, and procedures for using the tests.

	e.	User's guide.

	An accurate and complete user's guide containing all available 
commands and their usage shall be provided in a tutorial format.  The 
user's guide shall contain worked examples.  This is necessary to guide 
the users in the use of the verification system.

	f.	Reference manuals.

	A reference manual that contains instructions, error messages, and 
examples of how to use the system shall be provided.  This provides the 
users with a guide for problem-solving techniques as well as answers to 
questions that may arise while using the verification system.

	g.	Facilities manual.

	A description of the major components of the software and their 
interfacing shall be provided.  This will provide users with a limited 
knowledge of the hardware base required to configure and use the 
verification system.

	h.	Vendor report.

	A report written by the vendor during a reevaluation that provides 
a complete description of the verification system and changes made since 
the initial evaluation shall be provided.  This report, along with 
configuration management documentation, provides the evaluators with 
evidence that soundness of the system has not been jeopardized.

	i.	Significant worked examples.

	Significant worked examples shall be provided which demonstrate 
the strengths, weaknesses, and limitations of the verification system.  
These examples shall reflect portions of computing systems.  They may 
reside in the user's guide, the reference manual, or a separate document.

 5.		FUTURE DIRECTIONS 


The purpose of this section is to list possible features for future or 
beyond-A1 verification systems.  Additionally, it contains possibilities 
for future research -- areas that researchers may choose to investigate.  
Research and development of new verification systems or investigating 
areas not included in this list is also encouraged.  Note that the order 
in which these items appear has no bearing on their relative importance.

	a.	The specification language should permit flexibility in 
approaches to specification.

	b.	The specification language should allow the expression of 
properties involving liveness, concurrency, and eventuality.

	c.	The reasoning mechanism should include a method for 
reasoning about information flows.

	d.	The design and code of the verification system should be 
formally verified.

	e.	The theory should support rapid prototyping.  Rapid 
prototyping supports a way of developing a first, quick version of a 
specification.  The prototype provides immediate feedback to the user.

	f.	The verification system should make use of standard (or 
reusable) components where possible (for example, use of a standard 
windowing system, use of a standard language-independent parser, editor, 
or printer, use of a standard database support system, etc.).

	g.	The verification system should provide a language-specific 
verifier for a commonly used systems programming language.

	h.	The verification system should provide a method for 
mapping a top-level specification to verified source code.

	i.	The verification system should provide a tool for 
automatic test data generation of the design specification.

	j.	The verification system should provide a means of 
identifying which paths in the source code of the verification system are 
tested by a test suite.

	k.	The verification system should provide a facility for 
high-level debugging/tracing of unsuccessful proofs.

	l.	A formal justification of the methodology behind the 
verification system should be provided.

 APPENDIX

CONFIGURATION MANAGEMENT 


The purpose of configuration management is to ensure that changes made to 
verification systems take place in an identifiable and controlled 
environment.  Configuration managers take responsibility that additions, 
deletions, or changes made to the verification system do not jeopardize 
its ability to satisfy the requirements in Chapters 3 and 4.  Therefore, 
configuration management is vital to maintaining the endorsement of a 
verification system.

Additional information on configuration management can be found in A Guide 
to Understanding Configuration Management in Trusted Systems. [3]



OVERVIEW OF CONFIGURATION MANAGEMENT

Configuration management is a discipline applying technical and 
administrative direction to:  1) identify and document the functional and 
physical characteristics of each configuration item for the system; 2) 
manage all changes to these characteristics; and 3) record and report the 
status of change processing and implementation.  Configuration management 
involves process monitoring, version control, information capture, quality 
control, bookkeeping, and an organizational framework to support these 
activities.  The configuration being managed is the verification system 
plus all tools and documentation related to the configuration process.

Four major aspects of configuration management are configuration 
identification, configuration control, configuration status accounting, 
and configuration auditing.  



CONFIGURATION IDENTIFICATION

Configuration management entails decomposing the verification system into 
identifi*able, understandable, manageable, trackable units known as 
Configuration Items (CIs).  A CI is a uniquely identifiable subset of the 
system that represents the small*est portion to be subject to independent 
configuration control procedures.  The decomposition process of a 
verification system into CIs is called configuration identification.  

CIs can vary widely in size, type, and complexity.  Although there are no 
hard-and-fast rules for decomposition, the granularity of CIs can have 
great practical importance.  A favorable strategy is to designate 
relatively large CIs for elements that are not expected to change over the 
life of the system, and small CIs for elements likely to change more 
frequently.  



CONFIGURATION CONTROL

Configuration control is a means of assuring that system changes are 
approved before being implemented, only the proposed and approved changes 
are implemented, and the implementation is complete and accurate.  This 
involves strict procedures for proposing, monitoring, and approving system 
changes and their implementation.  Configuration control entails central 
direction of the change process by personnel who coordinate analytical 
tasks, approve system changes, review the implementation of changes, and 
supervise other tasks such as documentation.



CONFIGURATION ACCOUNTING

Configuration accounting documents the status of configuration control 
activities and in general provides the information needed to manage a 
configuration effectively.  It allows managers to trace system changes and 
establish the history of any developmental problems and associated fixes.  
Configuration accounting also tracks the status of current changes as they 
move through the configuration control process.  Configuration accounting 
establishes the granularity of recorded information and thus shapes the 
accuracy and usefulness of the audit function.

The accounting function must be able to locate all possible versions of a 
CI and all of the incremental changes involved, thereby deriving the 
status of that CI at any specific time.  The associated records must 
include commentary about the reason for each change and its major 
implications for the verification system.



CONFIGURATION AUDIT

Configuration audit is the quality assurance component of configuration 
management.  It involves periodic checks to determine the consistency and 
completeness of accounting information and to verify that all 
configuration management policies are being followed.  A vendor's 
configuration management program must be able to sustain a complete 
configuration audit by an NCSC review team.



CONFIGURATION MANAGEMENT PLAN

Strict adherence to a comprehensive configuration management plan is one 
of the most important requirements for successful configuration 
management.  The configuration management plan is the vendor's document 
tailored to the company's practices and personnel.  The plan accurately 
describes what the vendor is doing to the system at each moment and what 
evidence is being recorded.  



CONFIGURATION CONTROL BOARD

All analytical and design tasks are conducted under the direction of the 
vendor's corporate entity called the Configuration Control Board (CCB).  
The CCB is headed by a chairperson who is responsible for assuring that 
changes made do not jeopardize the soundness of the verification system.  
The Chairperson assures that the changes made are approved, tested, 
documented, and implemented correctly.  

The members of the CCB should interact periodically, either through formal 
meetings or other available means, to discuss configuration management 
topics such as proposed changes, configuration status accounting reports, 
and other topics that may be of interest to the different areas of the 
system development.  These interactions should be held to keep the entire 
system team updated on all advancements or alterations in the verification 
system.

 GLOSSARY 



Beta Version 

		Beta versions are intermediate releases of a product to be 
tested at one or more customer sites by the software end-user.  The 
customer describes in detail any problems encountered during testing to 
the developer, who makes the appropriate modifications.  Beta versions are 
not endorsed by the NCSC, but are primarily used for debugging and testing 
prior to submission for endorsement.

Complete

		A theory is complete if and only if every sentence of its 
language is either provable or refutable.

Concurrency 

		Simultaneous or parallel processing of events.

Configuration Accounting 

		The recording and reporting of configuration item 
descriptions and all departures from the baseline during design and 
production.

Configuration Audit 

		An independent review of computer software for the purpose 
of assessing compliance with established requirements, standards, and 
baselines. [3]

Configuration Control 

		The process of controlling modifications to the system's 
design, hardware, firmware, software, and documentation which provides 
sufficient assurance that the system is protected against the introduction 
of improper modification prior to, during, and after system 
implementation. [3]

Configuration Control Board (CCB) 

		An established vendor committee that is the final 
authority on all proposed changes to the verification system.

Configuration Identification 

		The identifying of the system configuration throughout the 
design, development, test, and production tasks. [3]

Configuration Item (CI) 

		The smallest component tracked by the configuration 
management system. [3]

Configuration Management 

		The process of controlling modifications to a verification 
system, including documentation, that provides sufficient assurance that 
the system is protected against the introduction of improper modification 
before, during, and after system implementation.  

Conjecture 

		A general conclusion proposed to be proved upon the basis 
of certain given premises or assumptions.

Consistency (Mathematical) 

		A logical theory is consistent if it contains no formula 
such that the formula and its negation are provable theorems.

Consistency (Methodological)

		Steadfast adherence to the same principles, course, form, 
etc.

Correctness 

		Free from errors; conforming to fact or truth.

Correctness Conditions 

		Conjectures that formalize the rules, security policies, 
models, or other critical requirements on a system.

Design Verification 

		A demonstration that a formal specification of a software 
system satisfies the correctness conditions (critical requirements 
specification).

Documentation 

		A set of manuals and technical papers that fully describe 
the verification system, its components, application, and operation.

Endorsed Tools List (ETL) 

		A list composed of those verification systems currently 
recommended by the NCSC for use in developing highly trusted systems.

Eventuality 

		The ability to prove that at some time in the future, a 
particular event will occur.

Formal Justification 

		Mathematically precise evidence that the methodology of 
the verification system is sound.

Formal Verification 

		The process of using formal proofs to demonstrate the 
consistency (design verification) between a formal specification of a 
system and a formal security policy model or (implementation verification) 
between the formal specification and its program implementation. [1]

Implementation Verification 

		A demonstration that a program implementation satisfies a 
formal specification of a system.

Informal Justification 

		An English description of the tools of a verification 
system and how they interact.  This includes a justification of the 
soundness of the theory.

Language 

		A set of symbols and rules of syntax regulating the 
relationship between the symbols, used to convey information.

Liveness 

		Formalizations that ensure that a system does something 
that it should do.

Metalogic 

		A type of logic used to describe another type of logic or 
a combination of different types of logic.

Methodology 

		The underlying principles and rules of organization of a 
verification system.

Production Quality Verification System 

		A verification system that is sound, user-friendly, 
efficient, robust, well-documented, maintainable, well-engineered 
(developed with software engineering techniques), available on a variety 
of hardware, and promoted (has education available for users). [2]

Proof 

		A syntactic analysis performed to validate the truth of an 
assertion relative to an (assumed) base of assertions.

Proof Checker 

		A tool that 1) accepts as input an assertion (called a 
conjecture), a set of assertions (called assumptions), and a proof; 2) 
terminates and outputs either success or failure; and 3) if it succeeds, 
then the conjecture is a valid consequence of the assumptions.

Reasoning Mechanism 

		A tool (interactive or fully automated) capable of 
checking or constructing proofs.

Safety Properties 

		Formalizations that ensure that a system does not do 
something that it should not do.

Semantics 

		A set of rules for interpreting the symbols and 
well-formed formulae of a language.

Sound 

		An argument is sound if all of its propositions are true 
and its argument form is valid.  A proof system is sound relative to a 
given semantics if every conjecture that can be proved is a valid 
consequence of the assumptions used in the proof.

Specification Language 

		A logically precise language used to describe the 
structure or behavior of a system to be verified.

Specification Processor 

		A software tool capable of receiving input, parsing it, 
generating conjectures (candidate theorems), and supplying results for 
further analysis (e.g., reasoning mechanism).

Syntax 

		A set of rules for constructing sequences of symbols from 
the primitive symbols of a language.

Technical Assessment Report (TAR) 

		A report that is written by an evaluation team during an 
evaluation of a verification system and available upon completion.

Theorem 

		In a given logical system, a well-formed formula that is 
proven in that system.

Theory 

		A formal theory is a coherent group of general 
propositions used as principles of explanation for a particular class of 
phenomena.

User-Friendly 

		A system is user-friendly if it facilitates learning and 
usage in an efficient manner.

Valid 

		An argument is valid when the conclusion is a valid 
consequence of the assumptions used in the argument.

Vendor Report (VR) 

		A report that is written by a vendor during and available 
upon completion of a reevaluation of a verification system.

Verification 

		The process of comparing two levels of system 
specification for proper correspondence (e.g., security policy model with 
top-level specification, top-level specification with source code, or 
source code with object code).  This process may or may not be automated. 
[1]

Verification Committee 

		A standing committee responsible for the management of the 
verification efforts at the NCSC.  The committee is chaired by the NCSC 
Deputy Director and includes the NCSC Chief Scientist, as well as 
representatives from both the NCSC's Office of Research and Development 
and Office of Computer Security Evaluations, Publications, and Support.

Verification System 

		An integrated set of tools and techniques for performing 
verification.

Well-Formed Formula 

		A sequence of symbols from a language that is constructed 
in accordance with the syntax for that language.



 BIBLIOGRAPHY 


[1]		Department of Defense, Department of Defense Trusted 
Computer System Evaluation Criteria, DOD 5200.28-STD, December 1985.  

[2]		Kemmerer, Richard A., Verification Assessment Study Final 
Report, University of California, March 1986.

[3]		National Computer Security Center, A Guide to 
Understanding Configuration Management in Trusted Systems, NCSC-TG-006, 
March 1988.

[4]		National Computer Security Center, Trusted Network 
Interpretation of the Trusted Computer System Evaluation Criteria, 
NCSC-TG-005, July 1987.

[5]		National Security Agency, Information Systems Security 
Products and Services Catalogue, Issued Quarterly, January 1989 and 
successors.

</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">testing</span>
        <span class="timestamp">2024-07-19 13:17:42</span>
    </div>
    <div class="message-content">this is first message

thanks

author: testing
</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">Unknown</span>
        <span class="timestamp">2024-07-22 18:27:57</span>
    </div>
    <div class="message-content">thank you god
</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">ilyag</span>
        <span class="timestamp">2024-07-22 19:38:03</span>
    </div>
    <div class="message-content">a new message

author: ilyag
</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">ilyag</span>
        <span class="timestamp">2024-07-28 17:04:51</span>
    </div>
    <div class="message-content">asdfadsfafdsfasd

author: ilyag</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">ilyag</span>
        <span class="timestamp">2024-07-28 17:04:51</span>
    </div>
    <div class="message-content">asdfadsf

author: ilyag</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">asdfads</span>
        <span class="timestamp">2024-07-28 17:04:51</span>
    </div>
    <div class="message-content">asdfadsfad

author: asdfads</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">ilyag</span>
        <span class="timestamp">2024-07-28 17:18:13</span>
    </div>
    <div class="message-content">thanks

author: ilyag</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">ilyag</span>
        <span class="timestamp">2024-07-28 17:38:17</span>
    </div>
    <div class="message-content">thisistest

author: ilyag</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">ilyag</span>
        <span class="timestamp">2024-07-28 17:38:46</span>
    </div>
    <div class="message-content">i test again

author: ilyag</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">ilyag</span>
        <span class="timestamp">2024-07-28 17:39:04</span>
    </div>
    <div class="message-content">test123

author: ilyag</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">ilyag</span>
        <span class="timestamp">2024-07-28 17:42:02</span>
    </div>
    <div class="message-content">99999999

author: ilyag</div>
    <div class="message-hashtags"></div>
</div>
<div class="message">
    <div class="message-header">
        <span class="author">alexa1</span>
        <span class="timestamp">2024-07-29 09:19:24</span>
    </div>
    <div class="message-content">aasdfds

author: alexa1</div>
    <div class="message-hashtags"></div>
</div>

            </div>
        </div>
        <div class="message-form">
            <form action="#" method="post">
                <input type="text" name="author" placeholder="Your Name" required>
                <textarea name="message" placeholder="Type your message here..." required></textarea>
                <button type="submit">Send</button>
            </form>
        </div>
        <div class="chat-info">
            <p>Total Messages: 30</p>
            <p>Generated on: 2024-07-29 10:08:22</p>
        </div>
    </div>
</body>
</html>
